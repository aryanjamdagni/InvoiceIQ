{
    "sample_spec": {
        "litellm_provider": "one of https://docs.litellm.ai/docs/providers",
        "mode": "one of: chat, embedding, completion, image_generation, audio_transcription, audio_speech, image_generation, moderation, rerank, search",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": "LEGACY parameter. set to max_output_tokens if provider specifies it. IF not set to max_input_tokens, if provider specifies it.",
        "max_input_tokens": "max input tokens, if the provider specifies it. if not default to max_tokens",
        "max_output_tokens": "max output tokens, if the provider specifies it. if not default to max_tokens"
    },
    "1024-x-1024/50-steps/bedrock/amazon.nova-canvas-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 2600,
        "max_output_tokens": null
    },
    "1024-x-1024/50-steps/stability.stable-diffusion-xl-v1": {
        "litellm_provider": "bedrock",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 77,
        "max_input_tokens": 77,
        "max_output_tokens": null
    },
    "1024-x-1024/dall-e-2": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "1024-x-1024/max-steps/stability.stable-diffusion-xl-v1": {
        "litellm_provider": "bedrock",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 77,
        "max_input_tokens": 77,
        "max_output_tokens": null
    },
    "256-x-256/dall-e-2": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "512-x-512/50-steps/stability.stable-diffusion-xl-v0": {
        "litellm_provider": "bedrock",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 77,
        "max_input_tokens": 77,
        "max_output_tokens": null
    },
    "512-x-512/dall-e-2": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "512-x-512/max-steps/stability.stable-diffusion-xl-v0": {
        "litellm_provider": "bedrock",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 77,
        "max_input_tokens": 77,
        "max_output_tokens": null
    },
    "ai21.j2-mid-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 1.25e-05,
        "output_cost_per_token": 1.25e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 8191,
        "max_output_tokens": 8191
    },
    "ai21.j2-ultra-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 1.88e-05,
        "output_cost_per_token": 1.88e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 8191,
        "max_output_tokens": 8191
    },
    "ai21.jamba-1-5-large-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 8e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "ai21.jamba-1-5-mini-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "ai21.jamba-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 7e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 70000,
        "max_output_tokens": 4096
    },
    "aiml/dall-e-2": {
        "litellm_provider": "aiml",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "aiml/dall-e-3": {
        "litellm_provider": "aiml",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "aiml/flux-pro": {
        "litellm_provider": "aiml",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "aiml/flux-pro/v1.1": {
        "litellm_provider": "aiml",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "aiml/flux-pro/v1.1-ultra": {
        "litellm_provider": "aiml",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "aiml/flux-realism": {
        "litellm_provider": "aiml",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "aiml/flux/dev": {
        "litellm_provider": "aiml",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "aiml/flux/kontext-max/text-to-image": {
        "litellm_provider": "aiml",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "aiml/flux/kontext-pro/text-to-image": {
        "litellm_provider": "aiml",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "aiml/flux/schnell": {
        "litellm_provider": "aiml",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "aiml/google/imagen-4.0-ultra-generate-001": {
        "litellm_provider": "aiml",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "aiml/google/nano-banana-pro": {
        "litellm_provider": "aiml",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "amazon.nova-canvas-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 2600,
        "max_output_tokens": null
    },
    "us.writer.palmyra-x4-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "us.writer.palmyra-x5-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 6e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192
    },
    "writer.palmyra-x4-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "writer.palmyra-x5-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 6e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192
    },
    "amazon.nova-lite-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 6e-08,
        "output_cost_per_token": 2.4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 10000,
        "max_input_tokens": 300000,
        "max_output_tokens": 10000
    },
    "amazon.nova-2-lite-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": 7.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 64000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000
    },
    "amazon.nova-2-pro-preview-20251202-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 2.1875e-06,
        "output_cost_per_token": 1.75e-05,
        "cache_read_input_token_cost": 5.46875e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 64000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000
    },
    "apac.amazon.nova-2-lite-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 3.3e-07,
        "output_cost_per_token": 2.75e-06,
        "cache_read_input_token_cost": 8.25e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 64000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000
    },
    "apac.amazon.nova-2-pro-preview-20251202-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 2.1875e-06,
        "output_cost_per_token": 1.75e-05,
        "cache_read_input_token_cost": 5.46875e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 64000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000
    },
    "eu.amazon.nova-2-lite-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 3.3e-07,
        "output_cost_per_token": 2.75e-06,
        "cache_read_input_token_cost": 8.25e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 64000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000
    },
    "eu.amazon.nova-2-pro-preview-20251202-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 2.1875e-06,
        "output_cost_per_token": 1.75e-05,
        "cache_read_input_token_cost": 5.46875e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 64000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000
    },
    "us.amazon.nova-2-lite-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 3.3e-07,
        "output_cost_per_token": 2.75e-06,
        "cache_read_input_token_cost": 8.25e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 64000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000
    },
    "us.amazon.nova-2-pro-preview-20251202-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 2.1875e-06,
        "output_cost_per_token": 1.75e-05,
        "cache_read_input_token_cost": 5.46875e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 64000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000
    },
    "amazon.nova-2-multimodal-embeddings-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "embedding",
        "input_cost_per_token": 1.35e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8172,
        "max_input_tokens": 8172,
        "max_output_tokens": null
    },
    "amazon.nova-micro-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 3.5e-08,
        "output_cost_per_token": 1.4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 10000,
        "max_input_tokens": 128000,
        "max_output_tokens": 10000
    },
    "amazon.nova-pro-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 8e-07,
        "output_cost_per_token": 3.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 10000,
        "max_input_tokens": 300000,
        "max_output_tokens": 10000
    },
    "amazon.rerank-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "rerank",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "max_output_tokens": 32000
    },
    "amazon.titan-embed-image-v1": {
        "litellm_provider": "bedrock",
        "mode": "embedding",
        "input_cost_per_token": 8e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128,
        "max_input_tokens": 128,
        "max_output_tokens": null
    },
    "amazon.titan-embed-text-v1": {
        "litellm_provider": "bedrock",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": null
    },
    "amazon.titan-embed-text-v2:0": {
        "litellm_provider": "bedrock",
        "mode": "embedding",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": null
    },
    "amazon.titan-image-generator-v1": {
        "litellm_provider": "bedrock",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "amazon.titan-image-generator-v2": {
        "litellm_provider": "bedrock",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "amazon.titan-image-generator-v2:0": {
        "litellm_provider": "bedrock",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "twelvelabs.marengo-embed-2-7-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "embedding",
        "input_cost_per_token": 7e-05,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 77,
        "max_input_tokens": 77,
        "max_output_tokens": null
    },
    "us.twelvelabs.marengo-embed-2-7-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "embedding",
        "input_cost_per_token": 7e-05,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 77,
        "max_input_tokens": 77,
        "max_output_tokens": null
    },
    "eu.twelvelabs.marengo-embed-2-7-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "embedding",
        "input_cost_per_token": 7e-05,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 77,
        "max_input_tokens": 77,
        "max_output_tokens": null
    },
    "twelvelabs.pegasus-1-2-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 7.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "us.twelvelabs.pegasus-1-2-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 7.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "eu.twelvelabs.pegasus-1-2-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 7.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "amazon.titan-text-express-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 1.3e-06,
        "output_cost_per_token": 1.7e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8000,
        "max_input_tokens": 42000,
        "max_output_tokens": 8000
    },
    "amazon.titan-text-lite-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4000,
        "max_input_tokens": 42000,
        "max_output_tokens": 4000
    },
    "amazon.titan-text-premier-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 42000,
        "max_output_tokens": 32000
    },
    "anthropic.claude-3-5-haiku-20241022-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 8e-07,
        "output_cost_per_token": 4e-06,
        "cache_read_input_token_cost": 8e-08,
        "cache_creation_input_token_cost": 1e-06,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "anthropic.claude-haiku-4-5-20251001-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": 1e-07,
        "cache_creation_input_token_cost": 1.25e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "anthropic.claude-haiku-4-5@20251001": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": 1e-07,
        "cache_creation_input_token_cost": 1.25e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "anthropic.claude-3-5-sonnet-20240620-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 4096,
        "max_input_tokens": 1000000,
        "max_output_tokens": 4096
    },
    "anthropic.claude-3-5-sonnet-20241022-v2:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192
    },
    "anthropic.claude-3-7-sonnet-20240620-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3.6e-06,
        "output_cost_per_token": 1.8e-05,
        "cache_read_input_token_cost": 3.6e-07,
        "cache_creation_input_token_cost": 4.5e-06,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "anthropic.claude-3-7-sonnet-20250219-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "anthropic.claude-3-haiku-20240307-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 1.25e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "anthropic.claude-3-opus-20240229-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "anthropic.claude-3-sonnet-20240229-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "anthropic.claude-instant-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 8e-07,
        "output_cost_per_token": 2.4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "anthropic.claude-opus-4-1-20250805-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "cache_creation_input_token_cost": 1.875e-05,
        "max_tokens": 32000,
        "max_input_tokens": 200000,
        "max_output_tokens": 32000
    },
    "anthropic.claude-opus-4-20250514-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "cache_creation_input_token_cost": 1.875e-05,
        "max_tokens": 32000,
        "max_input_tokens": 200000,
        "max_output_tokens": 32000
    },
    "anthropic.claude-opus-4-5-20251101-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 2.5e-05,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": 6.25e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "anthropic.claude-opus-4-6-v1": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 2.5e-05,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": 6.25e-06,
        "max_tokens": 128000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 128000
    },
    "global.anthropic.claude-opus-4-6-v1": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 2.5e-05,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": 6.25e-06,
        "max_tokens": 128000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 128000
    },
    "us.anthropic.claude-opus-4-6-v1": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 5.5e-06,
        "output_cost_per_token": 2.75e-05,
        "cache_read_input_token_cost": 5.5e-07,
        "cache_creation_input_token_cost": 6.875e-06,
        "max_tokens": 128000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 128000
    },
    "eu.anthropic.claude-opus-4-6-v1": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 5.5e-06,
        "output_cost_per_token": 2.75e-05,
        "cache_read_input_token_cost": 5.5e-07,
        "cache_creation_input_token_cost": 6.875e-06,
        "max_tokens": 128000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 128000
    },
    "apac.anthropic.claude-opus-4-6-v1": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 5.5e-06,
        "output_cost_per_token": 2.75e-05,
        "cache_read_input_token_cost": 5.5e-07,
        "cache_creation_input_token_cost": 6.875e-06,
        "max_tokens": 128000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 128000
    },
    "anthropic.claude-sonnet-4-20250514-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 64000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000
    },
    "anthropic.claude-sonnet-4-5-20250929-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "anthropic.claude-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 8e-06,
        "output_cost_per_token": 2.4e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "anthropic.claude-v2:1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 8e-06,
        "output_cost_per_token": 2.4e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "anyscale/HuggingFaceH4/zephyr-7b-beta": {
        "litellm_provider": "anyscale",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 1.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "anyscale/codellama/CodeLlama-34b-Instruct-hf": {
        "litellm_provider": "anyscale",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 1e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "anyscale/codellama/CodeLlama-70b-Instruct-hf": {
        "litellm_provider": "anyscale",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 1e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "anyscale/google/gemma-7b-it": {
        "litellm_provider": "anyscale",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 1.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "anyscale/meta-llama/Llama-2-13b-chat-hf": {
        "litellm_provider": "anyscale",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 2.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "anyscale/meta-llama/Llama-2-70b-chat-hf": {
        "litellm_provider": "anyscale",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 1e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "anyscale/meta-llama/Llama-2-7b-chat-hf": {
        "litellm_provider": "anyscale",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 1.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "anyscale/meta-llama/Meta-Llama-3-70B-Instruct": {
        "litellm_provider": "anyscale",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 1e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "anyscale/meta-llama/Meta-Llama-3-8B-Instruct": {
        "litellm_provider": "anyscale",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 1.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "anyscale/mistralai/Mistral-7B-Instruct-v0.1": {
        "litellm_provider": "anyscale",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 1.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "anyscale/mistralai/Mixtral-8x22B-Instruct-v0.1": {
        "litellm_provider": "anyscale",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 65536,
        "max_output_tokens": 65536
    },
    "anyscale/mistralai/Mixtral-8x7B-Instruct-v0.1": {
        "litellm_provider": "anyscale",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 1.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "apac.amazon.nova-lite-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 6.3e-08,
        "output_cost_per_token": 2.52e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 10000,
        "max_input_tokens": 300000,
        "max_output_tokens": 10000
    },
    "apac.amazon.nova-micro-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 3.7e-08,
        "output_cost_per_token": 1.48e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 10000,
        "max_input_tokens": 128000,
        "max_output_tokens": 10000
    },
    "apac.amazon.nova-pro-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 8.4e-07,
        "output_cost_per_token": 3.36e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 10000,
        "max_input_tokens": 300000,
        "max_output_tokens": 10000
    },
    "apac.anthropic.claude-3-5-sonnet-20240620-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "apac.anthropic.claude-3-5-sonnet-20241022-v2:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "apac.anthropic.claude-3-haiku-20240307-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 1.25e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "apac.anthropic.claude-haiku-4-5-20251001-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 1.1e-06,
        "output_cost_per_token": 5.5e-06,
        "cache_read_input_token_cost": 1.1e-07,
        "cache_creation_input_token_cost": 1.375e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "apac.anthropic.claude-3-sonnet-20240229-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "apac.anthropic.claude-sonnet-4-20250514-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 64000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000
    },
    "assemblyai/best": {
        "litellm_provider": "assemblyai",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "assemblyai/nano": {
        "litellm_provider": "assemblyai",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "au.anthropic.claude-sonnet-4-5-20250929-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 3.3e-06,
        "output_cost_per_token": 1.65e-05,
        "cache_read_input_token_cost": 3.3e-07,
        "cache_creation_input_token_cost": 4.125e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "azure/ada": {
        "litellm_provider": "azure",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 8191,
        "max_output_tokens": null
    },
    "azure/codex-mini": {
        "litellm_provider": "azure",
        "mode": "responses",
        "input_cost_per_token": 1.5e-06,
        "output_cost_per_token": 6e-06,
        "cache_read_input_token_cost": 3.75e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "azure/command-r-plus": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "azure_ai/claude-haiku-4-5": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": 1e-07,
        "cache_creation_input_token_cost": 1.25e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "azure_ai/claude-opus-4-5": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 2.5e-05,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": 6.25e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "azure_ai/claude-opus-4-6": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 2.5e-05,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": 6.25e-06,
        "max_tokens": 128000,
        "max_input_tokens": 200000,
        "max_output_tokens": 128000
    },
    "azure_ai/claude-opus-4-1": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "cache_creation_input_token_cost": 1.875e-05,
        "max_tokens": 32000,
        "max_input_tokens": 200000,
        "max_output_tokens": 32000
    },
    "azure_ai/claude-sonnet-4-5": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "azure/computer-use-preview": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.2e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 8192,
        "max_output_tokens": 1024
    },
    "azure/container": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure_ai/gpt-oss-120b": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "azure_ai/model_router": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 1.4e-07,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/eu/gpt-4o-2024-08-06": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 2.75e-06,
        "output_cost_per_token": 1.1e-05,
        "cache_read_input_token_cost": 1.375e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "azure/eu/gpt-4o-2024-11-20": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 2.75e-06,
        "output_cost_per_token": 1.1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": 1.38e-06,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "azure/eu/gpt-4o-mini-2024-07-18": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.65e-07,
        "output_cost_per_token": 6.6e-07,
        "cache_read_input_token_cost": 8.3e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "azure/eu/gpt-4o-mini-realtime-preview-2024-12-17": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 6.6e-07,
        "output_cost_per_token": 2.64e-06,
        "cache_read_input_token_cost": 3.3e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "azure/eu/gpt-4o-realtime-preview-2024-10-01": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 5.5e-06,
        "output_cost_per_token": 2.2e-05,
        "cache_read_input_token_cost": 2.75e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "azure/eu/gpt-4o-realtime-preview-2024-12-17": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 5.5e-06,
        "output_cost_per_token": 2.2e-05,
        "cache_read_input_token_cost": 2.75e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "azure/eu/gpt-5-2025-08-07": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.375e-06,
        "output_cost_per_token": 1.1e-05,
        "cache_read_input_token_cost": 1.375e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/eu/gpt-5-mini-2025-08-07": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 2.75e-07,
        "output_cost_per_token": 2.2e-06,
        "cache_read_input_token_cost": 2.75e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/eu/gpt-5.1": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.38e-06,
        "output_cost_per_token": 1.1e-05,
        "cache_read_input_token_cost": 1.4e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/eu/gpt-5.1-chat": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.38e-06,
        "output_cost_per_token": 1.1e-05,
        "cache_read_input_token_cost": 1.4e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "azure/eu/gpt-5.1-codex": {
        "litellm_provider": "azure",
        "mode": "responses",
        "input_cost_per_token": 1.38e-06,
        "output_cost_per_token": 1.1e-05,
        "cache_read_input_token_cost": 1.4e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/eu/gpt-5.1-codex-mini": {
        "litellm_provider": "azure",
        "mode": "responses",
        "input_cost_per_token": 2.75e-07,
        "output_cost_per_token": 2.2e-06,
        "cache_read_input_token_cost": 2.8e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/eu/gpt-5-nano-2025-08-07": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 5.5e-08,
        "output_cost_per_token": 4.4e-07,
        "cache_read_input_token_cost": 5.5e-09,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/eu/o1-2024-12-17": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.65e-05,
        "output_cost_per_token": 6.6e-05,
        "cache_read_input_token_cost": 8.25e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "azure/eu/o1-mini-2024-09-12": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.21e-06,
        "output_cost_per_token": 4.84e-06,
        "cache_read_input_token_cost": 6.05e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 128000,
        "max_output_tokens": 65536
    },
    "azure/eu/o1-preview-2024-09-12": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.65e-05,
        "output_cost_per_token": 6.6e-05,
        "cache_read_input_token_cost": 8.25e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 128000,
        "max_output_tokens": 32768
    },
    "azure/eu/o3-mini-2025-01-31": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.21e-06,
        "output_cost_per_token": 4.84e-06,
        "cache_read_input_token_cost": 6.05e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "azure/global-standard/gpt-4o-2024-08-06": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "azure/global-standard/gpt-4o-2024-11-20": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "azure/global-standard/gpt-4o-mini": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "azure/global/gpt-4o-2024-08-06": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "azure/global/gpt-4o-2024-11-20": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "azure/global/gpt-5.1": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/global/gpt-5.1-chat": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "azure/global/gpt-5.1-codex": {
        "litellm_provider": "azure",
        "mode": "responses",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/global/gpt-5.1-codex-mini": {
        "litellm_provider": "azure",
        "mode": "responses",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": 2.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/gpt-3.5-turbo": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4097,
        "max_output_tokens": 4096
    },
    "azure/gpt-3.5-turbo-0125": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 16384,
        "max_output_tokens": 4096
    },
    "azure/gpt-3.5-turbo-instruct-0914": {
        "litellm_provider": "azure_text",
        "mode": "completion",
        "input_cost_per_token": 1.5e-06,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4097,
        "max_input_tokens": 4097,
        "max_output_tokens": null
    },
    "azure/gpt-35-turbo": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4097,
        "max_output_tokens": 4096
    },
    "azure/gpt-35-turbo-0125": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 16384,
        "max_output_tokens": 4096
    },
    "azure/gpt-35-turbo-0301": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4097,
        "max_output_tokens": 4096
    },
    "azure/gpt-35-turbo-0613": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.5e-06,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4097,
        "max_output_tokens": 4096
    },
    "azure/gpt-35-turbo-1106": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 16384,
        "max_output_tokens": 4096
    },
    "azure/gpt-35-turbo-16k": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 16385,
        "max_output_tokens": 4096
    },
    "azure/gpt-35-turbo-16k-0613": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 16385,
        "max_output_tokens": 4096
    },
    "azure/gpt-35-turbo-instruct": {
        "litellm_provider": "azure_text",
        "mode": "completion",
        "input_cost_per_token": 1.5e-06,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4097,
        "max_input_tokens": 4097,
        "max_output_tokens": null
    },
    "azure/gpt-35-turbo-instruct-0914": {
        "litellm_provider": "azure_text",
        "mode": "completion",
        "input_cost_per_token": 1.5e-06,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4097,
        "max_input_tokens": 4097,
        "max_output_tokens": null
    },
    "azure/gpt-4": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 3e-05,
        "output_cost_per_token": 6e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096
    },
    "azure/gpt-4-0125-preview": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1e-05,
        "output_cost_per_token": 3e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "azure/gpt-4-0613": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 3e-05,
        "output_cost_per_token": 6e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096
    },
    "azure/gpt-4-1106-preview": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1e-05,
        "output_cost_per_token": 3e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "azure/gpt-4-32k": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 6e-05,
        "output_cost_per_token": 0.00012,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 32768,
        "max_output_tokens": 4096
    },
    "azure/gpt-4-32k-0613": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 6e-05,
        "output_cost_per_token": 0.00012,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 32768,
        "max_output_tokens": 4096
    },
    "azure/gpt-4-turbo": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1e-05,
        "output_cost_per_token": 3e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "azure/gpt-4-turbo-2024-04-09": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1e-05,
        "output_cost_per_token": 3e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "azure/gpt-4-turbo-vision-preview": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1e-05,
        "output_cost_per_token": 3e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "azure/gpt-4.1": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 8e-06,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768
    },
    "azure/gpt-4.1-2025-04-14": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 8e-06,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768
    },
    "azure/gpt-4.1-mini": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 1.6e-06,
        "cache_read_input_token_cost": 1e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768
    },
    "azure/gpt-4.1-mini-2025-04-14": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 1.6e-06,
        "cache_read_input_token_cost": 1e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768
    },
    "azure/gpt-4.1-nano": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": 2.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768
    },
    "azure/gpt-4.1-nano-2025-04-14": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": 2.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768
    },
    "azure/gpt-4.5-preview": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 7.5e-05,
        "output_cost_per_token": 0.00015,
        "cache_read_input_token_cost": 3.75e-05,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "azure/gpt-4o": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "azure/gpt-4o-2024-05-13": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "azure/gpt-4o-2024-08-06": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "azure/gpt-4o-2024-11-20": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 2.75e-06,
        "output_cost_per_token": 1.1e-05,
        "cache_read_input_token_cost": 1.25e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "azure/gpt-audio-2025-08-28": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "azure/gpt-audio-mini-2025-10-06": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "azure/gpt-4o-audio-preview-2024-12-17": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "azure/gpt-4o-mini": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.65e-07,
        "output_cost_per_token": 6.6e-07,
        "cache_read_input_token_cost": 7.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "azure/gpt-4o-mini-2024-07-18": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.65e-07,
        "output_cost_per_token": 6.6e-07,
        "cache_read_input_token_cost": 7.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "azure/gpt-4o-mini-audio-preview-2024-12-17": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "azure/gpt-4o-mini-realtime-preview-2024-12-17": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.4e-06,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "azure/gpt-realtime-2025-08-28": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 4e-06,
        "output_cost_per_token": 1.6e-05,
        "cache_read_input_token_cost": 4e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 32000,
        "max_output_tokens": 4096
    },
    "azure/gpt-realtime-mini-2025-10-06": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.4e-06,
        "cache_read_input_token_cost": 6e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 32000,
        "max_output_tokens": 4096
    },
    "azure/gpt-4o-mini-transcribe": {
        "litellm_provider": "azure",
        "mode": "audio_transcription",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 16000,
        "max_output_tokens": 2000
    },
    "azure/gpt-4o-mini-tts": {
        "litellm_provider": "azure",
        "mode": "audio_speech",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/gpt-4o-realtime-preview-2024-10-01": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 2e-05,
        "cache_read_input_token_cost": 2.5e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "azure/gpt-4o-realtime-preview-2024-12-17": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 2e-05,
        "cache_read_input_token_cost": 2.5e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "azure/gpt-4o-transcribe": {
        "litellm_provider": "azure",
        "mode": "audio_transcription",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 16000,
        "max_output_tokens": 2000
    },
    "azure/gpt-4o-transcribe-diarize": {
        "litellm_provider": "azure",
        "mode": "audio_transcription",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 16000,
        "max_output_tokens": 2000
    },
    "azure/gpt-5.1-2025-11-13": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/gpt-5.1-chat-2025-11-13": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "azure/gpt-5.1-codex-2025-11-13": {
        "litellm_provider": "azure",
        "mode": "responses",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/gpt-5.1-codex-mini-2025-11-13": {
        "litellm_provider": "azure",
        "mode": "responses",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": 2.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/gpt-5": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/gpt-5-2025-08-07": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/gpt-5-chat": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "azure/gpt-5-chat-latest": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "azure/gpt-5-codex": {
        "litellm_provider": "azure",
        "mode": "responses",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/gpt-5-mini": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": 2.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/gpt-5-mini-2025-08-07": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": 2.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/gpt-5-nano": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": 5e-09,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/gpt-5-nano-2025-08-07": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": 5e-09,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/gpt-5-pro": {
        "litellm_provider": "azure",
        "mode": "responses",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 0.00012,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/gpt-5.1": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/gpt-5.1-chat": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "azure/gpt-5.1-codex": {
        "litellm_provider": "azure",
        "mode": "responses",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/gpt-5.1-codex-max": {
        "litellm_provider": "azure",
        "mode": "responses",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/gpt-5.1-codex-mini": {
        "litellm_provider": "azure",
        "mode": "responses",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": 2.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/gpt-5.2": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.75e-06,
        "output_cost_per_token": 1.4e-05,
        "cache_read_input_token_cost": 1.75e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/gpt-5.2-2025-12-11": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.75e-06,
        "output_cost_per_token": 1.4e-05,
        "cache_read_input_token_cost": 1.75e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/gpt-5.2-chat": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.75e-06,
        "output_cost_per_token": 1.4e-05,
        "cache_read_input_token_cost": 1.75e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "azure/gpt-5.2-chat-2025-12-11": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.75e-06,
        "output_cost_per_token": 1.4e-05,
        "cache_read_input_token_cost": 1.75e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "azure/gpt-5.2-codex": {
        "litellm_provider": "azure",
        "mode": "responses",
        "input_cost_per_token": 1.75e-06,
        "output_cost_per_token": 1.4e-05,
        "cache_read_input_token_cost": 1.75e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/gpt-5.2-pro": {
        "litellm_provider": "azure",
        "mode": "responses",
        "input_cost_per_token": 2.1e-05,
        "output_cost_per_token": 0.000168,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/gpt-5.2-pro-2025-12-11": {
        "litellm_provider": "azure",
        "mode": "responses",
        "input_cost_per_token": 2.1e-05,
        "output_cost_per_token": 0.000168,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/gpt-image-1": {
        "litellm_provider": "azure",
        "mode": "image_generation",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": 1.25e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/hd/1024-x-1024/dall-e-3": {
        "litellm_provider": "azure",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/hd/1024-x-1792/dall-e-3": {
        "litellm_provider": "azure",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/hd/1792-x-1024/dall-e-3": {
        "litellm_provider": "azure",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/high/1024-x-1024/gpt-image-1": {
        "litellm_provider": "azure",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/high/1024-x-1536/gpt-image-1": {
        "litellm_provider": "azure",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/high/1536-x-1024/gpt-image-1": {
        "litellm_provider": "azure",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/low/1024-x-1024/gpt-image-1": {
        "litellm_provider": "azure",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/low/1024-x-1536/gpt-image-1": {
        "litellm_provider": "azure",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/low/1536-x-1024/gpt-image-1": {
        "litellm_provider": "azure",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/medium/1024-x-1024/gpt-image-1": {
        "litellm_provider": "azure",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/medium/1024-x-1536/gpt-image-1": {
        "litellm_provider": "azure",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/medium/1536-x-1024/gpt-image-1": {
        "litellm_provider": "azure",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/gpt-image-1-mini": {
        "litellm_provider": "azure",
        "mode": "image_generation",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": 2e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/gpt-image-1.5": {
        "litellm_provider": "azure",
        "mode": "image_generation",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": 1.25e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/gpt-image-1.5-2025-12-16": {
        "litellm_provider": "azure",
        "mode": "image_generation",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": 1.25e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/low/1024-x-1024/gpt-image-1-mini": {
        "litellm_provider": "azure",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/low/1024-x-1536/gpt-image-1-mini": {
        "litellm_provider": "azure",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/low/1536-x-1024/gpt-image-1-mini": {
        "litellm_provider": "azure",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/medium/1024-x-1024/gpt-image-1-mini": {
        "litellm_provider": "azure",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/medium/1024-x-1536/gpt-image-1-mini": {
        "litellm_provider": "azure",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/medium/1536-x-1024/gpt-image-1-mini": {
        "litellm_provider": "azure",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/high/1024-x-1024/gpt-image-1-mini": {
        "litellm_provider": "azure",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/high/1024-x-1536/gpt-image-1-mini": {
        "litellm_provider": "azure",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/high/1536-x-1024/gpt-image-1-mini": {
        "litellm_provider": "azure",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/mistral-large-2402": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 8e-06,
        "output_cost_per_token": 2.4e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "max_output_tokens": null
    },
    "azure/mistral-large-latest": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 8e-06,
        "output_cost_per_token": 2.4e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "max_output_tokens": null
    },
    "azure/o1": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 6e-05,
        "cache_read_input_token_cost": 7.5e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "azure/o1-2024-12-17": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 6e-05,
        "cache_read_input_token_cost": 7.5e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "azure/o1-mini": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.21e-06,
        "output_cost_per_token": 4.84e-06,
        "cache_read_input_token_cost": 6.05e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 128000,
        "max_output_tokens": 65536
    },
    "azure/o1-mini-2024-09-12": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.1e-06,
        "output_cost_per_token": 4.4e-06,
        "cache_read_input_token_cost": 5.5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 128000,
        "max_output_tokens": 65536
    },
    "azure/o1-preview": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 6e-05,
        "cache_read_input_token_cost": 7.5e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 128000,
        "max_output_tokens": 32768
    },
    "azure/o1-preview-2024-09-12": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 6e-05,
        "cache_read_input_token_cost": 7.5e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 128000,
        "max_output_tokens": 32768
    },
    "azure/o3": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 8e-06,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "azure/o3-2025-04-16": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 8e-06,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "azure/o3-deep-research": {
        "litellm_provider": "azure",
        "mode": "responses",
        "input_cost_per_token": 1e-05,
        "output_cost_per_token": 4e-05,
        "cache_read_input_token_cost": 2.5e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "azure/o3-mini": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.1e-06,
        "output_cost_per_token": 4.4e-06,
        "cache_read_input_token_cost": 5.5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "azure/o3-mini-2025-01-31": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.1e-06,
        "output_cost_per_token": 4.4e-06,
        "cache_read_input_token_cost": 5.5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "azure/o3-pro": {
        "litellm_provider": "azure",
        "mode": "responses",
        "input_cost_per_token": 2e-05,
        "output_cost_per_token": 8e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "azure/o3-pro-2025-06-10": {
        "litellm_provider": "azure",
        "mode": "responses",
        "input_cost_per_token": 2e-05,
        "output_cost_per_token": 8e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "azure/o4-mini": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.1e-06,
        "output_cost_per_token": 4.4e-06,
        "cache_read_input_token_cost": 2.75e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "azure/o4-mini-2025-04-16": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.1e-06,
        "output_cost_per_token": 4.4e-06,
        "cache_read_input_token_cost": 2.75e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "azure/standard/1024-x-1024/dall-e-2": {
        "litellm_provider": "azure",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/standard/1024-x-1024/dall-e-3": {
        "litellm_provider": "azure",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/standard/1024-x-1792/dall-e-3": {
        "litellm_provider": "azure",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/standard/1792-x-1024/dall-e-3": {
        "litellm_provider": "azure",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/text-embedding-3-large": {
        "litellm_provider": "azure",
        "mode": "embedding",
        "input_cost_per_token": 1.3e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 8191,
        "max_output_tokens": null
    },
    "azure/text-embedding-3-small": {
        "litellm_provider": "azure",
        "mode": "embedding",
        "input_cost_per_token": 2e-08,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 8191,
        "max_output_tokens": null
    },
    "azure/text-embedding-ada-002": {
        "litellm_provider": "azure",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 8191,
        "max_output_tokens": null
    },
    "azure/speech/azure-tts": {
        "litellm_provider": "azure",
        "mode": "audio_speech",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/speech/azure-tts-hd": {
        "litellm_provider": "azure",
        "mode": "audio_speech",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/tts-1": {
        "litellm_provider": "azure",
        "mode": "audio_speech",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/tts-1-hd": {
        "litellm_provider": "azure",
        "mode": "audio_speech",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/us/gpt-4.1-2025-04-14": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 2.2e-06,
        "output_cost_per_token": 8.8e-06,
        "cache_read_input_token_cost": 5.5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768
    },
    "azure/us/gpt-4.1-mini-2025-04-14": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 4.4e-07,
        "output_cost_per_token": 1.76e-06,
        "cache_read_input_token_cost": 1.1e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768
    },
    "azure/us/gpt-4.1-nano-2025-04-14": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.1e-07,
        "output_cost_per_token": 4.4e-07,
        "cache_read_input_token_cost": 2.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768
    },
    "azure/us/gpt-4o-2024-08-06": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 2.75e-06,
        "output_cost_per_token": 1.1e-05,
        "cache_read_input_token_cost": 1.375e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "azure/us/gpt-4o-2024-11-20": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 2.75e-06,
        "output_cost_per_token": 1.1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": 1.38e-06,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "azure/us/gpt-4o-mini-2024-07-18": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.65e-07,
        "output_cost_per_token": 6.6e-07,
        "cache_read_input_token_cost": 8.3e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "azure/us/gpt-4o-mini-realtime-preview-2024-12-17": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 6.6e-07,
        "output_cost_per_token": 2.64e-06,
        "cache_read_input_token_cost": 3.3e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "azure/us/gpt-4o-realtime-preview-2024-10-01": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 5.5e-06,
        "output_cost_per_token": 2.2e-05,
        "cache_read_input_token_cost": 2.75e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "azure/us/gpt-4o-realtime-preview-2024-12-17": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 5.5e-06,
        "output_cost_per_token": 2.2e-05,
        "cache_read_input_token_cost": 2.75e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "azure/us/gpt-5-2025-08-07": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.375e-06,
        "output_cost_per_token": 1.1e-05,
        "cache_read_input_token_cost": 1.375e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/us/gpt-5-mini-2025-08-07": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 2.75e-07,
        "output_cost_per_token": 2.2e-06,
        "cache_read_input_token_cost": 2.75e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/us/gpt-5-nano-2025-08-07": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 5.5e-08,
        "output_cost_per_token": 4.4e-07,
        "cache_read_input_token_cost": 5.5e-09,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/us/gpt-5.1": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.38e-06,
        "output_cost_per_token": 1.1e-05,
        "cache_read_input_token_cost": 1.4e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/us/gpt-5.1-chat": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.38e-06,
        "output_cost_per_token": 1.1e-05,
        "cache_read_input_token_cost": 1.4e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "azure/us/gpt-5.1-codex": {
        "litellm_provider": "azure",
        "mode": "responses",
        "input_cost_per_token": 1.38e-06,
        "output_cost_per_token": 1.1e-05,
        "cache_read_input_token_cost": 1.4e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/us/gpt-5.1-codex-mini": {
        "litellm_provider": "azure",
        "mode": "responses",
        "input_cost_per_token": 2.75e-07,
        "output_cost_per_token": 2.2e-06,
        "cache_read_input_token_cost": 2.8e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "azure/us/o1-2024-12-17": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.65e-05,
        "output_cost_per_token": 6.6e-05,
        "cache_read_input_token_cost": 8.25e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "azure/us/o1-mini-2024-09-12": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.21e-06,
        "output_cost_per_token": 4.84e-06,
        "cache_read_input_token_cost": 6.05e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 128000,
        "max_output_tokens": 65536
    },
    "azure/us/o1-preview-2024-09-12": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.65e-05,
        "output_cost_per_token": 6.6e-05,
        "cache_read_input_token_cost": 8.25e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 128000,
        "max_output_tokens": 32768
    },
    "azure/us/o3-2025-04-16": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 2.2e-06,
        "output_cost_per_token": 8.8e-06,
        "cache_read_input_token_cost": 5.5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "azure/us/o3-mini-2025-01-31": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.21e-06,
        "output_cost_per_token": 4.84e-06,
        "cache_read_input_token_cost": 6.05e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "azure/us/o4-mini-2025-04-16": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 1.21e-06,
        "output_cost_per_token": 4.84e-06,
        "cache_read_input_token_cost": 3.1e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "azure/whisper-1": {
        "litellm_provider": "azure",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure_ai/Cohere-embed-v3-english": {
        "litellm_provider": "azure_ai",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 512,
        "max_input_tokens": 512,
        "max_output_tokens": null
    },
    "azure_ai/Cohere-embed-v3-multilingual": {
        "litellm_provider": "azure_ai",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 512,
        "max_input_tokens": 512,
        "max_output_tokens": null
    },
    "azure_ai/FLUX-1.1-pro": {
        "litellm_provider": "azure_ai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure_ai/FLUX.1-Kontext-pro": {
        "litellm_provider": "azure_ai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure_ai/flux.2-pro": {
        "litellm_provider": "azure_ai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure_ai/Llama-3.2-11B-Vision-Instruct": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 3.7e-07,
        "output_cost_per_token": 3.7e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048
    },
    "azure_ai/Llama-3.2-90B-Vision-Instruct": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 2.04e-06,
        "output_cost_per_token": 2.04e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048
    },
    "azure_ai/Llama-3.3-70B-Instruct": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 7.1e-07,
        "output_cost_per_token": 7.1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048
    },
    "azure_ai/Llama-4-Maverick-17B-128E-Instruct-FP8": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 1.41e-06,
        "output_cost_per_token": 3.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 1000000,
        "max_output_tokens": 16384
    },
    "azure_ai/Llama-4-Scout-17B-16E-Instruct": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 7.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 10000000,
        "max_output_tokens": 16384
    },
    "azure_ai/Meta-Llama-3-70B-Instruct": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 1.1e-06,
        "output_cost_per_token": 3.7e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 8192,
        "max_output_tokens": 2048
    },
    "azure_ai/Meta-Llama-3.1-405B-Instruct": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 5.33e-06,
        "output_cost_per_token": 1.6e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048
    },
    "azure_ai/Meta-Llama-3.1-70B-Instruct": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 2.68e-06,
        "output_cost_per_token": 3.54e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048
    },
    "azure_ai/Meta-Llama-3.1-8B-Instruct": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 6.1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048
    },
    "azure_ai/Phi-3-medium-128k-instruct": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 1.7e-07,
        "output_cost_per_token": 6.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "azure_ai/Phi-3-medium-4k-instruct": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 1.7e-07,
        "output_cost_per_token": 6.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "azure_ai/Phi-3-mini-128k-instruct": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 1.3e-07,
        "output_cost_per_token": 5.2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "azure_ai/Phi-3-mini-4k-instruct": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 1.3e-07,
        "output_cost_per_token": 5.2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "azure_ai/Phi-3-small-128k-instruct": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "azure_ai/Phi-3-small-8k-instruct": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096
    },
    "azure_ai/Phi-3.5-MoE-instruct": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 1.6e-07,
        "output_cost_per_token": 6.4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "azure_ai/Phi-3.5-mini-instruct": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 1.3e-07,
        "output_cost_per_token": 5.2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "azure_ai/Phi-3.5-vision-instruct": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 1.3e-07,
        "output_cost_per_token": 5.2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "azure_ai/Phi-4": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "azure_ai/Phi-4-mini-instruct": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 7.5e-08,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 131072,
        "max_output_tokens": 4096
    },
    "azure_ai/Phi-4-multimodal-instruct": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 8e-08,
        "output_cost_per_token": 3.2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 131072,
        "max_output_tokens": 4096
    },
    "azure_ai/Phi-4-mini-reasoning": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 8e-08,
        "output_cost_per_token": 3.2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 131072,
        "max_output_tokens": 4096
    },
    "azure_ai/Phi-4-reasoning": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 32768,
        "max_output_tokens": 4096
    },
    "azure_ai/mistral-document-ai-2505": {
        "litellm_provider": "azure_ai",
        "mode": "ocr",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure_ai/doc-intelligence/prebuilt-read": {
        "litellm_provider": "azure_ai",
        "mode": "ocr",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure_ai/doc-intelligence/prebuilt-layout": {
        "litellm_provider": "azure_ai",
        "mode": "ocr",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure_ai/doc-intelligence/prebuilt-document": {
        "litellm_provider": "azure_ai",
        "mode": "ocr",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure_ai/MAI-DS-R1": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 1.35e-06,
        "output_cost_per_token": 5.4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "azure_ai/cohere-rerank-v3-english": {
        "litellm_provider": "azure_ai",
        "mode": "rerank",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "azure_ai/cohere-rerank-v3-multilingual": {
        "litellm_provider": "azure_ai",
        "mode": "rerank",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "azure_ai/cohere-rerank-v3.5": {
        "litellm_provider": "azure_ai",
        "mode": "rerank",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "azure_ai/cohere-rerank-v4.0-pro": {
        "litellm_provider": "azure_ai",
        "mode": "rerank",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "azure_ai/cohere-rerank-v4.0-fast": {
        "litellm_provider": "azure_ai",
        "mode": "rerank",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "azure_ai/deepseek-v3.2": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 5.8e-07,
        "output_cost_per_token": 1.68e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840
    },
    "azure_ai/deepseek-v3.2-speciale": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 5.8e-07,
        "output_cost_per_token": 1.68e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840
    },
    "azure_ai/deepseek-r1": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 1.35e-06,
        "output_cost_per_token": 5.4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "azure_ai/deepseek-v3": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 1.14e-06,
        "output_cost_per_token": 4.56e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "azure_ai/deepseek-v3-0324": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 1.14e-06,
        "output_cost_per_token": 4.56e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "azure_ai/embed-v-4-0": {
        "litellm_provider": "azure_ai",
        "mode": "embedding",
        "input_cost_per_token": 1.2e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": null
    },
    "azure_ai/global/grok-3": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "azure_ai/global/grok-3-mini": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 1.27e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "azure_ai/grok-3": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "azure_ai/grok-3-mini": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 1.27e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "azure_ai/grok-4": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "azure_ai/grok-4-fast-non-reasoning": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "azure_ai/grok-4-fast-reasoning": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "azure_ai/grok-code-fast-1": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "azure_ai/jais-30b-chat": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 0.0032,
        "output_cost_per_token": 0.00971,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "azure_ai/jamba-instruct": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 7e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 70000,
        "max_output_tokens": 4096
    },
    "azure_ai/ministral-3b": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 4e-08,
        "output_cost_per_token": 4e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "azure_ai/mistral-large": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 4e-06,
        "output_cost_per_token": 1.2e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191
    },
    "azure_ai/mistral-large-2407": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 6e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "azure_ai/mistral-large-latest": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 6e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "azure_ai/mistral-large-3": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 256000,
        "max_output_tokens": 8191
    },
    "azure_ai/mistral-medium-2505": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 131072,
        "max_output_tokens": 8191
    },
    "azure_ai/mistral-nemo": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 1.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 131072,
        "max_output_tokens": 4096
    },
    "azure_ai/mistral-small": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 3e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191
    },
    "azure_ai/mistral-small-2503": {
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 3e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "babbage-002": {
        "litellm_provider": "text-completion-openai",
        "mode": "completion",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 16384,
        "max_output_tokens": 4096
    },
    "bedrock/*/1-month-commitment/cohere.command-light-text-v14": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "bedrock/*/1-month-commitment/cohere.command-text-v14": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "bedrock/*/6-month-commitment/cohere.command-light-text-v14": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "bedrock/*/6-month-commitment/cohere.command-text-v14": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-instant-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2:1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-instant-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2:1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/ap-northeast-1/anthropic.claude-instant-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 2.23e-06,
        "output_cost_per_token": 7.55e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/ap-northeast-1/anthropic.claude-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 8e-06,
        "output_cost_per_token": 2.4e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/ap-northeast-1/anthropic.claude-v2:1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 8e-06,
        "output_cost_per_token": 2.4e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/ap-south-1/meta.llama3-70b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3.18e-06,
        "output_cost_per_token": 4.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "bedrock/ap-south-1/meta.llama3-8b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3.6e-07,
        "output_cost_per_token": 7.2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "bedrock/ca-central-1/meta.llama3-70b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3.05e-06,
        "output_cost_per_token": 4.03e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "bedrock/ca-central-1/meta.llama3-8b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3.5e-07,
        "output_cost_per_token": 6.9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "bedrock/eu-central-1/1-month-commitment/anthropic.claude-instant-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/eu-central-1/1-month-commitment/anthropic.claude-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2:1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/eu-central-1/6-month-commitment/anthropic.claude-instant-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/eu-central-1/6-month-commitment/anthropic.claude-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2:1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/eu-central-1/anthropic.claude-instant-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 2.48e-06,
        "output_cost_per_token": 8.38e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/eu-central-1/anthropic.claude-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 8e-06,
        "output_cost_per_token": 2.4e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/eu-central-1/anthropic.claude-v2:1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 8e-06,
        "output_cost_per_token": 2.4e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/eu-west-1/meta.llama3-70b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 2.86e-06,
        "output_cost_per_token": 3.78e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "bedrock/eu-west-1/meta.llama3-8b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3.2e-07,
        "output_cost_per_token": 6.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "bedrock/eu-west-2/meta.llama3-70b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3.45e-06,
        "output_cost_per_token": 4.55e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "bedrock/eu-west-2/meta.llama3-8b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3.9e-07,
        "output_cost_per_token": 7.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "bedrock/eu-west-3/mistral.mistral-7b-instruct-v0:2": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2.6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191
    },
    "bedrock/eu-west-3/mistral.mistral-large-2402-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 1.04e-05,
        "output_cost_per_token": 3.12e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191
    },
    "bedrock/eu-west-3/mistral.mixtral-8x7b-instruct-v0:1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 5.9e-07,
        "output_cost_per_token": 9.1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191
    },
    "bedrock/invoke/anthropic.claude-3-5-sonnet-20240620-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "bedrock/sa-east-1/meta.llama3-70b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 4.45e-06,
        "output_cost_per_token": 5.88e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "bedrock/sa-east-1/meta.llama3-8b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.01e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "bedrock/us-east-1/1-month-commitment/anthropic.claude-instant-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/us-east-1/1-month-commitment/anthropic.claude-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/us-east-1/1-month-commitment/anthropic.claude-v2:1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/us-east-1/6-month-commitment/anthropic.claude-instant-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/us-east-1/6-month-commitment/anthropic.claude-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/us-east-1/6-month-commitment/anthropic.claude-v2:1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/us-east-1/anthropic.claude-instant-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 8e-07,
        "output_cost_per_token": 2.4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/us-east-1/anthropic.claude-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 8e-06,
        "output_cost_per_token": 2.4e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/us-east-1/anthropic.claude-v2:1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 8e-06,
        "output_cost_per_token": 2.4e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/us-east-1/meta.llama3-70b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 2.65e-06,
        "output_cost_per_token": 3.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "bedrock/us-east-1/meta.llama3-8b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "bedrock/us-east-1/mistral.mistral-7b-instruct-v0:2": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191
    },
    "bedrock/us-east-1/mistral.mistral-large-2402-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 8e-06,
        "output_cost_per_token": 2.4e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191
    },
    "bedrock/us-east-1/mistral.mixtral-8x7b-instruct-v0:1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 4.5e-07,
        "output_cost_per_token": 7e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191
    },
    "bedrock/us-gov-east-1/amazon.nova-pro-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 9.6e-07,
        "output_cost_per_token": 3.84e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 10000,
        "max_input_tokens": 300000,
        "max_output_tokens": 10000
    },
    "bedrock/us-gov-east-1/amazon.titan-embed-text-v1": {
        "litellm_provider": "bedrock",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": null
    },
    "bedrock/us-gov-east-1/amazon.titan-embed-text-v2:0": {
        "litellm_provider": "bedrock",
        "mode": "embedding",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": null
    },
    "bedrock/us-gov-east-1/amazon.titan-text-express-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 1.3e-06,
        "output_cost_per_token": 1.7e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8000,
        "max_input_tokens": 42000,
        "max_output_tokens": 8000
    },
    "bedrock/us-gov-east-1/amazon.titan-text-lite-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4000,
        "max_input_tokens": 42000,
        "max_output_tokens": 4000
    },
    "bedrock/us-gov-east-1/amazon.titan-text-premier-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 42000,
        "max_output_tokens": 32000
    },
    "bedrock/us-gov-east-1/anthropic.claude-3-5-sonnet-20240620-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3.6e-06,
        "output_cost_per_token": 1.8e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "bedrock/us-gov-east-1/anthropic.claude-3-haiku-20240307-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "bedrock/us-gov-east-1/claude-sonnet-4-5-20250929-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3.3e-06,
        "output_cost_per_token": 1.65e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "bedrock/us-gov-east-1/meta.llama3-70b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 2.65e-06,
        "output_cost_per_token": 3.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 8000,
        "max_output_tokens": 2048
    },
    "bedrock/us-gov-east-1/meta.llama3-8b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 2.65e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 8000,
        "max_output_tokens": 2048
    },
    "bedrock/us-gov-west-1/amazon.nova-pro-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 9.6e-07,
        "output_cost_per_token": 3.84e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 10000,
        "max_input_tokens": 300000,
        "max_output_tokens": 10000
    },
    "bedrock/us-gov-west-1/amazon.titan-embed-text-v1": {
        "litellm_provider": "bedrock",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": null
    },
    "bedrock/us-gov-west-1/amazon.titan-embed-text-v2:0": {
        "litellm_provider": "bedrock",
        "mode": "embedding",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": null
    },
    "bedrock/us-gov-west-1/amazon.titan-text-express-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 1.3e-06,
        "output_cost_per_token": 1.7e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8000,
        "max_input_tokens": 42000,
        "max_output_tokens": 8000
    },
    "bedrock/us-gov-west-1/amazon.titan-text-lite-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4000,
        "max_input_tokens": 42000,
        "max_output_tokens": 4000
    },
    "bedrock/us-gov-west-1/amazon.titan-text-premier-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 42000,
        "max_output_tokens": 32000
    },
    "bedrock/us-gov-west-1/anthropic.claude-3-7-sonnet-20250219-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3.6e-06,
        "output_cost_per_token": 1.8e-05,
        "cache_read_input_token_cost": 3.6e-07,
        "cache_creation_input_token_cost": 4.5e-06,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "bedrock/us-gov-west-1/anthropic.claude-3-5-sonnet-20240620-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3.6e-06,
        "output_cost_per_token": 1.8e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "bedrock/us-gov-west-1/anthropic.claude-3-haiku-20240307-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "bedrock/us-gov-west-1/claude-sonnet-4-5-20250929-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3.3e-06,
        "output_cost_per_token": 1.65e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "bedrock/us-gov-west-1/meta.llama3-70b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 2.65e-06,
        "output_cost_per_token": 3.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 8000,
        "max_output_tokens": 2048
    },
    "bedrock/us-gov-west-1/meta.llama3-8b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 2.65e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 8000,
        "max_output_tokens": 2048
    },
    "bedrock/us-west-1/meta.llama3-70b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 2.65e-06,
        "output_cost_per_token": 3.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "bedrock/us-west-1/meta.llama3-8b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "bedrock/us-west-2/1-month-commitment/anthropic.claude-instant-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/us-west-2/1-month-commitment/anthropic.claude-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/us-west-2/1-month-commitment/anthropic.claude-v2:1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/us-west-2/6-month-commitment/anthropic.claude-instant-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/us-west-2/6-month-commitment/anthropic.claude-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/us-west-2/6-month-commitment/anthropic.claude-v2:1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/us-west-2/anthropic.claude-instant-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 8e-07,
        "output_cost_per_token": 2.4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/us-west-2/anthropic.claude-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 8e-06,
        "output_cost_per_token": 2.4e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/us-west-2/anthropic.claude-v2:1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 8e-06,
        "output_cost_per_token": 2.4e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191
    },
    "bedrock/us-west-2/mistral.mistral-7b-instruct-v0:2": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191
    },
    "bedrock/us-west-2/mistral.mistral-large-2402-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 8e-06,
        "output_cost_per_token": 2.4e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191
    },
    "bedrock/us-west-2/mistral.mixtral-8x7b-instruct-v0:1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 4.5e-07,
        "output_cost_per_token": 7e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191
    },
    "bedrock/us.anthropic.claude-3-5-haiku-20241022-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 8e-07,
        "output_cost_per_token": 4e-06,
        "cache_read_input_token_cost": 8e-08,
        "cache_creation_input_token_cost": 1e-06,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "cerebras/llama-3.3-70b": {
        "litellm_provider": "cerebras",
        "mode": "chat",
        "input_cost_per_token": 8.5e-07,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "cerebras/llama3.1-70b": {
        "litellm_provider": "cerebras",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "cerebras/llama3.1-8b": {
        "litellm_provider": "cerebras",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "cerebras/gpt-oss-120b": {
        "litellm_provider": "cerebras",
        "mode": "chat",
        "input_cost_per_token": 3.5e-07,
        "output_cost_per_token": 7.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 131072,
        "max_output_tokens": 32768
    },
    "cerebras/qwen-3-32b": {
        "litellm_provider": "cerebras",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "cerebras/zai-glm-4.6": {
        "litellm_provider": "cerebras",
        "mode": "chat",
        "input_cost_per_token": 2.25e-06,
        "output_cost_per_token": 2.75e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "cerebras/zai-glm-4.7": {
        "litellm_provider": "cerebras",
        "mode": "chat",
        "input_cost_per_token": 2.25e-06,
        "output_cost_per_token": 2.75e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "chat-bison": {
        "litellm_provider": "vertex_ai-chat-models",
        "mode": "chat",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 1.25e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096
    },
    "chat-bison-32k": {
        "litellm_provider": "vertex_ai-chat-models",
        "mode": "chat",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 1.25e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 32000,
        "max_output_tokens": 8192
    },
    "chat-bison-32k@002": {
        "litellm_provider": "vertex_ai-chat-models",
        "mode": "chat",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 1.25e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 32000,
        "max_output_tokens": 8192
    },
    "chat-bison@001": {
        "litellm_provider": "vertex_ai-chat-models",
        "mode": "chat",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 1.25e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096
    },
    "chat-bison@002": {
        "litellm_provider": "vertex_ai-chat-models",
        "mode": "chat",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 1.25e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096
    },
    "chatdolphin": {
        "litellm_provider": "nlp_cloud",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "chatgpt-4o-latest": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "gpt-4o-transcribe-diarize": {
        "litellm_provider": "openai",
        "mode": "audio_transcription",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 16000,
        "max_output_tokens": 2000
    },
    "claude-3-5-haiku-20241022": {
        "litellm_provider": "anthropic",
        "mode": "chat",
        "input_cost_per_token": 8e-07,
        "output_cost_per_token": 4e-06,
        "cache_read_input_token_cost": 8e-08,
        "cache_creation_input_token_cost": 1e-06,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "claude-3-5-haiku-latest": {
        "litellm_provider": "anthropic",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": 1e-07,
        "cache_creation_input_token_cost": 1.25e-06,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "claude-haiku-4-5-20251001": {
        "litellm_provider": "anthropic",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": 1e-07,
        "cache_creation_input_token_cost": 1.25e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "claude-haiku-4-5": {
        "litellm_provider": "anthropic",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": 1e-07,
        "cache_creation_input_token_cost": 1.25e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "claude-3-5-sonnet-20240620": {
        "litellm_provider": "anthropic",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "claude-3-5-sonnet-20241022": {
        "litellm_provider": "anthropic",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "claude-3-5-sonnet-latest": {
        "litellm_provider": "anthropic",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "claude-3-7-sonnet-20250219": {
        "litellm_provider": "anthropic",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "claude-3-7-sonnet-latest": {
        "litellm_provider": "anthropic",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "claude-3-haiku-20240307": {
        "litellm_provider": "anthropic",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 1.25e-06,
        "cache_read_input_token_cost": 3e-08,
        "cache_creation_input_token_cost": 3e-07,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "claude-3-opus-20240229": {
        "litellm_provider": "anthropic",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "cache_creation_input_token_cost": 1.875e-05,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "claude-3-opus-latest": {
        "litellm_provider": "anthropic",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "cache_creation_input_token_cost": 1.875e-05,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "claude-4-opus-20250514": {
        "litellm_provider": "anthropic",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "cache_creation_input_token_cost": 1.875e-05,
        "max_tokens": 32000,
        "max_input_tokens": 200000,
        "max_output_tokens": 32000
    },
    "claude-4-sonnet-20250514": {
        "litellm_provider": "anthropic",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 64000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000
    },
    "claude-sonnet-4-5": {
        "litellm_provider": "anthropic",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "claude-sonnet-4-5-20250929": {
        "litellm_provider": "anthropic",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "claude-sonnet-4-5-20250929-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "claude-opus-4-1": {
        "litellm_provider": "anthropic",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "cache_creation_input_token_cost": 1.875e-05,
        "max_tokens": 32000,
        "max_input_tokens": 200000,
        "max_output_tokens": 32000
    },
    "claude-opus-4-1-20250805": {
        "litellm_provider": "anthropic",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "cache_creation_input_token_cost": 1.875e-05,
        "max_tokens": 32000,
        "max_input_tokens": 200000,
        "max_output_tokens": 32000
    },
    "claude-opus-4-20250514": {
        "litellm_provider": "anthropic",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "cache_creation_input_token_cost": 1.875e-05,
        "max_tokens": 32000,
        "max_input_tokens": 200000,
        "max_output_tokens": 32000
    },
    "claude-opus-4-5-20251101": {
        "litellm_provider": "anthropic",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 2.5e-05,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": 6.25e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "claude-opus-4-5": {
        "litellm_provider": "anthropic",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 2.5e-05,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": 6.25e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "claude-opus-4-6": {
        "litellm_provider": "anthropic",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 2.5e-05,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": 6.25e-06,
        "max_tokens": 128000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 128000
    },
    "fast/claude-opus-4-6": {
        "litellm_provider": "anthropic",
        "mode": "chat",
        "input_cost_per_token": 3e-05,
        "output_cost_per_token": 0.00015,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": 6.25e-06,
        "max_tokens": 128000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 128000
    },
    "us/claude-opus-4-6": {
        "litellm_provider": "anthropic",
        "mode": "chat",
        "input_cost_per_token": 5.5e-06,
        "output_cost_per_token": 2.75e-05,
        "cache_read_input_token_cost": 5.5e-07,
        "cache_creation_input_token_cost": 6.875e-06,
        "max_tokens": 128000,
        "max_input_tokens": 200000,
        "max_output_tokens": 128000
    },
    "fast/us/claude-opus-4-6": {
        "litellm_provider": "anthropic",
        "mode": "chat",
        "input_cost_per_token": 3e-05,
        "output_cost_per_token": 0.00015,
        "cache_read_input_token_cost": 5.5e-07,
        "cache_creation_input_token_cost": 6.875e-06,
        "max_tokens": 128000,
        "max_input_tokens": 200000,
        "max_output_tokens": 128000
    },
    "claude-opus-4-6-20260205": {
        "litellm_provider": "anthropic",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 2.5e-05,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": 6.25e-06,
        "max_tokens": 128000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 128000
    },
    "fast/claude-opus-4-6-20260205": {
        "litellm_provider": "anthropic",
        "mode": "chat",
        "input_cost_per_token": 3e-05,
        "output_cost_per_token": 0.00015,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": 6.25e-06,
        "max_tokens": 128000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 128000
    },
    "us/claude-opus-4-6-20260205": {
        "litellm_provider": "anthropic",
        "mode": "chat",
        "input_cost_per_token": 5.5e-06,
        "output_cost_per_token": 2.75e-05,
        "cache_read_input_token_cost": 5.5e-07,
        "cache_creation_input_token_cost": 6.875e-06,
        "max_tokens": 128000,
        "max_input_tokens": 200000,
        "max_output_tokens": 128000
    },
    "claude-sonnet-4-20250514": {
        "litellm_provider": "anthropic",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 64000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000
    },
    "cloudflare/@cf/meta/llama-2-7b-chat-fp16": {
        "litellm_provider": "cloudflare",
        "mode": "chat",
        "input_cost_per_token": 1.923e-06,
        "output_cost_per_token": 1.923e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 3072,
        "max_input_tokens": 3072,
        "max_output_tokens": 3072
    },
    "cloudflare/@cf/meta/llama-2-7b-chat-int8": {
        "litellm_provider": "cloudflare",
        "mode": "chat",
        "input_cost_per_token": 1.923e-06,
        "output_cost_per_token": 1.923e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 2048,
        "max_output_tokens": 2048
    },
    "cloudflare/@cf/mistral/mistral-7b-instruct-v0.1": {
        "litellm_provider": "cloudflare",
        "mode": "chat",
        "input_cost_per_token": 1.923e-06,
        "output_cost_per_token": 1.923e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "cloudflare/@hf/thebloke/codellama-7b-instruct-awq": {
        "litellm_provider": "cloudflare",
        "mode": "chat",
        "input_cost_per_token": 1.923e-06,
        "output_cost_per_token": 1.923e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "code-bison": {
        "litellm_provider": "vertex_ai-code-text-models",
        "mode": "chat",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 1.25e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 6144,
        "max_output_tokens": 1024
    },
    "code-bison-32k@002": {
        "litellm_provider": "vertex_ai-code-text-models",
        "mode": "completion",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 1.25e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 6144,
        "max_output_tokens": 1024
    },
    "code-bison32k": {
        "litellm_provider": "vertex_ai-code-text-models",
        "mode": "completion",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 1.25e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 6144,
        "max_output_tokens": 1024
    },
    "code-bison@001": {
        "litellm_provider": "vertex_ai-code-text-models",
        "mode": "completion",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 1.25e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 6144,
        "max_output_tokens": 1024
    },
    "code-bison@002": {
        "litellm_provider": "vertex_ai-code-text-models",
        "mode": "completion",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 1.25e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 6144,
        "max_output_tokens": 1024
    },
    "code-gecko": {
        "litellm_provider": "vertex_ai-code-text-models",
        "mode": "completion",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 1.25e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 64,
        "max_input_tokens": 2048,
        "max_output_tokens": 64
    },
    "code-gecko-latest": {
        "litellm_provider": "vertex_ai-code-text-models",
        "mode": "completion",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 1.25e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 64,
        "max_input_tokens": 2048,
        "max_output_tokens": 64
    },
    "code-gecko@001": {
        "litellm_provider": "vertex_ai-code-text-models",
        "mode": "completion",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 1.25e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 64,
        "max_input_tokens": 2048,
        "max_output_tokens": 64
    },
    "code-gecko@002": {
        "litellm_provider": "vertex_ai-code-text-models",
        "mode": "completion",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 1.25e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 64,
        "max_input_tokens": 2048,
        "max_output_tokens": 64
    },
    "codechat-bison": {
        "litellm_provider": "vertex_ai-code-chat-models",
        "mode": "chat",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 1.25e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 6144,
        "max_output_tokens": 1024
    },
    "codechat-bison-32k": {
        "litellm_provider": "vertex_ai-code-chat-models",
        "mode": "chat",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 1.25e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 32000,
        "max_output_tokens": 8192
    },
    "codechat-bison-32k@002": {
        "litellm_provider": "vertex_ai-code-chat-models",
        "mode": "chat",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 1.25e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 32000,
        "max_output_tokens": 8192
    },
    "codechat-bison@001": {
        "litellm_provider": "vertex_ai-code-chat-models",
        "mode": "chat",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 1.25e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 6144,
        "max_output_tokens": 1024
    },
    "codechat-bison@002": {
        "litellm_provider": "vertex_ai-code-chat-models",
        "mode": "chat",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 1.25e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 6144,
        "max_output_tokens": 1024
    },
    "codechat-bison@latest": {
        "litellm_provider": "vertex_ai-code-chat-models",
        "mode": "chat",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 1.25e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 6144,
        "max_output_tokens": 1024
    },
    "codestral/codestral-2405": {
        "litellm_provider": "codestral",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191
    },
    "codestral/codestral-latest": {
        "litellm_provider": "codestral",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191
    },
    "codex-mini-latest": {
        "litellm_provider": "openai",
        "mode": "responses",
        "input_cost_per_token": 1.5e-06,
        "output_cost_per_token": 6e-06,
        "cache_read_input_token_cost": 3.75e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "cohere.command-light-text-v14": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "cohere.command-r-plus-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "cohere.command-r-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "cohere.command-text-v14": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 1.5e-06,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "cohere.embed-english-v3": {
        "litellm_provider": "bedrock",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 512,
        "max_input_tokens": 512,
        "max_output_tokens": null
    },
    "cohere.embed-multilingual-v3": {
        "litellm_provider": "bedrock",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 512,
        "max_input_tokens": 512,
        "max_output_tokens": null
    },
    "cohere.embed-v4:0": {
        "litellm_provider": "bedrock",
        "mode": "embedding",
        "input_cost_per_token": 1.2e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": null
    },
    "cohere/embed-v4.0": {
        "litellm_provider": "cohere",
        "mode": "embedding",
        "input_cost_per_token": 1.2e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": null
    },
    "cohere.rerank-v3-5:0": {
        "litellm_provider": "bedrock",
        "mode": "rerank",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "max_output_tokens": 32000
    },
    "command": {
        "litellm_provider": "cohere",
        "mode": "completion",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "command-a-03-2025": {
        "litellm_provider": "cohere_chat",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8000,
        "max_input_tokens": 256000,
        "max_output_tokens": 8000
    },
    "command-light": {
        "litellm_provider": "cohere_chat",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "command-nightly": {
        "litellm_provider": "cohere",
        "mode": "completion",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "command-r": {
        "litellm_provider": "cohere_chat",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "command-r-08-2024": {
        "litellm_provider": "cohere_chat",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "command-r-plus": {
        "litellm_provider": "cohere_chat",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "command-r-plus-08-2024": {
        "litellm_provider": "cohere_chat",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "command-r7b-12-2024": {
        "litellm_provider": "cohere_chat",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 3.75e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "computer-use-preview": {
        "litellm_provider": "azure",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.2e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 8192,
        "max_output_tokens": 1024
    },
    "dall-e-2": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "dall-e-3": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepseek-chat": {
        "litellm_provider": "deepseek",
        "mode": "chat",
        "input_cost_per_token": 2.8e-07,
        "output_cost_per_token": 4.2e-07,
        "cache_read_input_token_cost": 2.8e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 131072,
        "max_output_tokens": 8192
    },
    "deepseek-reasoner": {
        "litellm_provider": "deepseek",
        "mode": "chat",
        "input_cost_per_token": 2.8e-07,
        "output_cost_per_token": 4.2e-07,
        "cache_read_input_token_cost": 2.8e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 131072,
        "max_output_tokens": 65536
    },
    "dashscope/qwen-coder": {
        "litellm_provider": "dashscope",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 1000000,
        "max_output_tokens": 16384
    },
    "dashscope/qwen-flash": {
        "litellm_provider": "dashscope",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 997952,
        "max_output_tokens": 32768
    },
    "dashscope/qwen-flash-2025-07-28": {
        "litellm_provider": "dashscope",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 997952,
        "max_output_tokens": 32768
    },
    "dashscope/qwen-max": {
        "litellm_provider": "dashscope",
        "mode": "chat",
        "input_cost_per_token": 1.6e-06,
        "output_cost_per_token": 6.4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 30720,
        "max_output_tokens": 8192
    },
    "dashscope/qwen-plus": {
        "litellm_provider": "dashscope",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 129024,
        "max_output_tokens": 16384
    },
    "dashscope/qwen-plus-2025-01-25": {
        "litellm_provider": "dashscope",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 129024,
        "max_output_tokens": 8192
    },
    "dashscope/qwen-plus-2025-04-28": {
        "litellm_provider": "dashscope",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 129024,
        "max_output_tokens": 16384
    },
    "dashscope/qwen-plus-2025-07-14": {
        "litellm_provider": "dashscope",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 129024,
        "max_output_tokens": 16384
    },
    "dashscope/qwen-plus-2025-07-28": {
        "litellm_provider": "dashscope",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 997952,
        "max_output_tokens": 32768
    },
    "dashscope/qwen-plus-2025-09-11": {
        "litellm_provider": "dashscope",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 997952,
        "max_output_tokens": 32768
    },
    "dashscope/qwen-plus-latest": {
        "litellm_provider": "dashscope",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 997952,
        "max_output_tokens": 32768
    },
    "dashscope/qwen-turbo": {
        "litellm_provider": "dashscope",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 129024,
        "max_output_tokens": 16384
    },
    "dashscope/qwen-turbo-2024-11-01": {
        "litellm_provider": "dashscope",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192
    },
    "dashscope/qwen-turbo-2025-04-28": {
        "litellm_provider": "dashscope",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 1000000,
        "max_output_tokens": 16384
    },
    "dashscope/qwen-turbo-latest": {
        "litellm_provider": "dashscope",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 1000000,
        "max_output_tokens": 16384
    },
    "dashscope/qwen3-30b-a3b": {
        "litellm_provider": "dashscope",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 129024,
        "max_output_tokens": 16384
    },
    "dashscope/qwen3-coder-flash": {
        "litellm_provider": "dashscope",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 997952,
        "max_output_tokens": 65536
    },
    "dashscope/qwen3-coder-flash-2025-07-28": {
        "litellm_provider": "dashscope",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 997952,
        "max_output_tokens": 65536
    },
    "dashscope/qwen3-coder-plus": {
        "litellm_provider": "dashscope",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 997952,
        "max_output_tokens": 65536
    },
    "dashscope/qwen3-coder-plus-2025-07-22": {
        "litellm_provider": "dashscope",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 997952,
        "max_output_tokens": 65536
    },
    "dashscope/qwen3-max-preview": {
        "litellm_provider": "dashscope",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 258048,
        "max_output_tokens": 65536
    },
    "dashscope/qwq-plus": {
        "litellm_provider": "dashscope",
        "mode": "chat",
        "input_cost_per_token": 8e-07,
        "output_cost_per_token": 2.4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 98304,
        "max_output_tokens": 8192
    },
    "databricks/databricks-bge-large-en": {
        "litellm_provider": "databricks",
        "mode": "embedding",
        "input_cost_per_token": 1.0003e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 512,
        "max_input_tokens": 512,
        "max_output_tokens": null
    },
    "databricks/databricks-claude-3-7-sonnet": {
        "litellm_provider": "databricks",
        "mode": "chat",
        "input_cost_per_token": 2.9999900000000002e-06,
        "output_cost_per_token": 1.5000020000000002e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 200000,
        "max_output_tokens": 128000
    },
    "databricks/databricks-claude-haiku-4-5": {
        "litellm_provider": "databricks",
        "mode": "chat",
        "input_cost_per_token": 1.00002e-06,
        "output_cost_per_token": 5.00003e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "databricks/databricks-claude-opus-4": {
        "litellm_provider": "databricks",
        "mode": "chat",
        "input_cost_per_token": 1.5000020000000002e-05,
        "output_cost_per_token": 7.500003000000001e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 200000,
        "max_output_tokens": 32000
    },
    "databricks/databricks-claude-opus-4-1": {
        "litellm_provider": "databricks",
        "mode": "chat",
        "input_cost_per_token": 1.5000020000000002e-05,
        "output_cost_per_token": 7.500003000000001e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 200000,
        "max_output_tokens": 32000
    },
    "databricks/databricks-claude-opus-4-5": {
        "litellm_provider": "databricks",
        "mode": "chat",
        "input_cost_per_token": 5.00003e-06,
        "output_cost_per_token": 2.5000010000000002e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "databricks/databricks-claude-sonnet-4": {
        "litellm_provider": "databricks",
        "mode": "chat",
        "input_cost_per_token": 2.9999900000000002e-06,
        "output_cost_per_token": 1.5000020000000002e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "databricks/databricks-claude-sonnet-4-1": {
        "litellm_provider": "databricks",
        "mode": "chat",
        "input_cost_per_token": 2.9999900000000002e-06,
        "output_cost_per_token": 1.5000020000000002e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "databricks/databricks-claude-sonnet-4-5": {
        "litellm_provider": "databricks",
        "mode": "chat",
        "input_cost_per_token": 2.9999900000000002e-06,
        "output_cost_per_token": 1.5000020000000002e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "databricks/databricks-gemini-2-5-flash": {
        "litellm_provider": "databricks",
        "mode": "chat",
        "input_cost_per_token": 3.0001999999999996e-07,
        "output_cost_per_token": 2.49998e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "databricks/databricks-gemini-2-5-pro": {
        "litellm_provider": "databricks",
        "mode": "chat",
        "input_cost_per_token": 1.24999e-06,
        "output_cost_per_token": 9.999990000000002e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65536
    },
    "databricks/databricks-gemma-3-12b": {
        "litellm_provider": "databricks",
        "mode": "chat",
        "input_cost_per_token": 1.5000999999999998e-07,
        "output_cost_per_token": 5.0001e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 128000,
        "max_output_tokens": 32000
    },
    "databricks/databricks-gpt-5": {
        "litellm_provider": "databricks",
        "mode": "chat",
        "input_cost_per_token": 1.24999e-06,
        "output_cost_per_token": 9.999990000000002e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "databricks/databricks-gpt-5-1": {
        "litellm_provider": "databricks",
        "mode": "chat",
        "input_cost_per_token": 1.24999e-06,
        "output_cost_per_token": 9.999990000000002e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "databricks/databricks-gpt-5-mini": {
        "litellm_provider": "databricks",
        "mode": "chat",
        "input_cost_per_token": 2.4997000000000006e-07,
        "output_cost_per_token": 1.9999700000000004e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "databricks/databricks-gpt-5-nano": {
        "litellm_provider": "databricks",
        "mode": "chat",
        "input_cost_per_token": 4.998e-08,
        "output_cost_per_token": 3.9998000000000007e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "databricks/databricks-gpt-oss-120b": {
        "litellm_provider": "databricks",
        "mode": "chat",
        "input_cost_per_token": 1.5000999999999998e-07,
        "output_cost_per_token": 5.9997e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "databricks/databricks-gpt-oss-20b": {
        "litellm_provider": "databricks",
        "mode": "chat",
        "input_cost_per_token": 7e-08,
        "output_cost_per_token": 3.0001999999999996e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "databricks/databricks-gte-large-en": {
        "litellm_provider": "databricks",
        "mode": "embedding",
        "input_cost_per_token": 1.2999000000000001e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": null
    },
    "databricks/databricks-llama-2-70b-chat": {
        "litellm_provider": "databricks",
        "mode": "chat",
        "input_cost_per_token": 5.0001e-07,
        "output_cost_per_token": 1.5000300000000002e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "databricks/databricks-llama-4-maverick": {
        "litellm_provider": "databricks",
        "mode": "chat",
        "input_cost_per_token": 5.0001e-07,
        "output_cost_per_token": 1.5000300000000002e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "databricks/databricks-meta-llama-3-1-405b-instruct": {
        "litellm_provider": "databricks",
        "mode": "chat",
        "input_cost_per_token": 5.00003e-06,
        "output_cost_per_token": 1.5000020000000002e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "databricks/databricks-meta-llama-3-1-8b-instruct": {
        "litellm_provider": "databricks",
        "mode": "chat",
        "input_cost_per_token": 1.5000999999999998e-07,
        "output_cost_per_token": 4.5003000000000007e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 200000,
        "max_output_tokens": 128000
    },
    "databricks/databricks-meta-llama-3-3-70b-instruct": {
        "litellm_provider": "databricks",
        "mode": "chat",
        "input_cost_per_token": 5.0001e-07,
        "output_cost_per_token": 1.5000300000000002e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "databricks/databricks-meta-llama-3-70b-instruct": {
        "litellm_provider": "databricks",
        "mode": "chat",
        "input_cost_per_token": 1.00002e-06,
        "output_cost_per_token": 2.9999900000000002e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "databricks/databricks-mixtral-8x7b-instruct": {
        "litellm_provider": "databricks",
        "mode": "chat",
        "input_cost_per_token": 5.0001e-07,
        "output_cost_per_token": 1.00002e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "databricks/databricks-mpt-30b-instruct": {
        "litellm_provider": "databricks",
        "mode": "chat",
        "input_cost_per_token": 1.00002e-06,
        "output_cost_per_token": 1.00002e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "databricks/databricks-mpt-7b-instruct": {
        "litellm_provider": "databricks",
        "mode": "chat",
        "input_cost_per_token": 5.0001e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "dataforseo/search": {
        "litellm_provider": "dataforseo",
        "mode": "search",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "davinci-002": {
        "litellm_provider": "text-completion-openai",
        "mode": "completion",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 16384,
        "max_output_tokens": 4096
    },
    "deepgram/base": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/base-conversationalai": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/base-finance": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/base-general": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/base-meeting": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/base-phonecall": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/base-video": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/base-voicemail": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/enhanced": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/enhanced-finance": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/enhanced-general": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/enhanced-meeting": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/enhanced-phonecall": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/nova": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/nova-2": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/nova-2-atc": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/nova-2-automotive": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/nova-2-conversationalai": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/nova-2-drivethru": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/nova-2-finance": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/nova-2-general": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/nova-2-meeting": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/nova-2-phonecall": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/nova-2-video": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/nova-2-voicemail": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/nova-3": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/nova-3-general": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/nova-3-medical": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/nova-general": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/nova-phonecall": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/whisper": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/whisper-base": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/whisper-large": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/whisper-medium": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/whisper-small": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepgram/whisper-tiny": {
        "litellm_provider": "deepgram",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "deepinfra/Gryphe/MythoMax-L2-13b": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 8e-08,
        "output_cost_per_token": 9e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "deepinfra/NousResearch/Hermes-3-Llama-3.1-405B": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 1e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "deepinfra/NousResearch/Hermes-3-Llama-3.1-70B": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "deepinfra/Qwen/QwQ-32B": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "deepinfra/Qwen/Qwen2.5-72B-Instruct": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 1.2e-07,
        "output_cost_per_token": 3.9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "deepinfra/Qwen/Qwen2.5-7B-Instruct": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 4e-08,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "deepinfra/Qwen/Qwen2.5-VL-32B-Instruct": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "deepinfra/Qwen/Qwen3-14B": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 6e-08,
        "output_cost_per_token": 2.4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": 40960
    },
    "deepinfra/Qwen/Qwen3-235B-A22B": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 1.8e-07,
        "output_cost_per_token": 5.4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": 40960
    },
    "deepinfra/Qwen/Qwen3-235B-A22B-Instruct-2507": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 9e-08,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "deepinfra/Qwen/Qwen3-235B-A22B-Thinking-2507": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 2.9e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "deepinfra/Qwen/Qwen3-30B-A3B": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 8e-08,
        "output_cost_per_token": 2.9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": 40960
    },
    "deepinfra/Qwen/Qwen3-32B": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 2.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": 40960
    },
    "deepinfra/Qwen/Qwen3-Coder-480B-A35B-Instruct": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 1.6e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "deepinfra/Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 2.9e-07,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "deepinfra/Qwen/Qwen3-Next-80B-A3B-Instruct": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 1.4e-07,
        "output_cost_per_token": 1.4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "deepinfra/Qwen/Qwen3-Next-80B-A3B-Thinking": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 1.4e-07,
        "output_cost_per_token": 1.4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "deepinfra/Sao10K/L3-8B-Lunaris-v1-Turbo": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 4e-08,
        "output_cost_per_token": 5e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "deepinfra/Sao10K/L3.1-70B-Euryale-v2.2": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 6.5e-07,
        "output_cost_per_token": 7.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "deepinfra/Sao10K/L3.3-70B-Euryale-v2.3": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 6.5e-07,
        "output_cost_per_token": 7.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "deepinfra/allenai/olmOCR-7B-0725-FP8": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 2.7e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "deepinfra/anthropic/claude-3-7-sonnet-latest": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 3.3e-06,
        "output_cost_per_token": 1.65e-05,
        "cache_read_input_token_cost": 3.3e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 200000,
        "max_input_tokens": 200000,
        "max_output_tokens": 200000
    },
    "deepinfra/anthropic/claude-4-opus": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 1.65e-05,
        "output_cost_per_token": 8.25e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 200000,
        "max_input_tokens": 200000,
        "max_output_tokens": 200000
    },
    "deepinfra/anthropic/claude-4-sonnet": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 3.3e-06,
        "output_cost_per_token": 1.65e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 200000,
        "max_input_tokens": 200000,
        "max_output_tokens": 200000
    },
    "deepinfra/deepseek-ai/DeepSeek-R1": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 7e-07,
        "output_cost_per_token": 2.4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840
    },
    "deepinfra/deepseek-ai/DeepSeek-R1-0528": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 2.15e-06,
        "cache_read_input_token_cost": 4e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840
    },
    "deepinfra/deepseek-ai/DeepSeek-R1-0528-Turbo": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 3e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "deepinfra/deepseek-ai/DeepSeek-R1-Distill-Llama-70B": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "deepinfra/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 2.7e-07,
        "output_cost_per_token": 2.7e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "deepinfra/deepseek-ai/DeepSeek-R1-Turbo": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 3e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": 40960
    },
    "deepinfra/deepseek-ai/DeepSeek-V3": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 3.8e-07,
        "output_cost_per_token": 8.9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840
    },
    "deepinfra/deepseek-ai/DeepSeek-V3-0324": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 8.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840
    },
    "deepinfra/deepseek-ai/DeepSeek-V3.1": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 2.7e-07,
        "output_cost_per_token": 1e-06,
        "cache_read_input_token_cost": 2.16e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840
    },
    "deepinfra/deepseek-ai/DeepSeek-V3.1-Terminus": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 2.7e-07,
        "output_cost_per_token": 1e-06,
        "cache_read_input_token_cost": 2.16e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840
    },
    "deepinfra/google/gemini-2.0-flash-001": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1000000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 1000000
    },
    "deepinfra/google/gemini-2.5-flash": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1000000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 1000000
    },
    "deepinfra/google/gemini-2.5-pro": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1000000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 1000000
    },
    "deepinfra/google/gemma-3-12b-it": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "deepinfra/google/gemma-3-27b-it": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 9e-08,
        "output_cost_per_token": 1.6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "deepinfra/google/gemma-3-4b-it": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 4e-08,
        "output_cost_per_token": 8e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "deepinfra/meta-llama/Llama-3.2-11B-Vision-Instruct": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 4.9e-08,
        "output_cost_per_token": 4.9e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "deepinfra/meta-llama/Llama-3.2-3B-Instruct": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 2e-08,
        "output_cost_per_token": 2e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "deepinfra/meta-llama/Llama-3.3-70B-Instruct": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 2.3e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "deepinfra/meta-llama/Llama-3.3-70B-Instruct-Turbo": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 1.3e-07,
        "output_cost_per_token": 3.9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "deepinfra/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1048576,
        "max_input_tokens": 1048576,
        "max_output_tokens": 1048576
    },
    "deepinfra/meta-llama/Llama-4-Scout-17B-16E-Instruct": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 8e-08,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 327680,
        "max_input_tokens": 327680,
        "max_output_tokens": 327680
    },
    "deepinfra/meta-llama/Llama-Guard-3-8B": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 5.5e-08,
        "output_cost_per_token": 5.5e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "deepinfra/meta-llama/Llama-Guard-4-12B": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 1.8e-07,
        "output_cost_per_token": 1.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840
    },
    "deepinfra/meta-llama/Meta-Llama-3-8B-Instruct": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 3e-08,
        "output_cost_per_token": 6e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "deepinfra/meta-llama/Meta-Llama-3.1-70B-Instruct": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "deepinfra/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 2.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "deepinfra/meta-llama/Meta-Llama-3.1-8B-Instruct": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 3e-08,
        "output_cost_per_token": 5e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "deepinfra/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 2e-08,
        "output_cost_per_token": 3e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "deepinfra/microsoft/WizardLM-2-8x22B": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 4.8e-07,
        "output_cost_per_token": 4.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 65536,
        "max_output_tokens": 65536
    },
    "deepinfra/microsoft/phi-4": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 7e-08,
        "output_cost_per_token": 1.4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "deepinfra/mistralai/Mistral-Nemo-Instruct-2407": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 2e-08,
        "output_cost_per_token": 4e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "deepinfra/mistralai/Mistral-Small-24B-Instruct-2501": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 8e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "deepinfra/mistralai/Mistral-Small-3.2-24B-Instruct-2506": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 7.5e-08,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "deepinfra/mistralai/Mixtral-8x7B-Instruct-v0.1": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "deepinfra/moonshotai/Kimi-K2-Instruct": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "deepinfra/moonshotai/Kimi-K2-Instruct-0905": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": 4e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "deepinfra/nvidia/Llama-3.1-Nemotron-70B-Instruct": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "deepinfra/nvidia/Llama-3.3-Nemotron-Super-49B-v1.5": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "deepinfra/nvidia/NVIDIA-Nemotron-Nano-9B-v2": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 4e-08,
        "output_cost_per_token": 1.6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "deepinfra/openai/gpt-oss-120b": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 4.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "deepinfra/openai/gpt-oss-20b": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 4e-08,
        "output_cost_per_token": 1.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "deepinfra/zai-org/GLM-4.5": {
        "litellm_provider": "deepinfra",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 1.6e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "deepseek/deepseek-chat": {
        "litellm_provider": "deepseek",
        "mode": "chat",
        "input_cost_per_token": 2.8e-07,
        "output_cost_per_token": 4.2e-07,
        "cache_read_input_token_cost": 2.8e-08,
        "cache_creation_input_token_cost": 0.0,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "deepseek/deepseek-coder": {
        "litellm_provider": "deepseek",
        "mode": "chat",
        "input_cost_per_token": 1.4e-07,
        "output_cost_per_token": 2.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "deepseek/deepseek-r1": {
        "litellm_provider": "deepseek",
        "mode": "chat",
        "input_cost_per_token": 5.5e-07,
        "output_cost_per_token": 2.19e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 65536,
        "max_output_tokens": 8192
    },
    "deepseek/deepseek-reasoner": {
        "litellm_provider": "deepseek",
        "mode": "chat",
        "input_cost_per_token": 2.8e-07,
        "output_cost_per_token": 4.2e-07,
        "cache_read_input_token_cost": 2.8e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "deepseek/deepseek-v3": {
        "litellm_provider": "deepseek",
        "mode": "chat",
        "input_cost_per_token": 2.7e-07,
        "output_cost_per_token": 1.1e-06,
        "cache_read_input_token_cost": 7e-08,
        "cache_creation_input_token_cost": 0.0,
        "max_tokens": 8192,
        "max_input_tokens": 65536,
        "max_output_tokens": 8192
    },
    "deepseek/deepseek-v3.2": {
        "litellm_provider": "deepseek",
        "mode": "chat",
        "input_cost_per_token": 2.8e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840
    },
    "deepseek.v3-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 5.8e-07,
        "output_cost_per_token": 1.68e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 81920,
        "max_input_tokens": 163840,
        "max_output_tokens": 81920
    },
    "dolphin": {
        "litellm_provider": "nlp_cloud",
        "mode": "completion",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "deepseek-v3-2-251201": {
        "litellm_provider": "volcengine",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 98304,
        "max_output_tokens": 32768
    },
    "glm-4-7-251222": {
        "litellm_provider": "volcengine",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 204800,
        "max_output_tokens": 131072
    },
    "kimi-k2-thinking-251104": {
        "litellm_provider": "volcengine",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 229376,
        "max_output_tokens": 32768
    },
    "doubao-embedding": {
        "litellm_provider": "volcengine",
        "mode": "embedding",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": null
    },
    "doubao-embedding-large": {
        "litellm_provider": "volcengine",
        "mode": "embedding",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": null
    },
    "doubao-embedding-large-text-240915": {
        "litellm_provider": "volcengine",
        "mode": "embedding",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": null
    },
    "doubao-embedding-large-text-250515": {
        "litellm_provider": "volcengine",
        "mode": "embedding",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": null
    },
    "doubao-embedding-text-240715": {
        "litellm_provider": "volcengine",
        "mode": "embedding",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": null
    },
    "exa_ai/search": {
        "litellm_provider": "exa_ai",
        "mode": "search",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "firecrawl/search": {
        "litellm_provider": "firecrawl",
        "mode": "search",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "perplexity/search": {
        "litellm_provider": "perplexity",
        "mode": "search",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "searxng/search": {
        "litellm_provider": "searxng",
        "mode": "search",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "elevenlabs/scribe_v1": {
        "litellm_provider": "elevenlabs",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "elevenlabs/scribe_v1_experimental": {
        "litellm_provider": "elevenlabs",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "elevenlabs/eleven_v3": {
        "litellm_provider": "elevenlabs",
        "mode": "audio_speech",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "elevenlabs/eleven_multilingual_v2": {
        "litellm_provider": "elevenlabs",
        "mode": "audio_speech",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "embed-english-light-v2.0": {
        "litellm_provider": "cohere",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 1024,
        "max_output_tokens": null
    },
    "embed-english-light-v3.0": {
        "litellm_provider": "cohere",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 1024,
        "max_output_tokens": null
    },
    "embed-english-v2.0": {
        "litellm_provider": "cohere",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": null
    },
    "embed-english-v3.0": {
        "litellm_provider": "cohere",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 1024,
        "max_output_tokens": null
    },
    "embed-multilingual-v2.0": {
        "litellm_provider": "cohere",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 768,
        "max_input_tokens": 768,
        "max_output_tokens": null
    },
    "embed-multilingual-v3.0": {
        "litellm_provider": "cohere",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 1024,
        "max_output_tokens": null
    },
    "embed-multilingual-light-v3.0": {
        "litellm_provider": "cohere",
        "mode": "embedding",
        "input_cost_per_token": 0.0001,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 1024,
        "max_output_tokens": null
    },
    "eu.amazon.nova-lite-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 7.8e-08,
        "output_cost_per_token": 3.12e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 10000,
        "max_input_tokens": 300000,
        "max_output_tokens": 10000
    },
    "eu.amazon.nova-micro-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 4.6e-08,
        "output_cost_per_token": 1.84e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 10000,
        "max_input_tokens": 128000,
        "max_output_tokens": 10000
    },
    "eu.amazon.nova-pro-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 1.05e-06,
        "output_cost_per_token": 4.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 10000,
        "max_input_tokens": 300000,
        "max_output_tokens": 10000
    },
    "eu.anthropic.claude-3-5-haiku-20241022-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 1.25e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "eu.anthropic.claude-haiku-4-5-20251001-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 1.1e-06,
        "output_cost_per_token": 5.5e-06,
        "cache_read_input_token_cost": 1.1e-07,
        "cache_creation_input_token_cost": 1.375e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "eu.anthropic.claude-3-5-sonnet-20240620-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "eu.anthropic.claude-3-5-sonnet-20241022-v2:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "eu.anthropic.claude-3-7-sonnet-20250219-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "eu.anthropic.claude-3-haiku-20240307-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 1.25e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "eu.anthropic.claude-3-opus-20240229-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "eu.anthropic.claude-3-sonnet-20240229-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "eu.anthropic.claude-opus-4-1-20250805-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "cache_creation_input_token_cost": 1.875e-05,
        "max_tokens": 32000,
        "max_input_tokens": 200000,
        "max_output_tokens": 32000
    },
    "eu.anthropic.claude-opus-4-20250514-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "cache_creation_input_token_cost": 1.875e-05,
        "max_tokens": 32000,
        "max_input_tokens": 200000,
        "max_output_tokens": 32000
    },
    "eu.anthropic.claude-sonnet-4-20250514-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 64000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000
    },
    "eu.anthropic.claude-sonnet-4-5-20250929-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 3.3e-06,
        "output_cost_per_token": 1.65e-05,
        "cache_read_input_token_cost": 3.3e-07,
        "cache_creation_input_token_cost": 4.125e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "eu.meta.llama3-2-1b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 1.3e-07,
        "output_cost_per_token": 1.3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "eu.meta.llama3-2-3b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 1.9e-07,
        "output_cost_per_token": 1.9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "eu.mistral.pixtral-large-2502-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 6e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "fal_ai/bria/text-to-image/3.2": {
        "litellm_provider": "fal_ai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "fal_ai/fal-ai/flux-pro/v1.1": {
        "litellm_provider": "fal_ai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "fal_ai/fal-ai/flux-pro/v1.1-ultra": {
        "litellm_provider": "fal_ai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "fal_ai/fal-ai/flux/schnell": {
        "litellm_provider": "fal_ai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "fal_ai/fal-ai/bytedance/seedream/v3/text-to-image": {
        "litellm_provider": "fal_ai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "fal_ai/fal-ai/bytedance/dreamina/v3.1/text-to-image": {
        "litellm_provider": "fal_ai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "fal_ai/fal-ai/ideogram/v3": {
        "litellm_provider": "fal_ai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "fal_ai/fal-ai/imagen4/preview": {
        "litellm_provider": "fal_ai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "fal_ai/fal-ai/imagen4/preview/fast": {
        "litellm_provider": "fal_ai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "fal_ai/fal-ai/imagen4/preview/ultra": {
        "litellm_provider": "fal_ai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "fal_ai/fal-ai/recraft/v3/text-to-image": {
        "litellm_provider": "fal_ai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "fal_ai/fal-ai/stable-diffusion-v35-medium": {
        "litellm_provider": "fal_ai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "featherless_ai/featherless-ai/Qwerky-72B": {
        "litellm_provider": "featherless_ai",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 32768,
        "max_output_tokens": 4096
    },
    "featherless_ai/featherless-ai/Qwerky-QwQ-32B": {
        "litellm_provider": "featherless_ai",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 32768,
        "max_output_tokens": 4096
    },
    "fireworks-ai-4.1b-to-16b": {
        "litellm_provider": "fireworks_ai",
        "mode": null,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "fireworks-ai-56b-to-176b": {
        "litellm_provider": "fireworks_ai",
        "mode": null,
        "input_cost_per_token": 1.2e-06,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "fireworks-ai-above-16b": {
        "litellm_provider": "fireworks_ai",
        "mode": null,
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "fireworks-ai-default": {
        "litellm_provider": "fireworks_ai",
        "mode": null,
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "fireworks-ai-embedding-150m-to-350m": {
        "litellm_provider": "fireworks_ai-embedding-models",
        "mode": null,
        "input_cost_per_token": 1.6e-08,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "fireworks-ai-embedding-up-to-150m": {
        "litellm_provider": "fireworks_ai-embedding-models",
        "mode": null,
        "input_cost_per_token": 8e-09,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "fireworks-ai-moe-up-to-56b": {
        "litellm_provider": "fireworks_ai",
        "mode": null,
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "fireworks-ai-up-to-4b": {
        "litellm_provider": "fireworks_ai",
        "mode": null,
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "fireworks_ai/WhereIsAI/UAE-Large-V1": {
        "litellm_provider": "fireworks_ai-embedding-models",
        "mode": "embedding",
        "input_cost_per_token": 1.6e-08,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 512,
        "max_input_tokens": 512,
        "max_output_tokens": null
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1.2e-06,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 65536,
        "max_output_tokens": 65536
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 8e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 20480,
        "max_input_tokens": 128000,
        "max_output_tokens": 20480
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-0528": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 8e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 160000,
        "max_input_tokens": 160000,
        "max_output_tokens": 160000
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-basic": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 5.5e-07,
        "output_cost_per_token": 2.19e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 20480,
        "max_input_tokens": 128000,
        "max_output_tokens": 20480
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v3": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v3-0324": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v3p1": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 5.6e-07,
        "output_cost_per_token": 1.68e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v3p1-terminus": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 5.6e-07,
        "output_cost_per_token": 1.68e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v3p2": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 5.6e-07,
        "output_cost_per_token": 1.68e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840
    },
    "fireworks_ai/accounts/fireworks/models/firefunction-v2": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "fireworks_ai/accounts/fireworks/models/glm-4p5": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 5.5e-07,
        "output_cost_per_token": 2.19e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 96000,
        "max_input_tokens": 128000,
        "max_output_tokens": 96000
    },
    "fireworks_ai/accounts/fireworks/models/glm-4p5-air": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2.2e-07,
        "output_cost_per_token": 8.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 96000,
        "max_input_tokens": 128000,
        "max_output_tokens": 96000
    },
    "fireworks_ai/accounts/fireworks/models/glm-4p6": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 5.5e-07,
        "output_cost_per_token": 2.19e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 202800,
        "max_input_tokens": 202800,
        "max_output_tokens": 202800
    },
    "fireworks_ai/accounts/fireworks/models/gpt-oss-120b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/gpt-oss-20b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/kimi-k2-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 131072,
        "max_output_tokens": 16384
    },
    "fireworks_ai/accounts/fireworks/models/kimi-k2-instruct-0905": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 262144,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/kimi-k2-thinking": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p1-405b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 3e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p1-8b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p2-11b-vision-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p2-1b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p2-3b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p2-90b-vision-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "fireworks_ai/accounts/fireworks/models/llama4-maverick-instruct-basic": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2.2e-07,
        "output_cost_per_token": 8.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/llama4-scout-instruct-basic": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct-hf": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1.2e-06,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 65536,
        "max_output_tokens": 65536
    },
    "fireworks_ai/accounts/fireworks/models/qwen2-72b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/yi-large": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 3e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/nomic-ai/nomic-embed-text-v1": {
        "litellm_provider": "fireworks_ai-embedding-models",
        "mode": "embedding",
        "input_cost_per_token": 8e-09,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": null
    },
    "fireworks_ai/nomic-ai/nomic-embed-text-v1.5": {
        "litellm_provider": "fireworks_ai-embedding-models",
        "mode": "embedding",
        "input_cost_per_token": 8e-09,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": null
    },
    "fireworks_ai/thenlper/gte-base": {
        "litellm_provider": "fireworks_ai-embedding-models",
        "mode": "embedding",
        "input_cost_per_token": 8e-09,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 512,
        "max_input_tokens": 512,
        "max_output_tokens": null
    },
    "fireworks_ai/thenlper/gte-large": {
        "litellm_provider": "fireworks_ai-embedding-models",
        "mode": "embedding",
        "input_cost_per_token": 1.6e-08,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 512,
        "max_input_tokens": 512,
        "max_output_tokens": null
    },
    "friendliai/meta-llama-3.1-70b-instruct": {
        "litellm_provider": "friendliai",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "friendliai/meta-llama-3.1-8b-instruct": {
        "litellm_provider": "friendliai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "ft:babbage-002": {
        "litellm_provider": "text-completion-openai",
        "mode": "completion",
        "input_cost_per_token": 1.6e-06,
        "output_cost_per_token": 1.6e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 16384,
        "max_output_tokens": 4096
    },
    "ft:davinci-002": {
        "litellm_provider": "text-completion-openai",
        "mode": "completion",
        "input_cost_per_token": 1.2e-05,
        "output_cost_per_token": 1.2e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 16384,
        "max_output_tokens": 4096
    },
    "ft:gpt-3.5-turbo": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 6e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 16385,
        "max_output_tokens": 4096
    },
    "ft:gpt-3.5-turbo-0125": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 6e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 16385,
        "max_output_tokens": 4096
    },
    "ft:gpt-3.5-turbo-0613": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 6e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "ft:gpt-3.5-turbo-1106": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 6e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 16385,
        "max_output_tokens": 4096
    },
    "ft:gpt-4-0613": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 3e-05,
        "output_cost_per_token": 6e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096
    },
    "ft:gpt-4o-2024-08-06": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 3.75e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 1.875e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "ft:gpt-4o-2024-11-20": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 3.75e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": 1.875e-06,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "ft:gpt-4o-mini-2024-07-18": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": 1.5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "ft:gpt-4.1-2025-04-14": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.2e-05,
        "cache_read_input_token_cost": 7.5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768
    },
    "ft:gpt-4.1-mini-2025-04-14": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 8e-07,
        "output_cost_per_token": 3.2e-06,
        "cache_read_input_token_cost": 2e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768
    },
    "ft:gpt-4.1-nano-2025-04-14": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 8e-07,
        "cache_read_input_token_cost": 5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768
    },
    "ft:o4-mini-2025-04-16": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 4e-06,
        "output_cost_per_token": 1.6e-05,
        "cache_read_input_token_cost": 1e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "gemini-1.0-pro": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 32760,
        "max_output_tokens": 8192
    },
    "gemini-1.0-pro-001": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 32760,
        "max_output_tokens": 8192
    },
    "gemini-1.0-pro-002": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 32760,
        "max_output_tokens": 8192
    },
    "gemini-1.0-pro-vision": {
        "litellm_provider": "vertex_ai-vision-models",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 16384,
        "max_output_tokens": 2048
    },
    "gemini-1.0-pro-vision-001": {
        "litellm_provider": "vertex_ai-vision-models",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 16384,
        "max_output_tokens": 2048
    },
    "gemini-1.0-ultra": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 8192,
        "max_output_tokens": 2048
    },
    "gemini-1.0-ultra-001": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 8192,
        "max_output_tokens": 2048
    },
    "gemini-1.5-flash": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 7.5e-08,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192
    },
    "gemini-1.5-flash-001": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 7.5e-08,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192
    },
    "gemini-1.5-flash-002": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 7.5e-08,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192
    },
    "gemini-1.5-flash-exp-0827": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 4.688e-09,
        "output_cost_per_token": 4.6875e-09,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192
    },
    "gemini-1.5-flash-preview-0514": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 7.5e-08,
        "output_cost_per_token": 4.6875e-09,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192
    },
    "gemini-1.5-pro": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192
    },
    "gemini-1.5-pro-001": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192
    },
    "gemini-1.5-pro-002": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192
    },
    "gemini-1.5-pro-preview-0215": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 7.8125e-08,
        "output_cost_per_token": 3.125e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192
    },
    "gemini-1.5-pro-preview-0409": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 7.8125e-08,
        "output_cost_per_token": 3.125e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192
    },
    "gemini-1.5-pro-preview-0514": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 7.8125e-08,
        "output_cost_per_token": 3.125e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192
    },
    "gemini-2.0-flash": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": 2.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192
    },
    "gemini-2.0-flash-001": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": 3.75e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192
    },
    "gemini-2.0-flash-exp": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": 3.75e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192
    },
    "gemini-2.0-flash-lite": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 7.5e-08,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": 1.875e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192
    },
    "gemini-2.0-flash-lite-001": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 7.5e-08,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": 1.875e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192
    },
    "gemini-2.0-flash-live-preview-04-09": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": 7.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini-2.0-flash-preview-image-generation": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": 2.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192
    },
    "gemini-2.0-flash-thinking-exp": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": 0.0,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192
    },
    "gemini-2.0-flash-thinking-exp-01-21": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": 0.0,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65536
    },
    "gemini-2.0-pro-exp-02-05": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 3.125e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192
    },
    "gemini-2.5-flash": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": 3e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini-2.5-flash-image": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "image_generation",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": 3e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "gemini-2.5-flash-image-preview": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "image_generation",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 3e-05,
        "cache_read_input_token_cost": 7.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini-3-pro-image-preview": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "image_generation",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 1.2e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 65536,
        "max_output_tokens": 32768
    },
    "deep-research-pro-preview-12-2025": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "image_generation",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 1.2e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 65536,
        "max_output_tokens": 32768
    },
    "gemini-2.5-flash-lite": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": 1e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini-2.5-flash-lite-preview-09-2025": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": 1e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini-2.5-flash-preview-09-2025": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": 7.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini-live-2.5-flash-preview-native-audio-09-2025": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": 7.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini/gemini-live-2.5-flash-preview-native-audio-09-2025": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": 7.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini-2.5-flash-lite-preview-06-17": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": 2.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini-2.5-flash-preview-04-17": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": 3.75e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini-2.5-flash-preview-05-20": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": 7.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini-2.5-pro": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini-3-pro-preview": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 1.2e-05,
        "cache_read_input_token_cost": 2e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "vertex_ai/gemini-3-pro-preview": {
        "litellm_provider": "vertex_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 1.2e-05,
        "cache_read_input_token_cost": 2e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "vertex_ai/gemini-3-flash-preview": {
        "litellm_provider": "vertex_ai",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 3e-06,
        "cache_read_input_token_cost": 5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini-2.5-pro-exp-03-25": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini-2.5-pro-preview-03-25": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini-2.5-pro-preview-05-06": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini-2.5-pro-preview-06-05": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini-2.5-pro-preview-tts": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini-robotics-er-1.5-preview": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": 0,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini/gemini-robotics-er-1.5-preview": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": 0,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini-2.5-computer-use-preview-10-2025": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 64000,
        "max_input_tokens": 128000,
        "max_output_tokens": 64000
    },
    "gemini-embedding-001": {
        "litellm_provider": "vertex_ai-embedding-models",
        "mode": "embedding",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 2048,
        "max_output_tokens": null
    },
    "gemini-flash-experimental": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192
    },
    "gemini-pro": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 32760,
        "max_output_tokens": 8192
    },
    "gemini-pro-experimental": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192
    },
    "gemini-pro-vision": {
        "litellm_provider": "vertex_ai-vision-models",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 16384,
        "max_output_tokens": 2048
    },
    "gemini/gemini-embedding-001": {
        "litellm_provider": "gemini",
        "mode": "embedding",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 2048,
        "max_output_tokens": null
    },
    "gemini/gemini-1.5-flash": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 7.5e-08,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192
    },
    "gemini/gemini-1.5-flash-001": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 7.5e-08,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": 1.875e-08,
        "cache_creation_input_token_cost": 1e-06,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192
    },
    "gemini/gemini-1.5-flash-002": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 7.5e-08,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": 1.875e-08,
        "cache_creation_input_token_cost": 1e-06,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192
    },
    "gemini/gemini-1.5-flash-8b": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192
    },
    "gemini/gemini-1.5-flash-8b-exp-0827": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192
    },
    "gemini/gemini-1.5-flash-8b-exp-0924": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192
    },
    "gemini/gemini-1.5-flash-exp-0827": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192
    },
    "gemini/gemini-1.5-flash-latest": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 7.5e-08,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192
    },
    "gemini/gemini-1.5-pro": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 3.5e-06,
        "output_cost_per_token": 1.05e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192
    },
    "gemini/gemini-1.5-pro-001": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 3.5e-06,
        "output_cost_per_token": 1.05e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192
    },
    "gemini/gemini-1.5-pro-002": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 3.5e-06,
        "output_cost_per_token": 1.05e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192
    },
    "gemini/gemini-1.5-pro-exp-0801": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 3.5e-06,
        "output_cost_per_token": 1.05e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192
    },
    "gemini/gemini-1.5-pro-exp-0827": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192
    },
    "gemini/gemini-1.5-pro-latest": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 3.5e-06,
        "output_cost_per_token": 1.05e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192
    },
    "gemini/gemini-2.0-flash": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": 2.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192
    },
    "gemini/gemini-2.0-flash-001": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": 2.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192
    },
    "gemini/gemini-2.0-flash-exp": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": 0.0,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192
    },
    "gemini/gemini-2.0-flash-lite": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 7.5e-08,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": 1.875e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192
    },
    "gemini/gemini-2.0-flash-lite-preview-02-05": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 7.5e-08,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": 1.875e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192
    },
    "gemini/gemini-2.0-flash-live-001": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 3.5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": 7.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini/gemini-2.0-flash-preview-image-generation": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": 2.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192
    },
    "gemini/gemini-2.0-flash-thinking-exp": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": 0.0,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65536
    },
    "gemini/gemini-2.0-flash-thinking-exp-01-21": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": 0.0,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65536
    },
    "gemini/gemini-2.0-pro-exp-02-05": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": 0.0,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192
    },
    "gemini/gemini-2.5-flash": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": 3e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini/gemini-2.5-flash-image": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "image_generation",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": 3e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "gemini/gemini-2.5-flash-image-preview": {
        "litellm_provider": "gemini",
        "mode": "image_generation",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 3e-05,
        "cache_read_input_token_cost": 7.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini/gemini-3-pro-image-preview": {
        "litellm_provider": "gemini",
        "mode": "image_generation",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 1.2e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 65536,
        "max_output_tokens": 32768
    },
    "gemini/deep-research-pro-preview-12-2025": {
        "litellm_provider": "gemini",
        "mode": "image_generation",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 1.2e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 65536,
        "max_output_tokens": 32768
    },
    "gemini/gemini-2.5-flash-lite": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": 1e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini/gemini-2.5-flash-lite-preview-09-2025": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": 1e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini/gemini-2.5-flash-preview-09-2025": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": 7.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini/gemini-flash-latest": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": 7.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini/gemini-flash-lite-latest": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": 2.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini/gemini-2.5-flash-lite-preview-06-17": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": 2.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini/gemini-2.5-flash-preview-04-17": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": 3.75e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini/gemini-2.5-flash-preview-05-20": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": 7.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini/gemini-2.5-flash-preview-tts": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": 3.75e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini/gemini-2.5-pro": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini/gemini-2.5-computer-use-preview-10-2025": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 64000,
        "max_input_tokens": 128000,
        "max_output_tokens": 64000
    },
    "gemini/gemini-3-pro-preview": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 1.2e-05,
        "cache_read_input_token_cost": 2e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini/gemini-3-flash-preview": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 3e-06,
        "cache_read_input_token_cost": 5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini-3-flash-preview": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 3e-06,
        "cache_read_input_token_cost": 5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini/gemini-2.5-pro-exp-03-25": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": 0.0,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini/gemini-2.5-pro-preview-03-25": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini/gemini-2.5-pro-preview-05-06": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini/gemini-2.5-pro-preview-06-05": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini/gemini-2.5-pro-preview-tts": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "gemini/gemini-exp-1114": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192
    },
    "gemini/gemini-exp-1206": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192
    },
    "gemini/gemini-gemma-2-27b-it": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 3.5e-07,
        "output_cost_per_token": 1.05e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": null,
        "max_output_tokens": 8192
    },
    "gemini/gemini-gemma-2-9b-it": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 3.5e-07,
        "output_cost_per_token": 1.05e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": null,
        "max_output_tokens": 8192
    },
    "gemini/gemini-pro": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 3.5e-07,
        "output_cost_per_token": 1.05e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 32760,
        "max_output_tokens": 8192
    },
    "gemini/gemini-pro-vision": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 3.5e-07,
        "output_cost_per_token": 1.05e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 30720,
        "max_output_tokens": 2048
    },
    "gemini/gemma-3-27b-it": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 131072,
        "max_output_tokens": 8192
    },
    "gemini/imagen-3.0-fast-generate-001": {
        "litellm_provider": "gemini",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "gemini/imagen-3.0-generate-001": {
        "litellm_provider": "gemini",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "gemini/imagen-3.0-generate-002": {
        "litellm_provider": "gemini",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "gemini/imagen-4.0-fast-generate-001": {
        "litellm_provider": "gemini",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "gemini/imagen-4.0-generate-001": {
        "litellm_provider": "gemini",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "gemini/imagen-4.0-ultra-generate-001": {
        "litellm_provider": "gemini",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "gemini/learnlm-1.5-pro-experimental": {
        "litellm_provider": "gemini",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 32767,
        "max_output_tokens": 8192
    },
    "gemini/veo-2.0-generate-001": {
        "litellm_provider": "gemini",
        "mode": "video_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 1024,
        "max_output_tokens": null
    },
    "gemini/veo-3.0-fast-generate-preview": {
        "litellm_provider": "gemini",
        "mode": "video_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 1024,
        "max_output_tokens": null
    },
    "gemini/veo-3.0-generate-preview": {
        "litellm_provider": "gemini",
        "mode": "video_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 1024,
        "max_output_tokens": null
    },
    "gemini/veo-3.1-fast-generate-preview": {
        "litellm_provider": "gemini",
        "mode": "video_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 1024,
        "max_output_tokens": null
    },
    "gemini/veo-3.1-generate-preview": {
        "litellm_provider": "gemini",
        "mode": "video_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 1024,
        "max_output_tokens": null
    },
    "gemini/veo-3.1-fast-generate-001": {
        "litellm_provider": "gemini",
        "mode": "video_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 1024,
        "max_output_tokens": null
    },
    "gemini/veo-3.1-generate-001": {
        "litellm_provider": "gemini",
        "mode": "video_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 1024,
        "max_output_tokens": null
    },
    "github_copilot/claude-haiku-4.5": {
        "litellm_provider": "github_copilot",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16000,
        "max_input_tokens": 128000,
        "max_output_tokens": 16000
    },
    "github_copilot/claude-opus-4.5": {
        "litellm_provider": "github_copilot",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16000,
        "max_input_tokens": 128000,
        "max_output_tokens": 16000
    },
    "github_copilot/claude-opus-41": {
        "litellm_provider": "github_copilot",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16000,
        "max_input_tokens": 80000,
        "max_output_tokens": 16000
    },
    "github_copilot/claude-sonnet-4": {
        "litellm_provider": "github_copilot",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16000,
        "max_input_tokens": 128000,
        "max_output_tokens": 16000
    },
    "github_copilot/claude-sonnet-4.5": {
        "litellm_provider": "github_copilot",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16000,
        "max_input_tokens": 128000,
        "max_output_tokens": 16000
    },
    "github_copilot/gemini-2.5-pro": {
        "litellm_provider": "github_copilot",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 64000,
        "max_input_tokens": 128000,
        "max_output_tokens": 64000
    },
    "github_copilot/gemini-3-pro-preview": {
        "litellm_provider": "github_copilot",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 64000,
        "max_input_tokens": 128000,
        "max_output_tokens": 64000
    },
    "github_copilot/gpt-3.5-turbo": {
        "litellm_provider": "github_copilot",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 16384,
        "max_output_tokens": 4096
    },
    "github_copilot/gpt-3.5-turbo-0613": {
        "litellm_provider": "github_copilot",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 16384,
        "max_output_tokens": 4096
    },
    "github_copilot/gpt-4": {
        "litellm_provider": "github_copilot",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 32768,
        "max_output_tokens": 4096
    },
    "github_copilot/gpt-4-0613": {
        "litellm_provider": "github_copilot",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 32768,
        "max_output_tokens": 4096
    },
    "github_copilot/gpt-4-o-preview": {
        "litellm_provider": "github_copilot",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 64000,
        "max_output_tokens": 4096
    },
    "github_copilot/gpt-4.1": {
        "litellm_provider": "github_copilot",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "github_copilot/gpt-4.1-2025-04-14": {
        "litellm_provider": "github_copilot",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "github_copilot/gpt-41-copilot": {
        "litellm_provider": "github_copilot",
        "mode": "completion",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "github_copilot/gpt-4o": {
        "litellm_provider": "github_copilot",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 64000,
        "max_output_tokens": 4096
    },
    "github_copilot/gpt-4o-2024-05-13": {
        "litellm_provider": "github_copilot",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 64000,
        "max_output_tokens": 4096
    },
    "github_copilot/gpt-4o-2024-08-06": {
        "litellm_provider": "github_copilot",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 64000,
        "max_output_tokens": 16384
    },
    "github_copilot/gpt-4o-2024-11-20": {
        "litellm_provider": "github_copilot",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 64000,
        "max_output_tokens": 16384
    },
    "github_copilot/gpt-4o-mini": {
        "litellm_provider": "github_copilot",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 64000,
        "max_output_tokens": 4096
    },
    "github_copilot/gpt-4o-mini-2024-07-18": {
        "litellm_provider": "github_copilot",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 64000,
        "max_output_tokens": 4096
    },
    "github_copilot/gpt-5": {
        "litellm_provider": "github_copilot",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "github_copilot/gpt-5-mini": {
        "litellm_provider": "github_copilot",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 64000,
        "max_input_tokens": 128000,
        "max_output_tokens": 64000
    },
    "github_copilot/gpt-5.1": {
        "litellm_provider": "github_copilot",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 64000,
        "max_input_tokens": 128000,
        "max_output_tokens": 64000
    },
    "github_copilot/gpt-5.1-codex-max": {
        "litellm_provider": "github_copilot",
        "mode": "responses",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "github_copilot/gpt-5.2": {
        "litellm_provider": "github_copilot",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 64000,
        "max_input_tokens": 128000,
        "max_output_tokens": 64000
    },
    "github_copilot/text-embedding-3-small": {
        "litellm_provider": "github_copilot",
        "mode": "embedding",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 8191,
        "max_output_tokens": null
    },
    "github_copilot/text-embedding-3-small-inference": {
        "litellm_provider": "github_copilot",
        "mode": "embedding",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 8191,
        "max_output_tokens": null
    },
    "github_copilot/text-embedding-ada-002": {
        "litellm_provider": "github_copilot",
        "mode": "embedding",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 8191,
        "max_output_tokens": null
    },
    "chatgpt/gpt-5.2-codex": {
        "litellm_provider": "chatgpt",
        "mode": "responses",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "chatgpt/gpt-5.2": {
        "litellm_provider": "chatgpt",
        "mode": "responses",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 64000,
        "max_input_tokens": 128000,
        "max_output_tokens": 64000
    },
    "chatgpt/gpt-5.1-codex-max": {
        "litellm_provider": "chatgpt",
        "mode": "responses",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "chatgpt/gpt-5.1-codex-mini": {
        "litellm_provider": "chatgpt",
        "mode": "responses",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 64000,
        "max_input_tokens": 128000,
        "max_output_tokens": 64000
    },
    "gigachat/GigaChat-2-Lite": {
        "litellm_provider": "gigachat",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "gigachat/GigaChat-2-Max": {
        "litellm_provider": "gigachat",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "gigachat/GigaChat-2-Pro": {
        "litellm_provider": "gigachat",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "gigachat/Embeddings": {
        "litellm_provider": "gigachat",
        "mode": "embedding",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 512,
        "max_input_tokens": 512,
        "max_output_tokens": null
    },
    "gigachat/Embeddings-2": {
        "litellm_provider": "gigachat",
        "mode": "embedding",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 512,
        "max_input_tokens": 512,
        "max_output_tokens": null
    },
    "gigachat/EmbeddingsGigaR": {
        "litellm_provider": "gigachat",
        "mode": "embedding",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": null
    },
    "gmi/anthropic/claude-opus-4.5": {
        "litellm_provider": "gmi",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 2.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 409600,
        "max_output_tokens": 32000
    },
    "gmi/anthropic/claude-sonnet-4.5": {
        "litellm_provider": "gmi",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 409600,
        "max_output_tokens": 32000
    },
    "gmi/anthropic/claude-sonnet-4": {
        "litellm_provider": "gmi",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 409600,
        "max_output_tokens": 32000
    },
    "gmi/anthropic/claude-opus-4": {
        "litellm_provider": "gmi",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 409600,
        "max_output_tokens": 32000
    },
    "gmi/openai/gpt-5.2": {
        "litellm_provider": "gmi",
        "mode": "chat",
        "input_cost_per_token": 1.75e-06,
        "output_cost_per_token": 1.4e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 409600,
        "max_output_tokens": 32000
    },
    "gmi/openai/gpt-5.1": {
        "litellm_provider": "gmi",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 409600,
        "max_output_tokens": 32000
    },
    "gmi/openai/gpt-5": {
        "litellm_provider": "gmi",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 409600,
        "max_output_tokens": 32000
    },
    "gmi/openai/gpt-4o": {
        "litellm_provider": "gmi",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 131072,
        "max_output_tokens": 16384
    },
    "gmi/openai/gpt-4o-mini": {
        "litellm_provider": "gmi",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 131072,
        "max_output_tokens": 16384
    },
    "gmi/deepseek-ai/DeepSeek-V3.2": {
        "litellm_provider": "gmi",
        "mode": "chat",
        "input_cost_per_token": 2.8e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 163840,
        "max_output_tokens": 16384
    },
    "gmi/deepseek-ai/DeepSeek-V3-0324": {
        "litellm_provider": "gmi",
        "mode": "chat",
        "input_cost_per_token": 2.8e-07,
        "output_cost_per_token": 8.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 163840,
        "max_output_tokens": 16384
    },
    "gmi/google/gemini-3-pro-preview": {
        "litellm_provider": "gmi",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 1.2e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65536
    },
    "gmi/google/gemini-3-flash-preview": {
        "litellm_provider": "gmi",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 3e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65536
    },
    "gmi/moonshotai/Kimi-K2-Thinking": {
        "litellm_provider": "gmi",
        "mode": "chat",
        "input_cost_per_token": 8e-07,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 262144,
        "max_output_tokens": 16384
    },
    "gmi/MiniMaxAI/MiniMax-M2.1": {
        "litellm_provider": "gmi",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 196608,
        "max_output_tokens": 16384
    },
    "gmi/Qwen/Qwen3-VL-235B-A22B-Instruct-FP8": {
        "litellm_provider": "gmi",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 1.4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 262144,
        "max_output_tokens": 16384
    },
    "gmi/zai-org/GLM-4.7-FP8": {
        "litellm_provider": "gmi",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 202752,
        "max_output_tokens": 16384
    },
    "google.gemma-3-12b-it": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 9e-08,
        "output_cost_per_token": 2.9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "google.gemma-3-27b-it": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 2.3e-07,
        "output_cost_per_token": 3.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "google.gemma-3-4b-it": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 4e-08,
        "output_cost_per_token": 8e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "google_pse/search": {
        "litellm_provider": "google_pse",
        "mode": "search",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "global.anthropic.claude-sonnet-4-5-20250929-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "global.anthropic.claude-sonnet-4-20250514-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 64000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000
    },
    "global.anthropic.claude-haiku-4-5-20251001-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": 1e-07,
        "cache_creation_input_token_cost": 1.25e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "global.amazon.nova-2-lite-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": 7.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 64000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000
    },
    "gpt-3.5-turbo": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 16385,
        "max_output_tokens": 4096
    },
    "gpt-3.5-turbo-0125": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 16385,
        "max_output_tokens": 4096
    },
    "gpt-3.5-turbo-0301": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1.5e-06,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4097,
        "max_output_tokens": 4096
    },
    "gpt-3.5-turbo-0613": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1.5e-06,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4097,
        "max_output_tokens": 4096
    },
    "gpt-3.5-turbo-1106": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 16385,
        "max_output_tokens": 4096
    },
    "gpt-3.5-turbo-16k": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 16385,
        "max_output_tokens": 4096
    },
    "gpt-3.5-turbo-16k-0613": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 16385,
        "max_output_tokens": 4096
    },
    "gpt-3.5-turbo-instruct": {
        "litellm_provider": "text-completion-openai",
        "mode": "completion",
        "input_cost_per_token": 1.5e-06,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096
    },
    "gpt-3.5-turbo-instruct-0914": {
        "litellm_provider": "text-completion-openai",
        "mode": "completion",
        "input_cost_per_token": 1.5e-06,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4097,
        "max_input_tokens": 8192,
        "max_output_tokens": 4097
    },
    "gpt-4": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 3e-05,
        "output_cost_per_token": 6e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096
    },
    "gpt-4-0125-preview": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1e-05,
        "output_cost_per_token": 3e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "gpt-4-0314": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 3e-05,
        "output_cost_per_token": 6e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096
    },
    "gpt-4-0613": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 3e-05,
        "output_cost_per_token": 6e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096
    },
    "gpt-4-1106-preview": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1e-05,
        "output_cost_per_token": 3e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "gpt-4-1106-vision-preview": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1e-05,
        "output_cost_per_token": 3e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "gpt-4-32k": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 6e-05,
        "output_cost_per_token": 0.00012,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 32768,
        "max_output_tokens": 4096
    },
    "gpt-4-32k-0314": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 6e-05,
        "output_cost_per_token": 0.00012,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 32768,
        "max_output_tokens": 4096
    },
    "gpt-4-32k-0613": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 6e-05,
        "output_cost_per_token": 0.00012,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 32768,
        "max_output_tokens": 4096
    },
    "gpt-4-turbo": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1e-05,
        "output_cost_per_token": 3e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "gpt-4-turbo-2024-04-09": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1e-05,
        "output_cost_per_token": 3e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "gpt-4-turbo-preview": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1e-05,
        "output_cost_per_token": 3e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "gpt-4-vision-preview": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1e-05,
        "output_cost_per_token": 3e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "gpt-4.1": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 8e-06,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768
    },
    "gpt-4.1-2025-04-14": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 8e-06,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768
    },
    "gpt-4.1-mini": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 1.6e-06,
        "cache_read_input_token_cost": 1e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768
    },
    "gpt-4.1-mini-2025-04-14": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 1.6e-06,
        "cache_read_input_token_cost": 1e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768
    },
    "gpt-4.1-nano": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": 2.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768
    },
    "gpt-4.1-nano-2025-04-14": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": 2.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768
    },
    "gpt-4.5-preview": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 7.5e-05,
        "output_cost_per_token": 0.00015,
        "cache_read_input_token_cost": 3.75e-05,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "gpt-4.5-preview-2025-02-27": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 7.5e-05,
        "output_cost_per_token": 0.00015,
        "cache_read_input_token_cost": 3.75e-05,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "gpt-4o": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "gpt-4o-2024-05-13": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "gpt-4o-2024-08-06": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "gpt-4o-2024-11-20": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "gpt-4o-audio-preview": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "gpt-4o-audio-preview-2024-10-01": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "gpt-4o-audio-preview-2024-12-17": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "gpt-4o-audio-preview-2025-06-03": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "gpt-audio": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "gpt-audio-2025-08-28": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "gpt-audio-mini": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "gpt-audio-mini-2025-10-06": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "gpt-audio-mini-2025-12-15": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "gpt-4o-mini": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": 7.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "gpt-4o-mini-2024-07-18": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": 7.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "gpt-4o-mini-audio-preview": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "gpt-4o-mini-audio-preview-2024-12-17": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "gpt-4o-mini-realtime-preview": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.4e-06,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "gpt-4o-mini-realtime-preview-2024-12-17": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.4e-06,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "gpt-4o-mini-search-preview": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": 7.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "gpt-4o-mini-search-preview-2025-03-11": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": 7.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "gpt-4o-mini-transcribe": {
        "litellm_provider": "openai",
        "mode": "audio_transcription",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 16000,
        "max_output_tokens": 2000
    },
    "gpt-4o-mini-tts": {
        "litellm_provider": "openai",
        "mode": "audio_speech",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "gpt-4o-realtime-preview": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 2e-05,
        "cache_read_input_token_cost": 2.5e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "gpt-4o-realtime-preview-2024-10-01": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 2e-05,
        "cache_read_input_token_cost": 2.5e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "gpt-4o-realtime-preview-2024-12-17": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 2e-05,
        "cache_read_input_token_cost": 2.5e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "gpt-4o-realtime-preview-2025-06-03": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 2e-05,
        "cache_read_input_token_cost": 2.5e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "gpt-4o-search-preview": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "gpt-4o-search-preview-2025-03-11": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "gpt-4o-transcribe": {
        "litellm_provider": "openai",
        "mode": "audio_transcription",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 16000,
        "max_output_tokens": 2000
    },
    "gpt-image-1.5": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "gpt-image-1.5-2025-12-16": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "low/1024-x-1024/gpt-image-1.5": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "low/1024-x-1536/gpt-image-1.5": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "low/1536-x-1024/gpt-image-1.5": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "medium/1024-x-1024/gpt-image-1.5": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "medium/1024-x-1536/gpt-image-1.5": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "medium/1536-x-1024/gpt-image-1.5": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "high/1024-x-1024/gpt-image-1.5": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "high/1024-x-1536/gpt-image-1.5": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "high/1536-x-1024/gpt-image-1.5": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "standard/1024-x-1024/gpt-image-1.5": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "standard/1024-x-1536/gpt-image-1.5": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "standard/1536-x-1024/gpt-image-1.5": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "1024-x-1024/gpt-image-1.5": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "1024-x-1536/gpt-image-1.5": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "1536-x-1024/gpt-image-1.5": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "low/1024-x-1024/gpt-image-1.5-2025-12-16": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "low/1024-x-1536/gpt-image-1.5-2025-12-16": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "low/1536-x-1024/gpt-image-1.5-2025-12-16": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "medium/1024-x-1024/gpt-image-1.5-2025-12-16": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "medium/1024-x-1536/gpt-image-1.5-2025-12-16": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "medium/1536-x-1024/gpt-image-1.5-2025-12-16": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "high/1024-x-1024/gpt-image-1.5-2025-12-16": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "high/1024-x-1536/gpt-image-1.5-2025-12-16": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "high/1536-x-1024/gpt-image-1.5-2025-12-16": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "standard/1024-x-1024/gpt-image-1.5-2025-12-16": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "standard/1024-x-1536/gpt-image-1.5-2025-12-16": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "standard/1536-x-1024/gpt-image-1.5-2025-12-16": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "1024-x-1024/gpt-image-1.5-2025-12-16": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "1024-x-1536/gpt-image-1.5-2025-12-16": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "1536-x-1024/gpt-image-1.5-2025-12-16": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "gpt-5": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "gpt-5.1": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "gpt-5.1-2025-11-13": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "gpt-5.1-chat-latest": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "gpt-5.2": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1.75e-06,
        "output_cost_per_token": 1.4e-05,
        "cache_read_input_token_cost": 1.75e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "gpt-5.2-2025-12-11": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1.75e-06,
        "output_cost_per_token": 1.4e-05,
        "cache_read_input_token_cost": 1.75e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "gpt-5.2-chat-latest": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1.75e-06,
        "output_cost_per_token": 1.4e-05,
        "cache_read_input_token_cost": 1.75e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "gpt-5.2-pro": {
        "litellm_provider": "openai",
        "mode": "responses",
        "input_cost_per_token": 2.1e-05,
        "output_cost_per_token": 0.000168,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "gpt-5.2-pro-2025-12-11": {
        "litellm_provider": "openai",
        "mode": "responses",
        "input_cost_per_token": 2.1e-05,
        "output_cost_per_token": 0.000168,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "gpt-5-pro": {
        "litellm_provider": "openai",
        "mode": "responses",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 0.00012,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 272000,
        "max_input_tokens": 128000,
        "max_output_tokens": 272000
    },
    "gpt-5-pro-2025-10-06": {
        "litellm_provider": "openai",
        "mode": "responses",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 0.00012,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 272000,
        "max_input_tokens": 128000,
        "max_output_tokens": 272000
    },
    "gpt-5-2025-08-07": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "gpt-5-chat": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "gpt-5-chat-latest": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "gpt-5-codex": {
        "litellm_provider": "openai",
        "mode": "responses",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "gpt-5.1-codex": {
        "litellm_provider": "openai",
        "mode": "responses",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "gpt-5.1-codex-max": {
        "litellm_provider": "openai",
        "mode": "responses",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "gpt-5.1-codex-mini": {
        "litellm_provider": "openai",
        "mode": "responses",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": 2.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "gpt-5.2-codex": {
        "litellm_provider": "openai",
        "mode": "responses",
        "input_cost_per_token": 1.75e-06,
        "output_cost_per_token": 1.4e-05,
        "cache_read_input_token_cost": 1.75e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "gpt-5-mini": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": 2.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "gpt-5-mini-2025-08-07": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": 2.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "gpt-5-nano": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": 5e-09,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "gpt-5-nano-2025-08-07": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": 5e-09,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "gpt-image-1": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": 1.25e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "gpt-image-1-mini": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": 2e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "gpt-realtime": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 4e-06,
        "output_cost_per_token": 1.6e-05,
        "cache_read_input_token_cost": 4e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 32000,
        "max_output_tokens": 4096
    },
    "gpt-realtime-mini": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "gpt-realtime-2025-08-28": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 4e-06,
        "output_cost_per_token": 1.6e-05,
        "cache_read_input_token_cost": 4e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 32000,
        "max_output_tokens": 4096
    },
    "gradient_ai/alibaba-qwen3-32b": {
        "litellm_provider": "gradient_ai",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "gradient_ai/anthropic-claude-3-opus": {
        "litellm_provider": "gradient_ai",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "gradient_ai/anthropic-claude-3.5-haiku": {
        "litellm_provider": "gradient_ai",
        "mode": "chat",
        "input_cost_per_token": 8e-07,
        "output_cost_per_token": 4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "gradient_ai/anthropic-claude-3.5-sonnet": {
        "litellm_provider": "gradient_ai",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "gradient_ai/anthropic-claude-3.7-sonnet": {
        "litellm_provider": "gradient_ai",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "gradient_ai/deepseek-r1-distill-llama-70b": {
        "litellm_provider": "gradient_ai",
        "mode": "chat",
        "input_cost_per_token": 9.9e-07,
        "output_cost_per_token": 9.9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8000,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "gradient_ai/llama3-8b-instruct": {
        "litellm_provider": "gradient_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 512,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "gradient_ai/llama3.3-70b-instruct": {
        "litellm_provider": "gradient_ai",
        "mode": "chat",
        "input_cost_per_token": 6.5e-07,
        "output_cost_per_token": 6.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "gradient_ai/mistral-nemo-instruct-2407": {
        "litellm_provider": "gradient_ai",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 512,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "gradient_ai/openai-gpt-4o": {
        "litellm_provider": "gradient_ai",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "gradient_ai/openai-gpt-4o-mini": {
        "litellm_provider": "gradient_ai",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "gradient_ai/openai-o3": {
        "litellm_provider": "gradient_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 8e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "gradient_ai/openai-o3-mini": {
        "litellm_provider": "gradient_ai",
        "mode": "chat",
        "input_cost_per_token": 1.1e-06,
        "output_cost_per_token": 4.4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "lemonade/Qwen3-Coder-30B-A3B-Instruct-GGUF": {
        "litellm_provider": "lemonade",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 262144,
        "max_output_tokens": 32768
    },
    "lemonade/gpt-oss-20b-mxfp4-GGUF": {
        "litellm_provider": "lemonade",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 131072,
        "max_output_tokens": 32768
    },
    "lemonade/gpt-oss-120b-mxfp-GGUF": {
        "litellm_provider": "lemonade",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 131072,
        "max_output_tokens": 32768
    },
    "lemonade/Gemma-3-4b-it-GGUF": {
        "litellm_provider": "lemonade",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "lemonade/Qwen3-4B-Instruct-2507-GGUF": {
        "litellm_provider": "lemonade",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 262144,
        "max_output_tokens": 32768
    },
    "amazon-nova/nova-micro-v1": {
        "litellm_provider": "amazon_nova",
        "mode": "chat",
        "input_cost_per_token": 3.5e-08,
        "output_cost_per_token": 1.4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 10000,
        "max_input_tokens": 128000,
        "max_output_tokens": 10000
    },
    "amazon-nova/nova-lite-v1": {
        "litellm_provider": "amazon_nova",
        "mode": "chat",
        "input_cost_per_token": 6e-08,
        "output_cost_per_token": 2.4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 10000,
        "max_input_tokens": 300000,
        "max_output_tokens": 10000
    },
    "amazon-nova/nova-premier-v1": {
        "litellm_provider": "amazon_nova",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1.25e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 10000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 10000
    },
    "amazon-nova/nova-pro-v1": {
        "litellm_provider": "amazon_nova",
        "mode": "chat",
        "input_cost_per_token": 8e-07,
        "output_cost_per_token": 3.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 10000,
        "max_input_tokens": 300000,
        "max_output_tokens": 10000
    },
    "groq/llama-3.1-8b-instant": {
        "litellm_provider": "groq",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 8e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "groq/llama-3.3-70b-versatile": {
        "litellm_provider": "groq",
        "mode": "chat",
        "input_cost_per_token": 5.9e-07,
        "output_cost_per_token": 7.9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 128000,
        "max_output_tokens": 32768
    },
    "groq/gemma-7b-it": {
        "litellm_provider": "groq",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 8e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "groq/meta-llama/llama-guard-4-12b": {
        "litellm_provider": "groq",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "groq/meta-llama/llama-4-maverick-17b-128e-instruct": {
        "litellm_provider": "groq",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 131072,
        "max_output_tokens": 8192
    },
    "groq/meta-llama/llama-4-scout-17b-16e-instruct": {
        "litellm_provider": "groq",
        "mode": "chat",
        "input_cost_per_token": 1.1e-07,
        "output_cost_per_token": 3.4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 131072,
        "max_output_tokens": 8192
    },
    "groq/moonshotai/kimi-k2-instruct-0905": {
        "litellm_provider": "groq",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 3e-06,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 262144,
        "max_output_tokens": 16384
    },
    "groq/openai/gpt-oss-120b": {
        "litellm_provider": "groq",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": 7.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32766,
        "max_input_tokens": 131072,
        "max_output_tokens": 32766
    },
    "groq/openai/gpt-oss-20b": {
        "litellm_provider": "groq",
        "mode": "chat",
        "input_cost_per_token": 7.5e-08,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": 3.75e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 131072,
        "max_output_tokens": 32768
    },
    "groq/playai-tts": {
        "litellm_provider": "groq",
        "mode": "audio_speech",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 10000,
        "max_input_tokens": 10000,
        "max_output_tokens": 10000
    },
    "groq/qwen/qwen3-32b": {
        "litellm_provider": "groq",
        "mode": "chat",
        "input_cost_per_token": 2.9e-07,
        "output_cost_per_token": 5.9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131000,
        "max_input_tokens": 131000,
        "max_output_tokens": 131000
    },
    "groq/whisper-large-v3": {
        "litellm_provider": "groq",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "groq/whisper-large-v3-turbo": {
        "litellm_provider": "groq",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "hd/1024-x-1024/dall-e-3": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "hd/1024-x-1792/dall-e-3": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "hd/1792-x-1024/dall-e-3": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "heroku/claude-3-5-haiku": {
        "litellm_provider": "heroku",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "heroku/claude-3-5-sonnet-latest": {
        "litellm_provider": "heroku",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "heroku/claude-3-7-sonnet": {
        "litellm_provider": "heroku",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "heroku/claude-4-sonnet": {
        "litellm_provider": "heroku",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "high/1024-x-1024/gpt-image-1": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "high/1024-x-1536/gpt-image-1": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "high/1536-x-1024/gpt-image-1": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "hyperbolic/NousResearch/Hermes-3-Llama-3.1-70B": {
        "litellm_provider": "hyperbolic",
        "mode": "chat",
        "input_cost_per_token": 1.2e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "hyperbolic/Qwen/QwQ-32B": {
        "litellm_provider": "hyperbolic",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "hyperbolic/Qwen/Qwen2.5-72B-Instruct": {
        "litellm_provider": "hyperbolic",
        "mode": "chat",
        "input_cost_per_token": 1.2e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "hyperbolic/Qwen/Qwen2.5-Coder-32B-Instruct": {
        "litellm_provider": "hyperbolic",
        "mode": "chat",
        "input_cost_per_token": 1.2e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "hyperbolic/Qwen/Qwen3-235B-A22B": {
        "litellm_provider": "hyperbolic",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "hyperbolic/deepseek-ai/DeepSeek-R1": {
        "litellm_provider": "hyperbolic",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "hyperbolic/deepseek-ai/DeepSeek-R1-0528": {
        "litellm_provider": "hyperbolic",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 2.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "hyperbolic/deepseek-ai/DeepSeek-V3": {
        "litellm_provider": "hyperbolic",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "hyperbolic/deepseek-ai/DeepSeek-V3-0324": {
        "litellm_provider": "hyperbolic",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "hyperbolic/meta-llama/Llama-3.2-3B-Instruct": {
        "litellm_provider": "hyperbolic",
        "mode": "chat",
        "input_cost_per_token": 1.2e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "hyperbolic/meta-llama/Llama-3.3-70B-Instruct": {
        "litellm_provider": "hyperbolic",
        "mode": "chat",
        "input_cost_per_token": 1.2e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "hyperbolic/meta-llama/Meta-Llama-3-70B-Instruct": {
        "litellm_provider": "hyperbolic",
        "mode": "chat",
        "input_cost_per_token": 1.2e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct": {
        "litellm_provider": "hyperbolic",
        "mode": "chat",
        "input_cost_per_token": 1.2e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct": {
        "litellm_provider": "hyperbolic",
        "mode": "chat",
        "input_cost_per_token": 1.2e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct": {
        "litellm_provider": "hyperbolic",
        "mode": "chat",
        "input_cost_per_token": 1.2e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "hyperbolic/moonshotai/Kimi-K2-Instruct": {
        "litellm_provider": "hyperbolic",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "j2-light": {
        "litellm_provider": "ai21",
        "mode": "completion",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 3e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "j2-mid": {
        "litellm_provider": "ai21",
        "mode": "completion",
        "input_cost_per_token": 1e-05,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "j2-ultra": {
        "litellm_provider": "ai21",
        "mode": "completion",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "jamba-1.5": {
        "litellm_provider": "ai21",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "jamba-1.5-large": {
        "litellm_provider": "ai21",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 8e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "jamba-1.5-large@001": {
        "litellm_provider": "ai21",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 8e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "jamba-1.5-mini": {
        "litellm_provider": "ai21",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "jamba-1.5-mini@001": {
        "litellm_provider": "ai21",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "jamba-large-1.6": {
        "litellm_provider": "ai21",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 8e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "jamba-large-1.7": {
        "litellm_provider": "ai21",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 8e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "jamba-mini-1.6": {
        "litellm_provider": "ai21",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "jamba-mini-1.7": {
        "litellm_provider": "ai21",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "jina-reranker-v2-base-multilingual": {
        "litellm_provider": "jina_ai",
        "mode": "rerank",
        "input_cost_per_token": 1.8e-08,
        "output_cost_per_token": 1.8e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 1024,
        "max_output_tokens": 1024
    },
    "jp.anthropic.claude-sonnet-4-5-20250929-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 3.3e-06,
        "output_cost_per_token": 1.65e-05,
        "cache_read_input_token_cost": 3.3e-07,
        "cache_creation_input_token_cost": 4.125e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "jp.anthropic.claude-haiku-4-5-20251001-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 1.1e-06,
        "output_cost_per_token": 5.5e-06,
        "cache_read_input_token_cost": 1.1e-07,
        "cache_creation_input_token_cost": 1.375e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "lambda_ai/deepseek-llama3.3-70b": {
        "litellm_provider": "lambda_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "lambda_ai/deepseek-r1-0528": {
        "litellm_provider": "lambda_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "lambda_ai/deepseek-r1-671b": {
        "litellm_provider": "lambda_ai",
        "mode": "chat",
        "input_cost_per_token": 8e-07,
        "output_cost_per_token": 8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "lambda_ai/deepseek-v3-0324": {
        "litellm_provider": "lambda_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "lambda_ai/hermes3-405b": {
        "litellm_provider": "lambda_ai",
        "mode": "chat",
        "input_cost_per_token": 8e-07,
        "output_cost_per_token": 8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "lambda_ai/hermes3-70b": {
        "litellm_provider": "lambda_ai",
        "mode": "chat",
        "input_cost_per_token": 1.2e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "lambda_ai/hermes3-8b": {
        "litellm_provider": "lambda_ai",
        "mode": "chat",
        "input_cost_per_token": 2.5e-08,
        "output_cost_per_token": 4e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "lambda_ai/lfm-40b": {
        "litellm_provider": "lambda_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "lambda_ai/lfm-7b": {
        "litellm_provider": "lambda_ai",
        "mode": "chat",
        "input_cost_per_token": 2.5e-08,
        "output_cost_per_token": 4e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "lambda_ai/llama-4-maverick-17b-128e-instruct-fp8": {
        "litellm_provider": "lambda_ai",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 131072,
        "max_output_tokens": 8192
    },
    "lambda_ai/llama-4-scout-17b-16e-instruct": {
        "litellm_provider": "lambda_ai",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 16384,
        "max_output_tokens": 8192
    },
    "lambda_ai/llama3.1-405b-instruct-fp8": {
        "litellm_provider": "lambda_ai",
        "mode": "chat",
        "input_cost_per_token": 8e-07,
        "output_cost_per_token": 8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "lambda_ai/llama3.1-70b-instruct-fp8": {
        "litellm_provider": "lambda_ai",
        "mode": "chat",
        "input_cost_per_token": 1.2e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "lambda_ai/llama3.1-8b-instruct": {
        "litellm_provider": "lambda_ai",
        "mode": "chat",
        "input_cost_per_token": 2.5e-08,
        "output_cost_per_token": 4e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "lambda_ai/llama3.1-nemotron-70b-instruct-fp8": {
        "litellm_provider": "lambda_ai",
        "mode": "chat",
        "input_cost_per_token": 1.2e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "lambda_ai/llama3.2-11b-vision-instruct": {
        "litellm_provider": "lambda_ai",
        "mode": "chat",
        "input_cost_per_token": 1.5e-08,
        "output_cost_per_token": 2.5e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "lambda_ai/llama3.2-3b-instruct": {
        "litellm_provider": "lambda_ai",
        "mode": "chat",
        "input_cost_per_token": 1.5e-08,
        "output_cost_per_token": 2.5e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "lambda_ai/llama3.3-70b-instruct-fp8": {
        "litellm_provider": "lambda_ai",
        "mode": "chat",
        "input_cost_per_token": 1.2e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "lambda_ai/qwen25-coder-32b-instruct": {
        "litellm_provider": "lambda_ai",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "lambda_ai/qwen3-32b-fp8": {
        "litellm_provider": "lambda_ai",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "low/1024-x-1024/gpt-image-1": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "low/1024-x-1536/gpt-image-1": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "low/1536-x-1024/gpt-image-1": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "luminous-base": {
        "litellm_provider": "aleph_alpha",
        "mode": "completion",
        "input_cost_per_token": 3e-05,
        "output_cost_per_token": 3.3e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "luminous-base-control": {
        "litellm_provider": "aleph_alpha",
        "mode": "chat",
        "input_cost_per_token": 3.75e-05,
        "output_cost_per_token": 4.125e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "luminous-extended": {
        "litellm_provider": "aleph_alpha",
        "mode": "completion",
        "input_cost_per_token": 4.5e-05,
        "output_cost_per_token": 4.95e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "luminous-extended-control": {
        "litellm_provider": "aleph_alpha",
        "mode": "chat",
        "input_cost_per_token": 5.625e-05,
        "output_cost_per_token": 6.1875e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "luminous-supreme": {
        "litellm_provider": "aleph_alpha",
        "mode": "completion",
        "input_cost_per_token": 0.000175,
        "output_cost_per_token": 0.0001925,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "luminous-supreme-control": {
        "litellm_provider": "aleph_alpha",
        "mode": "chat",
        "input_cost_per_token": 0.00021875,
        "output_cost_per_token": 0.000240625,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "max-x-max/50-steps/stability.stable-diffusion-xl-v0": {
        "litellm_provider": "bedrock",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 77,
        "max_input_tokens": 77,
        "max_output_tokens": null
    },
    "max-x-max/max-steps/stability.stable-diffusion-xl-v0": {
        "litellm_provider": "bedrock",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 77,
        "max_input_tokens": 77,
        "max_output_tokens": null
    },
    "medium/1024-x-1024/gpt-image-1": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "medium/1024-x-1536/gpt-image-1": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "medium/1536-x-1024/gpt-image-1": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "low/1024-x-1024/gpt-image-1-mini": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "low/1024-x-1536/gpt-image-1-mini": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "low/1536-x-1024/gpt-image-1-mini": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "medium/1024-x-1024/gpt-image-1-mini": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "medium/1024-x-1536/gpt-image-1-mini": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "medium/1536-x-1024/gpt-image-1-mini": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "medlm-large": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 8192,
        "max_output_tokens": 1024
    },
    "medlm-medium": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 32768,
        "max_output_tokens": 8192
    },
    "meta.llama2-13b-chat-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 7.5e-07,
        "output_cost_per_token": 1e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "meta.llama2-70b-chat-v1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 1.95e-06,
        "output_cost_per_token": 2.56e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "meta.llama3-1-405b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 5.32e-06,
        "output_cost_per_token": 1.6e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "meta.llama3-1-70b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 9.9e-07,
        "output_cost_per_token": 9.9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048
    },
    "meta.llama3-1-8b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 2.2e-07,
        "output_cost_per_token": 2.2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048
    },
    "meta.llama3-2-11b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3.5e-07,
        "output_cost_per_token": 3.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "meta.llama3-2-1b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "meta.llama3-2-3b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 1.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "meta.llama3-2-90b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "meta.llama3-3-70b-instruct-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 7.2e-07,
        "output_cost_per_token": 7.2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "meta.llama3-70b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 2.65e-06,
        "output_cost_per_token": 3.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "meta.llama3-8b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "meta.llama4-maverick-17b-instruct-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 2.4e-07,
        "output_cost_per_token": 9.7e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "meta.llama4-scout-17b-instruct-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 1.7e-07,
        "output_cost_per_token": 6.6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "meta_llama/Llama-3.3-70B-Instruct": {
        "litellm_provider": "meta_llama",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4028,
        "max_input_tokens": 128000,
        "max_output_tokens": 4028
    },
    "meta_llama/Llama-3.3-8B-Instruct": {
        "litellm_provider": "meta_llama",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4028,
        "max_input_tokens": 128000,
        "max_output_tokens": 4028
    },
    "meta_llama/Llama-4-Maverick-17B-128E-Instruct-FP8": {
        "litellm_provider": "meta_llama",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4028,
        "max_input_tokens": 1000000,
        "max_output_tokens": 4028
    },
    "meta_llama/Llama-4-Scout-17B-16E-Instruct-FP8": {
        "litellm_provider": "meta_llama",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4028,
        "max_input_tokens": 10000000,
        "max_output_tokens": 4028
    },
    "minimax.minimax-m2": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "minimax/speech-02-hd": {
        "litellm_provider": "minimax",
        "mode": "audio_speech",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "minimax/speech-02-turbo": {
        "litellm_provider": "minimax",
        "mode": "audio_speech",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "minimax/speech-2.6-hd": {
        "litellm_provider": "minimax",
        "mode": "audio_speech",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "minimax/speech-2.6-turbo": {
        "litellm_provider": "minimax",
        "mode": "audio_speech",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "minimax/MiniMax-M2.1": {
        "litellm_provider": "minimax",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": 3e-08,
        "cache_creation_input_token_cost": 3.75e-07,
        "max_tokens": null,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192
    },
    "minimax/MiniMax-M2.1-lightning": {
        "litellm_provider": "minimax",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 2.4e-06,
        "cache_read_input_token_cost": 3e-08,
        "cache_creation_input_token_cost": 3.75e-07,
        "max_tokens": null,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192
    },
    "minimax/MiniMax-M2": {
        "litellm_provider": "minimax",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": 3e-08,
        "cache_creation_input_token_cost": 3.75e-07,
        "max_tokens": null,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "mistral.magistral-small-2509": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "mistral.ministral-3-14b-instruct": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "mistral.ministral-3-3b-instruct": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "mistral.ministral-3-8b-instruct": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 1.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "mistral.mistral-7b-instruct-v0:2": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191
    },
    "mistral.mistral-large-2402-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 8e-06,
        "output_cost_per_token": 2.4e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191
    },
    "mistral.mistral-large-2407-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 9e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 128000,
        "max_output_tokens": 8191
    },
    "mistral.mistral-large-3-675b-instruct": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "mistral.mistral-small-2402-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 3e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191
    },
    "mistral.mixtral-8x7b-instruct-v0:1": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 4.5e-07,
        "output_cost_per_token": 7e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191
    },
    "mistral.voxtral-mini-3b-2507": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 4e-08,
        "output_cost_per_token": 4e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "mistral.voxtral-small-24b-2507": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "mistral/codestral-2405": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 3e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191
    },
    "mistral/codestral-2508": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "mistral/codestral-latest": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 3e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191
    },
    "mistral/codestral-mamba-latest": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 2.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "mistral/devstral-medium-2507": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "mistral/devstral-small-2505": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "mistral/devstral-small-2507": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "mistral/labs-devstral-small-2512": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "mistral/devstral-2512": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "mistral/magistral-medium-2506": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 40000,
        "max_input_tokens": 40000,
        "max_output_tokens": 40000
    },
    "mistral/magistral-medium-2509": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 40000,
        "max_input_tokens": 40000,
        "max_output_tokens": 40000
    },
    "mistral/mistral-ocr-latest": {
        "litellm_provider": "mistral",
        "mode": "ocr",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "mistral/mistral-ocr-2505-completion": {
        "litellm_provider": "mistral",
        "mode": "ocr",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "mistral/magistral-medium-latest": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 40000,
        "max_input_tokens": 40000,
        "max_output_tokens": 40000
    },
    "mistral/magistral-small-2506": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 40000,
        "max_input_tokens": 40000,
        "max_output_tokens": 40000
    },
    "mistral/magistral-small-latest": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 40000,
        "max_input_tokens": 40000,
        "max_output_tokens": 40000
    },
    "mistral/mistral-embed": {
        "litellm_provider": "mistral",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": null
    },
    "mistral/codestral-embed": {
        "litellm_provider": "mistral",
        "mode": "embedding",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": null
    },
    "mistral/codestral-embed-2505": {
        "litellm_provider": "mistral",
        "mode": "embedding",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": null
    },
    "mistral/mistral-large-2402": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 4e-06,
        "output_cost_per_token": 1.2e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191
    },
    "mistral/mistral-large-2407": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 9e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "mistral/mistral-large-2411": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 6e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "mistral/mistral-large-latest": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 6e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "mistral/mistral-large-3": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 256000,
        "max_output_tokens": 8191
    },
    "mistral/mistral-medium": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 2.7e-06,
        "output_cost_per_token": 8.1e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191
    },
    "mistral/mistral-medium-2312": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 2.7e-06,
        "output_cost_per_token": 8.1e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191
    },
    "mistral/mistral-medium-2505": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 131072,
        "max_output_tokens": 8191
    },
    "mistral/mistral-medium-latest": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 131072,
        "max_output_tokens": 8191
    },
    "mistral/mistral-small": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191
    },
    "mistral/mistral-small-latest": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191
    },
    "mistral/mistral-tiny": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 2.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191
    },
    "mistral/open-codestral-mamba": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 2.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "mistral/open-mistral-7b": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 2.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191
    },
    "mistral/open-mistral-nemo": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "mistral/open-mistral-nemo-2407": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "mistral/open-mixtral-8x22b": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 6e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 65336,
        "max_output_tokens": 8191
    },
    "mistral/open-mixtral-8x7b": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 7e-07,
        "output_cost_per_token": 7e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191
    },
    "mistral/pixtral-12b-2409": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 1.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "mistral/pixtral-large-2411": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 6e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "mistral/pixtral-large-latest": {
        "litellm_provider": "mistral",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 6e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "moonshot.kimi-k2-thinking": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "moonshot/kimi-k2-0711-preview": {
        "litellm_provider": "moonshot",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": 1.5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "moonshot/kimi-k2-0905-preview": {
        "litellm_provider": "moonshot",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": 1.5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "moonshot/kimi-k2-turbo-preview": {
        "litellm_provider": "moonshot",
        "mode": "chat",
        "input_cost_per_token": 1.15e-06,
        "output_cost_per_token": 8e-06,
        "cache_read_input_token_cost": 1.5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "moonshot/kimi-k2.5": {
        "litellm_provider": "moonshot",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 3e-06,
        "cache_read_input_token_cost": 1e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "moonshot/kimi-latest": {
        "litellm_provider": "moonshot",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": 1.5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "moonshot/kimi-latest-128k": {
        "litellm_provider": "moonshot",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": 1.5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "moonshot/kimi-latest-32k": {
        "litellm_provider": "moonshot",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 3e-06,
        "cache_read_input_token_cost": 1.5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "moonshot/kimi-latest-8k": {
        "litellm_provider": "moonshot",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": 1.5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "moonshot/kimi-thinking-preview": {
        "litellm_provider": "moonshot",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": 1.5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "moonshot/kimi-k2-thinking": {
        "litellm_provider": "moonshot",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": 1.5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "moonshot/kimi-k2-thinking-turbo": {
        "litellm_provider": "moonshot",
        "mode": "chat",
        "input_cost_per_token": 1.15e-06,
        "output_cost_per_token": 8e-06,
        "cache_read_input_token_cost": 1.5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "moonshot/moonshot-v1-128k": {
        "litellm_provider": "moonshot",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "moonshot/moonshot-v1-128k-0430": {
        "litellm_provider": "moonshot",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "moonshot/moonshot-v1-128k-vision-preview": {
        "litellm_provider": "moonshot",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "moonshot/moonshot-v1-32k": {
        "litellm_provider": "moonshot",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 3e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "moonshot/moonshot-v1-32k-0430": {
        "litellm_provider": "moonshot",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 3e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "moonshot/moonshot-v1-32k-vision-preview": {
        "litellm_provider": "moonshot",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 3e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "moonshot/moonshot-v1-8k": {
        "litellm_provider": "moonshot",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "moonshot/moonshot-v1-8k-0430": {
        "litellm_provider": "moonshot",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "moonshot/moonshot-v1-8k-vision-preview": {
        "litellm_provider": "moonshot",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "moonshot/moonshot-v1-auto": {
        "litellm_provider": "moonshot",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "morph/morph-v3-fast": {
        "litellm_provider": "morph",
        "mode": "chat",
        "input_cost_per_token": 8e-07,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16000,
        "max_input_tokens": 16000,
        "max_output_tokens": 16000
    },
    "morph/morph-v3-large": {
        "litellm_provider": "morph",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 1.9e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16000,
        "max_input_tokens": 16000,
        "max_output_tokens": 16000
    },
    "multimodalembedding": {
        "litellm_provider": "vertex_ai-embedding-models",
        "mode": "embedding",
        "input_cost_per_token": 8e-07,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 2048,
        "max_output_tokens": null
    },
    "multimodalembedding@001": {
        "litellm_provider": "vertex_ai-embedding-models",
        "mode": "embedding",
        "input_cost_per_token": 8e-07,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 2048,
        "max_output_tokens": null
    },
    "nscale/Qwen/QwQ-32B": {
        "litellm_provider": "nscale",
        "mode": "chat",
        "input_cost_per_token": 1.8e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "nscale/Qwen/Qwen2.5-Coder-32B-Instruct": {
        "litellm_provider": "nscale",
        "mode": "chat",
        "input_cost_per_token": 6e-08,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "nscale/Qwen/Qwen2.5-Coder-3B-Instruct": {
        "litellm_provider": "nscale",
        "mode": "chat",
        "input_cost_per_token": 1e-08,
        "output_cost_per_token": 3e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "nscale/Qwen/Qwen2.5-Coder-7B-Instruct": {
        "litellm_provider": "nscale",
        "mode": "chat",
        "input_cost_per_token": 1e-08,
        "output_cost_per_token": 3e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "nscale/black-forest-labs/FLUX.1-schnell": {
        "litellm_provider": "nscale",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-70B": {
        "litellm_provider": "nscale",
        "mode": "chat",
        "input_cost_per_token": 3.75e-07,
        "output_cost_per_token": 3.75e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-8B": {
        "litellm_provider": "nscale",
        "mode": "chat",
        "input_cost_per_token": 2.5e-08,
        "output_cost_per_token": 2.5e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B": {
        "litellm_provider": "nscale",
        "mode": "chat",
        "input_cost_per_token": 9e-08,
        "output_cost_per_token": 9e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B": {
        "litellm_provider": "nscale",
        "mode": "chat",
        "input_cost_per_token": 7e-08,
        "output_cost_per_token": 7e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B": {
        "litellm_provider": "nscale",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 1.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B": {
        "litellm_provider": "nscale",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "nscale/meta-llama/Llama-3.1-8B-Instruct": {
        "litellm_provider": "nscale",
        "mode": "chat",
        "input_cost_per_token": 3e-08,
        "output_cost_per_token": 3e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "nscale/meta-llama/Llama-3.3-70B-Instruct": {
        "litellm_provider": "nscale",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "nscale/meta-llama/Llama-4-Scout-17B-16E-Instruct": {
        "litellm_provider": "nscale",
        "mode": "chat",
        "input_cost_per_token": 9e-08,
        "output_cost_per_token": 2.9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "nscale/mistralai/mixtral-8x22b-instruct-v0.1": {
        "litellm_provider": "nscale",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "nscale/stabilityai/stable-diffusion-xl-base-1.0": {
        "litellm_provider": "nscale",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "nvidia.nemotron-nano-12b-v2": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "nvidia.nemotron-nano-9b-v2": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 6e-08,
        "output_cost_per_token": 2.3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "o1": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 6e-05,
        "cache_read_input_token_cost": 7.5e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "o1-2024-12-17": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 6e-05,
        "cache_read_input_token_cost": 7.5e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "o1-mini": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1.1e-06,
        "output_cost_per_token": 4.4e-06,
        "cache_read_input_token_cost": 5.5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 128000,
        "max_output_tokens": 65536
    },
    "o1-mini-2024-09-12": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.2e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 128000,
        "max_output_tokens": 65536
    },
    "o1-preview": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 6e-05,
        "cache_read_input_token_cost": 7.5e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 128000,
        "max_output_tokens": 32768
    },
    "o1-preview-2024-09-12": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 6e-05,
        "cache_read_input_token_cost": 7.5e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 128000,
        "max_output_tokens": 32768
    },
    "o1-pro": {
        "litellm_provider": "openai",
        "mode": "responses",
        "input_cost_per_token": 0.00015,
        "output_cost_per_token": 0.0006,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "o1-pro-2025-03-19": {
        "litellm_provider": "openai",
        "mode": "responses",
        "input_cost_per_token": 0.00015,
        "output_cost_per_token": 0.0006,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "o3": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 8e-06,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "o3-2025-04-16": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 8e-06,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "o3-deep-research": {
        "litellm_provider": "openai",
        "mode": "responses",
        "input_cost_per_token": 1e-05,
        "output_cost_per_token": 4e-05,
        "cache_read_input_token_cost": 2.5e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "o3-deep-research-2025-06-26": {
        "litellm_provider": "openai",
        "mode": "responses",
        "input_cost_per_token": 1e-05,
        "output_cost_per_token": 4e-05,
        "cache_read_input_token_cost": 2.5e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "o3-mini": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1.1e-06,
        "output_cost_per_token": 4.4e-06,
        "cache_read_input_token_cost": 5.5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "o3-mini-2025-01-31": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1.1e-06,
        "output_cost_per_token": 4.4e-06,
        "cache_read_input_token_cost": 5.5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "o3-pro": {
        "litellm_provider": "openai",
        "mode": "responses",
        "input_cost_per_token": 2e-05,
        "output_cost_per_token": 8e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "o3-pro-2025-06-10": {
        "litellm_provider": "openai",
        "mode": "responses",
        "input_cost_per_token": 2e-05,
        "output_cost_per_token": 8e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "o4-mini": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1.1e-06,
        "output_cost_per_token": 4.4e-06,
        "cache_read_input_token_cost": 2.75e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "o4-mini-2025-04-16": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 1.1e-06,
        "output_cost_per_token": 4.4e-06,
        "cache_read_input_token_cost": 2.75e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "o4-mini-deep-research": {
        "litellm_provider": "openai",
        "mode": "responses",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 8e-06,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "o4-mini-deep-research-2025-06-26": {
        "litellm_provider": "openai",
        "mode": "responses",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 8e-06,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "oci/meta.llama-3.1-405b-instruct": {
        "litellm_provider": "oci",
        "mode": "chat",
        "input_cost_per_token": 1.068e-05,
        "output_cost_per_token": 1.068e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4000,
        "max_input_tokens": 128000,
        "max_output_tokens": 4000
    },
    "oci/meta.llama-3.2-90b-vision-instruct": {
        "litellm_provider": "oci",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4000,
        "max_input_tokens": 128000,
        "max_output_tokens": 4000
    },
    "oci/meta.llama-3.3-70b-instruct": {
        "litellm_provider": "oci",
        "mode": "chat",
        "input_cost_per_token": 7.2e-07,
        "output_cost_per_token": 7.2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4000,
        "max_input_tokens": 128000,
        "max_output_tokens": 4000
    },
    "oci/meta.llama-4-maverick-17b-128e-instruct-fp8": {
        "litellm_provider": "oci",
        "mode": "chat",
        "input_cost_per_token": 7.2e-07,
        "output_cost_per_token": 7.2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4000,
        "max_input_tokens": 512000,
        "max_output_tokens": 4000
    },
    "oci/meta.llama-4-scout-17b-16e-instruct": {
        "litellm_provider": "oci",
        "mode": "chat",
        "input_cost_per_token": 7.2e-07,
        "output_cost_per_token": 7.2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4000,
        "max_input_tokens": 192000,
        "max_output_tokens": 4000
    },
    "oci/xai.grok-3": {
        "litellm_provider": "oci",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "oci/xai.grok-3-fast": {
        "litellm_provider": "oci",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 2.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "oci/xai.grok-3-mini": {
        "litellm_provider": "oci",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "oci/xai.grok-3-mini-fast": {
        "litellm_provider": "oci",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "oci/xai.grok-4": {
        "litellm_provider": "oci",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "oci/cohere.command-latest": {
        "litellm_provider": "oci",
        "mode": "chat",
        "input_cost_per_token": 1.56e-06,
        "output_cost_per_token": 1.56e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4000,
        "max_input_tokens": 128000,
        "max_output_tokens": 4000
    },
    "oci/cohere.command-a-03-2025": {
        "litellm_provider": "oci",
        "mode": "chat",
        "input_cost_per_token": 1.56e-06,
        "output_cost_per_token": 1.56e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4000,
        "max_input_tokens": 256000,
        "max_output_tokens": 4000
    },
    "oci/cohere.command-plus-latest": {
        "litellm_provider": "oci",
        "mode": "chat",
        "input_cost_per_token": 1.56e-06,
        "output_cost_per_token": 1.56e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4000,
        "max_input_tokens": 128000,
        "max_output_tokens": 4000
    },
    "ollama/codegeex4": {
        "litellm_provider": "ollama",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 32768,
        "max_output_tokens": 8192
    },
    "ollama/codegemma": {
        "litellm_provider": "ollama",
        "mode": "completion",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "ollama/codellama": {
        "litellm_provider": "ollama",
        "mode": "completion",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "ollama/deepseek-coder-v2-base": {
        "litellm_provider": "ollama",
        "mode": "completion",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "ollama/deepseek-coder-v2-instruct": {
        "litellm_provider": "ollama",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 32768,
        "max_output_tokens": 8192
    },
    "ollama/deepseek-coder-v2-lite-base": {
        "litellm_provider": "ollama",
        "mode": "completion",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "ollama/deepseek-coder-v2-lite-instruct": {
        "litellm_provider": "ollama",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 32768,
        "max_output_tokens": 8192
    },
    "ollama/deepseek-v3.1:671b-cloud": {
        "litellm_provider": "ollama",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840
    },
    "ollama/gpt-oss:120b-cloud": {
        "litellm_provider": "ollama",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "ollama/gpt-oss:20b-cloud": {
        "litellm_provider": "ollama",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "ollama/internlm2_5-20b-chat": {
        "litellm_provider": "ollama",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 32768,
        "max_output_tokens": 8192
    },
    "ollama/llama2": {
        "litellm_provider": "ollama",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "ollama/llama2-uncensored": {
        "litellm_provider": "ollama",
        "mode": "completion",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "ollama/llama2:13b": {
        "litellm_provider": "ollama",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "ollama/llama2:70b": {
        "litellm_provider": "ollama",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "ollama/llama2:7b": {
        "litellm_provider": "ollama",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "ollama/llama3": {
        "litellm_provider": "ollama",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "ollama/llama3.1": {
        "litellm_provider": "ollama",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "ollama/llama3:70b": {
        "litellm_provider": "ollama",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "ollama/llama3:8b": {
        "litellm_provider": "ollama",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "ollama/mistral": {
        "litellm_provider": "ollama",
        "mode": "completion",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "ollama/mistral-7B-Instruct-v0.1": {
        "litellm_provider": "ollama",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "ollama/mistral-7B-Instruct-v0.2": {
        "litellm_provider": "ollama",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "ollama/mistral-large-instruct-2407": {
        "litellm_provider": "ollama",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 65536,
        "max_output_tokens": 8192
    },
    "ollama/mixtral-8x22B-Instruct-v0.1": {
        "litellm_provider": "ollama",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 65536,
        "max_output_tokens": 65536
    },
    "ollama/mixtral-8x7B-Instruct-v0.1": {
        "litellm_provider": "ollama",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "ollama/orca-mini": {
        "litellm_provider": "ollama",
        "mode": "completion",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "ollama/qwen3-coder:480b-cloud": {
        "litellm_provider": "ollama",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "ollama/vicuna": {
        "litellm_provider": "ollama",
        "mode": "completion",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 2048,
        "max_output_tokens": 2048
    },
    "omni-moderation-2024-09-26": {
        "litellm_provider": "openai",
        "mode": "moderation",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 0,
        "max_input_tokens": 32768,
        "max_output_tokens": 0
    },
    "omni-moderation-latest": {
        "litellm_provider": "openai",
        "mode": "moderation",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 0,
        "max_input_tokens": 32768,
        "max_output_tokens": 0
    },
    "omni-moderation-latest-intents": {
        "litellm_provider": "openai",
        "mode": "moderation",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 0,
        "max_input_tokens": 32768,
        "max_output_tokens": 0
    },
    "openai.gpt-oss-120b-1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "openai.gpt-oss-20b-1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 7e-08,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "openai.gpt-oss-safeguard-120b": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "openai.gpt-oss-safeguard-20b": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 7e-08,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "openrouter/anthropic/claude-2": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.102e-05,
        "output_cost_per_token": 3.268e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": null,
        "max_output_tokens": 8191
    },
    "openrouter/anthropic/claude-3-5-haiku": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 200000,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/anthropic/claude-3-5-haiku-20241022": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "openrouter/anthropic/claude-3-haiku": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 1.25e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 200000,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/anthropic/claude-3-haiku-20240307": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 1.25e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "openrouter/anthropic/claude-3-opus": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "openrouter/anthropic/claude-3-sonnet": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 200000,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/anthropic/claude-3.5-sonnet": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "openrouter/anthropic/claude-3.5-sonnet:beta": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "openrouter/anthropic/claude-3.7-sonnet": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 200000,
        "max_output_tokens": 128000
    },
    "openrouter/anthropic/claude-3.7-sonnet:beta": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 200000,
        "max_output_tokens": 128000
    },
    "openrouter/anthropic/claude-instant-v1": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.63e-06,
        "output_cost_per_token": 5.51e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": null,
        "max_output_tokens": 8191
    },
    "openrouter/anthropic/claude-opus-4": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "cache_creation_input_token_cost": 1.875e-05,
        "max_tokens": 32000,
        "max_input_tokens": 200000,
        "max_output_tokens": 32000
    },
    "openrouter/anthropic/claude-opus-4.1": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "cache_creation_input_token_cost": 1.875e-05,
        "max_tokens": 32000,
        "max_input_tokens": 200000,
        "max_output_tokens": 32000
    },
    "openrouter/anthropic/claude-sonnet-4": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 64000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000
    },
    "openrouter/anthropic/claude-opus-4.5": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 2.5e-05,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": 6.25e-06,
        "max_tokens": 32000,
        "max_input_tokens": 200000,
        "max_output_tokens": 32000
    },
    "openrouter/anthropic/claude-sonnet-4.5": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 1000000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 1000000
    },
    "openrouter/anthropic/claude-haiku-4.5": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": 1e-07,
        "cache_creation_input_token_cost": 1.25e-06,
        "max_tokens": 200000,
        "max_input_tokens": 200000,
        "max_output_tokens": 200000
    },
    "openrouter/bytedance/ui-tars-1.5-7b": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 131072,
        "max_output_tokens": 2048
    },
    "openrouter/cognitivecomputations/dolphin-mixtral-8x7b": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32769,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/cohere/command-r-plus": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/databricks/dbrx-instruct": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/deepseek/deepseek-chat": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.4e-07,
        "output_cost_per_token": 2.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 65536,
        "max_output_tokens": 8192
    },
    "openrouter/deepseek/deepseek-chat-v3-0324": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.4e-07,
        "output_cost_per_token": 2.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 65536,
        "max_output_tokens": 8192
    },
    "openrouter/deepseek/deepseek-chat-v3.1": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840
    },
    "openrouter/deepseek/deepseek-v3.2": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 2.8e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840
    },
    "openrouter/deepseek/deepseek-v3.2-exp": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840
    },
    "openrouter/deepseek/deepseek-coder": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.4e-07,
        "output_cost_per_token": 2.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 66000,
        "max_output_tokens": 4096
    },
    "openrouter/deepseek/deepseek-r1": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 5.5e-07,
        "output_cost_per_token": 2.19e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 65336,
        "max_output_tokens": 8192
    },
    "openrouter/deepseek/deepseek-r1-0528": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 2.15e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 65336,
        "max_output_tokens": 8192
    },
    "openrouter/fireworks/firellava-13b": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/google/gemini-2.0-flash-001": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192
    },
    "openrouter/google/gemini-2.5-flash": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192
    },
    "openrouter/google/gemini-2.5-pro": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192
    },
    "openrouter/google/gemini-3-pro-preview": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 1.2e-05,
        "cache_read_input_token_cost": 2e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "openrouter/google/gemini-3-flash-preview": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 3e-06,
        "cache_read_input_token_cost": 5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65535,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535
    },
    "openrouter/google/gemini-pro-1.5": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 7.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192
    },
    "openrouter/google/gemini-pro-vision": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 3.75e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 45875,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/google/palm-2-chat-bison": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 25804,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/google/palm-2-codechat-bison": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 20070,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/gryphe/mythomax-l2-13b": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.875e-06,
        "output_cost_per_token": 1.875e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/jondurbin/airoboros-l2-70b-2.1": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.3875e-05,
        "output_cost_per_token": 1.3875e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/mancer/weaver": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 5.625e-06,
        "output_cost_per_token": 5.625e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8000,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/meta-llama/codellama-34b-instruct": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/meta-llama/llama-2-13b-chat": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/meta-llama/llama-2-70b-chat": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.5e-06,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/meta-llama/llama-3-70b-instruct": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 5.9e-07,
        "output_cost_per_token": 7.9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/meta-llama/llama-3-70b-instruct:nitro": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/meta-llama/llama-3-8b-instruct:extended": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 2.25e-07,
        "output_cost_per_token": 2.25e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/meta-llama/llama-3-8b-instruct:free": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/microsoft/wizardlm-2-8x22b:nitro": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 1e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/minimax/minimax-m2": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 2.55e-07,
        "output_cost_per_token": 1.02e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 204800,
        "max_input_tokens": 204800,
        "max_output_tokens": 204800
    },
    "openrouter/mistralai/devstral-2512:free": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "openrouter/mistralai/devstral-2512": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 262144,
        "max_output_tokens": 65536
    },
    "openrouter/mistralai/ministral-3b-2512": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "openrouter/mistralai/ministral-8b-2512": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 1.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "openrouter/mistralai/ministral-14b-2512": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "openrouter/mistralai/mistral-large-2512": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "openrouter/mistralai/mistral-7b-instruct": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.3e-07,
        "output_cost_per_token": 1.3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/mistralai/mistral-7b-instruct:free": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/mistralai/mistral-large": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 8e-06,
        "output_cost_per_token": 2.4e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/mistralai/mistral-small-3.1-24b-instruct": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/mistralai/mistral-small-3.2-24b-instruct": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/mistralai/mixtral-8x22b-instruct": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 6.5e-07,
        "output_cost_per_token": 6.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/moonshotai/kimi-k2.5": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 3e-06,
        "cache_read_input_token_cost": 1e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "openrouter/nousresearch/nous-hermes-llama2-13b": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/openai/gpt-3.5-turbo": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.5e-06,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4095,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/openai/gpt-3.5-turbo-16k": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16383,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/openai/gpt-4": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 3e-05,
        "output_cost_per_token": 6e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/openai/gpt-4-vision-preview": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1e-05,
        "output_cost_per_token": 3e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 130000,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/openai/gpt-4.1": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 8e-06,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768
    },
    "openrouter/openai/gpt-4.1-2025-04-14": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 8e-06,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768
    },
    "openrouter/openai/gpt-4.1-mini": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 1.6e-06,
        "cache_read_input_token_cost": 1e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768
    },
    "openrouter/openai/gpt-4.1-mini-2025-04-14": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 1.6e-06,
        "cache_read_input_token_cost": 1e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768
    },
    "openrouter/openai/gpt-4.1-nano": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": 2.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768
    },
    "openrouter/openai/gpt-4.1-nano-2025-04-14": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": 2.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768
    },
    "openrouter/openai/gpt-4o": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "openrouter/openai/gpt-4o-2024-05-13": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "openrouter/openai/gpt-5-chat": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "openrouter/openai/gpt-5-codex": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "openrouter/openai/gpt-5.2-codex": {
        "litellm_provider": "openrouter",
        "mode": "responses",
        "input_cost_per_token": 1.75e-06,
        "output_cost_per_token": 1.4e-05,
        "cache_read_input_token_cost": 1.75e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "openrouter/openai/gpt-5": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "openrouter/openai/gpt-5-mini": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": 2.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "openrouter/openai/gpt-5-nano": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": 5e-09,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "openrouter/openai/gpt-5.2": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.75e-06,
        "output_cost_per_token": 1.4e-05,
        "cache_read_input_token_cost": 1.75e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "openrouter/openai/gpt-5.2-chat": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.75e-06,
        "output_cost_per_token": 1.4e-05,
        "cache_read_input_token_cost": 1.75e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "openrouter/openai/gpt-5.2-pro": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 2.1e-05,
        "output_cost_per_token": 0.000168,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 272000,
        "max_output_tokens": 128000
    },
    "openrouter/openai/gpt-oss-120b": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.8e-07,
        "output_cost_per_token": 8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 131072,
        "max_output_tokens": 32768
    },
    "openrouter/openai/gpt-oss-20b": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 2e-08,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 131072,
        "max_output_tokens": 32768
    },
    "openrouter/openai/o1": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 6e-05,
        "cache_read_input_token_cost": 7.5e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "openrouter/openai/o1-mini": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.2e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 128000,
        "max_output_tokens": 65536
    },
    "openrouter/openai/o1-mini-2024-09-12": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.2e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 128000,
        "max_output_tokens": 65536
    },
    "openrouter/openai/o1-preview": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 6e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 128000,
        "max_output_tokens": 32768
    },
    "openrouter/openai/o1-preview-2024-09-12": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 6e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 128000,
        "max_output_tokens": 32768
    },
    "openrouter/openai/o3-mini": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.1e-06,
        "output_cost_per_token": 4.4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 128000,
        "max_output_tokens": 65536
    },
    "openrouter/openai/o3-mini-high": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.1e-06,
        "output_cost_per_token": 4.4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 128000,
        "max_output_tokens": 65536
    },
    "openrouter/pygmalionai/mythalion-13b": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.875e-06,
        "output_cost_per_token": 1.875e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/qwen/qwen-2.5-coder-32b-instruct": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.8e-07,
        "output_cost_per_token": 1.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 33792,
        "max_input_tokens": 33792,
        "max_output_tokens": 33792
    },
    "openrouter/qwen/qwen-vl-plus": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 2.1e-07,
        "output_cost_per_token": 6.3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 8192,
        "max_output_tokens": 2048
    },
    "openrouter/qwen/qwen3-coder": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 2.2e-07,
        "output_cost_per_token": 9.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262100,
        "max_input_tokens": 262100,
        "max_output_tokens": 262100
    },
    "openrouter/qwen/qwen3-235b-a22b-2507": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 7.1e-08,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "openrouter/qwen/qwen3-235b-a22b-thinking-2507": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.1e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "openrouter/switchpoint/router": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 8.5e-07,
        "output_cost_per_token": 3.4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "openrouter/undi95/remm-slerp-l2-13b": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 1.875e-06,
        "output_cost_per_token": 1.875e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 6144,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openrouter/x-ai/grok-4": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "openrouter/x-ai/grok-4-fast:free": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 30000,
        "max_input_tokens": 2000000,
        "max_output_tokens": 30000
    },
    "openrouter/z-ai/glm-4.6": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 1.75e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131000,
        "max_input_tokens": 202800,
        "max_output_tokens": 131000
    },
    "openrouter/z-ai/glm-4.6:exacto": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 4.5e-07,
        "output_cost_per_token": 1.9e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131000,
        "max_input_tokens": 202800,
        "max_output_tokens": 131000
    },
    "openrouter/xiaomi/mimo-v2-flash": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 9e-08,
        "output_cost_per_token": 2.9e-07,
        "cache_read_input_token_cost": 0.0,
        "cache_creation_input_token_cost": 0.0,
        "max_tokens": 16384,
        "max_input_tokens": 262144,
        "max_output_tokens": 16384
    },
    "openrouter/z-ai/glm-4.7": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": 0.0,
        "cache_creation_input_token_cost": 0.0,
        "max_tokens": 64000,
        "max_input_tokens": 202752,
        "max_output_tokens": 64000
    },
    "openrouter/z-ai/glm-4.7-flash": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 7e-08,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": 0.0,
        "cache_creation_input_token_cost": 0.0,
        "max_tokens": 32000,
        "max_input_tokens": 200000,
        "max_output_tokens": 32000
    },
    "openrouter/minimax/minimax-m2.1": {
        "litellm_provider": "openrouter",
        "mode": "chat",
        "input_cost_per_token": 2.7e-07,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": 0.0,
        "cache_creation_input_token_cost": 0.0,
        "max_tokens": 64000,
        "max_input_tokens": 204000,
        "max_output_tokens": 64000
    },
    "ovhcloud/DeepSeek-R1-Distill-Llama-70B": {
        "litellm_provider": "ovhcloud",
        "mode": "chat",
        "input_cost_per_token": 6.7e-07,
        "output_cost_per_token": 6.7e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131000,
        "max_input_tokens": 131000,
        "max_output_tokens": 131000
    },
    "ovhcloud/Llama-3.1-8B-Instruct": {
        "litellm_provider": "ovhcloud",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131000,
        "max_input_tokens": 131000,
        "max_output_tokens": 131000
    },
    "ovhcloud/Meta-Llama-3_1-70B-Instruct": {
        "litellm_provider": "ovhcloud",
        "mode": "chat",
        "input_cost_per_token": 6.7e-07,
        "output_cost_per_token": 6.7e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131000,
        "max_input_tokens": 131000,
        "max_output_tokens": 131000
    },
    "ovhcloud/Meta-Llama-3_3-70B-Instruct": {
        "litellm_provider": "ovhcloud",
        "mode": "chat",
        "input_cost_per_token": 6.7e-07,
        "output_cost_per_token": 6.7e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131000,
        "max_input_tokens": 131000,
        "max_output_tokens": 131000
    },
    "ovhcloud/Mistral-7B-Instruct-v0.3": {
        "litellm_provider": "ovhcloud",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 127000,
        "max_input_tokens": 127000,
        "max_output_tokens": 127000
    },
    "ovhcloud/Mistral-Nemo-Instruct-2407": {
        "litellm_provider": "ovhcloud",
        "mode": "chat",
        "input_cost_per_token": 1.3e-07,
        "output_cost_per_token": 1.3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 118000,
        "max_input_tokens": 118000,
        "max_output_tokens": 118000
    },
    "ovhcloud/Mistral-Small-3.2-24B-Instruct-2506": {
        "litellm_provider": "ovhcloud",
        "mode": "chat",
        "input_cost_per_token": 9e-08,
        "output_cost_per_token": 2.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "ovhcloud/Mixtral-8x7B-Instruct-v0.1": {
        "litellm_provider": "ovhcloud",
        "mode": "chat",
        "input_cost_per_token": 6.3e-07,
        "output_cost_per_token": 6.3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "max_output_tokens": 32000
    },
    "ovhcloud/Qwen2.5-Coder-32B-Instruct": {
        "litellm_provider": "ovhcloud",
        "mode": "chat",
        "input_cost_per_token": 8.7e-07,
        "output_cost_per_token": 8.7e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "max_output_tokens": 32000
    },
    "ovhcloud/Qwen2.5-VL-72B-Instruct": {
        "litellm_provider": "ovhcloud",
        "mode": "chat",
        "input_cost_per_token": 9.1e-07,
        "output_cost_per_token": 9.1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "max_output_tokens": 32000
    },
    "ovhcloud/Qwen3-32B": {
        "litellm_provider": "ovhcloud",
        "mode": "chat",
        "input_cost_per_token": 8e-08,
        "output_cost_per_token": 2.3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "max_output_tokens": 32000
    },
    "ovhcloud/gpt-oss-120b": {
        "litellm_provider": "ovhcloud",
        "mode": "chat",
        "input_cost_per_token": 8e-08,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131000,
        "max_input_tokens": 131000,
        "max_output_tokens": 131000
    },
    "ovhcloud/gpt-oss-20b": {
        "litellm_provider": "ovhcloud",
        "mode": "chat",
        "input_cost_per_token": 4e-08,
        "output_cost_per_token": 1.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131000,
        "max_input_tokens": 131000,
        "max_output_tokens": 131000
    },
    "ovhcloud/llava-v1.6-mistral-7b-hf": {
        "litellm_provider": "ovhcloud",
        "mode": "chat",
        "input_cost_per_token": 2.9e-07,
        "output_cost_per_token": 2.9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "max_output_tokens": 32000
    },
    "ovhcloud/mamba-codestral-7B-v0.1": {
        "litellm_provider": "ovhcloud",
        "mode": "chat",
        "input_cost_per_token": 1.9e-07,
        "output_cost_per_token": 1.9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "palm/chat-bison": {
        "litellm_provider": "palm",
        "mode": "chat",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 1.25e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096
    },
    "palm/chat-bison-001": {
        "litellm_provider": "palm",
        "mode": "chat",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 1.25e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096
    },
    "palm/text-bison": {
        "litellm_provider": "palm",
        "mode": "completion",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 1.25e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 8192,
        "max_output_tokens": 1024
    },
    "palm/text-bison-001": {
        "litellm_provider": "palm",
        "mode": "completion",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 1.25e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 8192,
        "max_output_tokens": 1024
    },
    "palm/text-bison-safety-off": {
        "litellm_provider": "palm",
        "mode": "completion",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 1.25e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 8192,
        "max_output_tokens": 1024
    },
    "palm/text-bison-safety-recitation-off": {
        "litellm_provider": "palm",
        "mode": "completion",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 1.25e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 8192,
        "max_output_tokens": 1024
    },
    "parallel_ai/search": {
        "litellm_provider": "parallel_ai",
        "mode": "search",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "parallel_ai/search-pro": {
        "litellm_provider": "parallel_ai",
        "mode": "search",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "perplexity/codellama-34b-instruct": {
        "litellm_provider": "perplexity",
        "mode": "chat",
        "input_cost_per_token": 3.5e-07,
        "output_cost_per_token": 1.4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "perplexity/codellama-70b-instruct": {
        "litellm_provider": "perplexity",
        "mode": "chat",
        "input_cost_per_token": 7e-07,
        "output_cost_per_token": 2.8e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "perplexity/llama-2-70b-chat": {
        "litellm_provider": "perplexity",
        "mode": "chat",
        "input_cost_per_token": 7e-07,
        "output_cost_per_token": 2.8e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "perplexity/llama-3.1-70b-instruct": {
        "litellm_provider": "perplexity",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 1e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "perplexity/llama-3.1-8b-instruct": {
        "litellm_provider": "perplexity",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "perplexity/llama-3.1-sonar-huge-128k-online": {
        "litellm_provider": "perplexity",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 127072,
        "max_input_tokens": 127072,
        "max_output_tokens": 127072
    },
    "perplexity/llama-3.1-sonar-large-128k-chat": {
        "litellm_provider": "perplexity",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 1e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "perplexity/llama-3.1-sonar-large-128k-online": {
        "litellm_provider": "perplexity",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 1e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 127072,
        "max_input_tokens": 127072,
        "max_output_tokens": 127072
    },
    "perplexity/llama-3.1-sonar-small-128k-chat": {
        "litellm_provider": "perplexity",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "perplexity/llama-3.1-sonar-small-128k-online": {
        "litellm_provider": "perplexity",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 127072,
        "max_input_tokens": 127072,
        "max_output_tokens": 127072
    },
    "perplexity/mistral-7b-instruct": {
        "litellm_provider": "perplexity",
        "mode": "chat",
        "input_cost_per_token": 7e-08,
        "output_cost_per_token": 2.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "perplexity/mixtral-8x7b-instruct": {
        "litellm_provider": "perplexity",
        "mode": "chat",
        "input_cost_per_token": 7e-08,
        "output_cost_per_token": 2.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "perplexity/pplx-70b-chat": {
        "litellm_provider": "perplexity",
        "mode": "chat",
        "input_cost_per_token": 7e-07,
        "output_cost_per_token": 2.8e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "perplexity/pplx-70b-online": {
        "litellm_provider": "perplexity",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 2.8e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "perplexity/pplx-7b-chat": {
        "litellm_provider": "perplexity",
        "mode": "chat",
        "input_cost_per_token": 7e-08,
        "output_cost_per_token": 2.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "perplexity/pplx-7b-online": {
        "litellm_provider": "perplexity",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 2.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "perplexity/sonar": {
        "litellm_provider": "perplexity",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 1e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": null
    },
    "perplexity/sonar-deep-research": {
        "litellm_provider": "perplexity",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 8e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": null
    },
    "perplexity/sonar-medium-chat": {
        "litellm_provider": "perplexity",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 1.8e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "perplexity/sonar-medium-online": {
        "litellm_provider": "perplexity",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 1.8e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 12000,
        "max_input_tokens": 12000,
        "max_output_tokens": 12000
    },
    "perplexity/sonar-pro": {
        "litellm_provider": "perplexity",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8000,
        "max_input_tokens": 200000,
        "max_output_tokens": 8000
    },
    "perplexity/sonar-reasoning": {
        "litellm_provider": "perplexity",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": null
    },
    "perplexity/sonar-reasoning-pro": {
        "litellm_provider": "perplexity",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 8e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": null
    },
    "perplexity/sonar-small-chat": {
        "litellm_provider": "perplexity",
        "mode": "chat",
        "input_cost_per_token": 7e-08,
        "output_cost_per_token": 2.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "perplexity/sonar-small-online": {
        "litellm_provider": "perplexity",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 2.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 12000,
        "max_input_tokens": 12000,
        "max_output_tokens": 12000
    },
    "publicai/swiss-ai/apertus-8b-instruct": {
        "litellm_provider": "publicai",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096
    },
    "publicai/swiss-ai/apertus-70b-instruct": {
        "litellm_provider": "publicai",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096
    },
    "publicai/aisingapore/Gemma-SEA-LION-v4-27B-IT": {
        "litellm_provider": "publicai",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096
    },
    "publicai/BSC-LT/salamandra-7b-instruct-tools-16k": {
        "litellm_provider": "publicai",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 16384,
        "max_output_tokens": 4096
    },
    "publicai/BSC-LT/ALIA-40b-instruct_Q8_0": {
        "litellm_provider": "publicai",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096
    },
    "publicai/allenai/Olmo-3-7B-Instruct": {
        "litellm_provider": "publicai",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 32768,
        "max_output_tokens": 4096
    },
    "publicai/aisingapore/Qwen-SEA-LION-v4-32B-IT": {
        "litellm_provider": "publicai",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 32768,
        "max_output_tokens": 4096
    },
    "publicai/allenai/Olmo-3-7B-Think": {
        "litellm_provider": "publicai",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 32768,
        "max_output_tokens": 4096
    },
    "publicai/allenai/Olmo-3-32B-Think": {
        "litellm_provider": "publicai",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 32768,
        "max_output_tokens": 4096
    },
    "qwen.qwen3-coder-480b-a35b-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 2.2e-07,
        "output_cost_per_token": 1.8e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 262000,
        "max_output_tokens": 65536
    },
    "qwen.qwen3-235b-a22b-2507-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 2.2e-07,
        "output_cost_per_token": 8.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 262144,
        "max_output_tokens": 131072
    },
    "qwen.qwen3-coder-30b-a3b-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 262144,
        "max_output_tokens": 131072
    },
    "qwen.qwen3-32b-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 131072,
        "max_output_tokens": 16384
    },
    "qwen.qwen3-next-80b-a3b": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "qwen.qwen3-vl-235b-a22b": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 5.3e-07,
        "output_cost_per_token": 2.66e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "recraft/recraftv2": {
        "litellm_provider": "recraft",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "recraft/recraftv3": {
        "litellm_provider": "recraft",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "replicate/meta/llama-2-13b": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "replicate/meta/llama-2-13b-chat": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "replicate/meta/llama-2-70b": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 6.5e-07,
        "output_cost_per_token": 2.75e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "replicate/meta/llama-2-70b-chat": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 6.5e-07,
        "output_cost_per_token": 2.75e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "replicate/meta/llama-2-7b": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 2.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "replicate/meta/llama-2-7b-chat": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 2.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "replicate/meta/llama-3-70b": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 6.5e-07,
        "output_cost_per_token": 2.75e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "replicate/meta/llama-3-70b-instruct": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 6.5e-07,
        "output_cost_per_token": 2.75e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "replicate/meta/llama-3-8b": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 2.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8086,
        "max_input_tokens": 8086,
        "max_output_tokens": 8086
    },
    "replicate/meta/llama-3-8b-instruct": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 2.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8086,
        "max_input_tokens": 8086,
        "max_output_tokens": 8086
    },
    "replicate/mistralai/mistral-7b-instruct-v0.2": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 2.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "replicate/mistralai/mistral-7b-v0.1": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 2.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "replicate/mistralai/mixtral-8x7b-instruct-v0.1": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 1e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "replicate/openai/gpt-5": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "replicateopenai/gpt-oss-20b": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 9e-08,
        "output_cost_per_token": 3.6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "replicate/anthropic/claude-4.5-haiku": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "replicate/ibm-granite/granite-3.3-8b-instruct": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 3e-08,
        "output_cost_per_token": 2.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "replicate/openai/gpt-4o": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "replicate/openai/o4-mini": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "replicate/openai/o1-mini": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 1.1e-06,
        "output_cost_per_token": 4.4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "replicate/openai/o1": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 6e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "replicate/openai/gpt-4o-mini": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "replicate/qwen/qwen3-235b-a22b-instruct-2507": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 2.64e-07,
        "output_cost_per_token": 1.06e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "replicate/anthropic/claude-4-sonnet": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "replicate/deepseek-ai/deepseek-v3": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 1.45e-06,
        "output_cost_per_token": 1.45e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 65536,
        "max_output_tokens": 8192
    },
    "replicate/anthropic/claude-3.7-sonnet": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "replicate/anthropic/claude-3.5-haiku": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "replicate/anthropic/claude-3.5-sonnet": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 3.75e-06,
        "output_cost_per_token": 1.875e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "replicate/google/gemini-3-pro": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 1.2e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "replicate/anthropic/claude-4.5-sonnet": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "replicate/openai/gpt-4.1": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 8e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "replicate/openai/gpt-4.1-nano": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "replicate/openai/gpt-4.1-mini": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 1.6e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "replicate/openai/gpt-5-nano": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "replicate/openai/gpt-5-mini": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "replicate/google/gemini-2.5-flash": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "replicate/openai/gpt-oss-120b": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 1.8e-07,
        "output_cost_per_token": 7.2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "replicate/deepseek-ai/deepseek-v3.1": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 6.72e-07,
        "output_cost_per_token": 2.016e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840
    },
    "replicate/xai/grok-4": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 7.2e-06,
        "output_cost_per_token": 3.6e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "replicate/deepseek-ai/deepseek-r1": {
        "litellm_provider": "replicate",
        "mode": "chat",
        "input_cost_per_token": 3.75e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 65536,
        "max_output_tokens": 8192
    },
    "rerank-english-v2.0": {
        "litellm_provider": "cohere",
        "mode": "rerank",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "rerank-english-v3.0": {
        "litellm_provider": "cohere",
        "mode": "rerank",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "rerank-multilingual-v2.0": {
        "litellm_provider": "cohere",
        "mode": "rerank",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "rerank-multilingual-v3.0": {
        "litellm_provider": "cohere",
        "mode": "rerank",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "rerank-v3.5": {
        "litellm_provider": "cohere",
        "mode": "rerank",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "nvidia_nim/nvidia/nv-rerankqa-mistral-4b-v3": {
        "litellm_provider": "nvidia_nim",
        "mode": "rerank",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "nvidia_nim/nvidia/llama-3_2-nv-rerankqa-1b-v2": {
        "litellm_provider": "nvidia_nim",
        "mode": "rerank",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "nvidia_nim/ranking/nvidia/llama-3.2-nv-rerankqa-1b-v2": {
        "litellm_provider": "nvidia_nim",
        "mode": "rerank",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "sagemaker/meta-textgeneration-llama-2-13b": {
        "litellm_provider": "sagemaker",
        "mode": "completion",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "sagemaker/meta-textgeneration-llama-2-13b-f": {
        "litellm_provider": "sagemaker",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "sagemaker/meta-textgeneration-llama-2-70b": {
        "litellm_provider": "sagemaker",
        "mode": "completion",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "sagemaker/meta-textgeneration-llama-2-70b-b-f": {
        "litellm_provider": "sagemaker",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "sagemaker/meta-textgeneration-llama-2-7b": {
        "litellm_provider": "sagemaker",
        "mode": "completion",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "sagemaker/meta-textgeneration-llama-2-7b-f": {
        "litellm_provider": "sagemaker",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "sambanova/DeepSeek-R1": {
        "litellm_provider": "sambanova",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 7e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "sambanova/DeepSeek-R1-Distill-Llama-70B": {
        "litellm_provider": "sambanova",
        "mode": "chat",
        "input_cost_per_token": 7e-07,
        "output_cost_per_token": 1.4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "sambanova/DeepSeek-V3-0324": {
        "litellm_provider": "sambanova",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 4.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "sambanova/Llama-4-Maverick-17B-128E-Instruct": {
        "litellm_provider": "sambanova",
        "mode": "chat",
        "input_cost_per_token": 6.3e-07,
        "output_cost_per_token": 1.8e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "sambanova/Llama-4-Scout-17B-16E-Instruct": {
        "litellm_provider": "sambanova",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 7e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "sambanova/Meta-Llama-3.1-405B-Instruct": {
        "litellm_provider": "sambanova",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "sambanova/Meta-Llama-3.1-8B-Instruct": {
        "litellm_provider": "sambanova",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "sambanova/Meta-Llama-3.2-1B-Instruct": {
        "litellm_provider": "sambanova",
        "mode": "chat",
        "input_cost_per_token": 4e-08,
        "output_cost_per_token": 8e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "sambanova/Meta-Llama-3.2-3B-Instruct": {
        "litellm_provider": "sambanova",
        "mode": "chat",
        "input_cost_per_token": 8e-08,
        "output_cost_per_token": 1.6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "sambanova/Meta-Llama-3.3-70B-Instruct": {
        "litellm_provider": "sambanova",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "sambanova/Meta-Llama-Guard-3-8B": {
        "litellm_provider": "sambanova",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "sambanova/QwQ-32B": {
        "litellm_provider": "sambanova",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "sambanova/Qwen2-Audio-7B-Instruct": {
        "litellm_provider": "sambanova",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 0.0001,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "sambanova/Qwen3-32B": {
        "litellm_provider": "sambanova",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "sambanova/DeepSeek-V3.1": {
        "litellm_provider": "sambanova",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 4.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "sambanova/gpt-oss-120b": {
        "litellm_provider": "sambanova",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 4.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "snowflake/claude-3-5-sonnet": {
        "litellm_provider": "snowflake",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 18000,
        "max_output_tokens": 8192
    },
    "snowflake/deepseek-r1": {
        "litellm_provider": "snowflake",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 32768,
        "max_output_tokens": 8192
    },
    "snowflake/gemma-7b": {
        "litellm_provider": "snowflake",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8000,
        "max_output_tokens": 8192
    },
    "snowflake/jamba-1.5-large": {
        "litellm_provider": "snowflake",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 256000,
        "max_output_tokens": 8192
    },
    "snowflake/jamba-1.5-mini": {
        "litellm_provider": "snowflake",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 256000,
        "max_output_tokens": 8192
    },
    "snowflake/jamba-instruct": {
        "litellm_provider": "snowflake",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 256000,
        "max_output_tokens": 8192
    },
    "snowflake/llama2-70b-chat": {
        "litellm_provider": "snowflake",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 4096,
        "max_output_tokens": 8192
    },
    "snowflake/llama3-70b": {
        "litellm_provider": "snowflake",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8000,
        "max_output_tokens": 8192
    },
    "snowflake/llama3-8b": {
        "litellm_provider": "snowflake",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8000,
        "max_output_tokens": 8192
    },
    "snowflake/llama3.1-405b": {
        "litellm_provider": "snowflake",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "snowflake/llama3.1-70b": {
        "litellm_provider": "snowflake",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "snowflake/llama3.1-8b": {
        "litellm_provider": "snowflake",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "snowflake/llama3.2-1b": {
        "litellm_provider": "snowflake",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "snowflake/llama3.2-3b": {
        "litellm_provider": "snowflake",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "snowflake/llama3.3-70b": {
        "litellm_provider": "snowflake",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "snowflake/mistral-7b": {
        "litellm_provider": "snowflake",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 32000,
        "max_output_tokens": 8192
    },
    "snowflake/mistral-large": {
        "litellm_provider": "snowflake",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 32000,
        "max_output_tokens": 8192
    },
    "snowflake/mistral-large2": {
        "litellm_provider": "snowflake",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "snowflake/mixtral-8x7b": {
        "litellm_provider": "snowflake",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 32000,
        "max_output_tokens": 8192
    },
    "snowflake/reka-core": {
        "litellm_provider": "snowflake",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 32000,
        "max_output_tokens": 8192
    },
    "snowflake/reka-flash": {
        "litellm_provider": "snowflake",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 100000,
        "max_output_tokens": 8192
    },
    "snowflake/snowflake-arctic": {
        "litellm_provider": "snowflake",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 4096,
        "max_output_tokens": 8192
    },
    "snowflake/snowflake-llama-3.1-405b": {
        "litellm_provider": "snowflake",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8000,
        "max_output_tokens": 8192
    },
    "snowflake/snowflake-llama-3.3-70b": {
        "litellm_provider": "snowflake",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8000,
        "max_output_tokens": 8192
    },
    "stability/sd3": {
        "litellm_provider": "stability",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "stability/sd3-large": {
        "litellm_provider": "stability",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "stability/sd3-large-turbo": {
        "litellm_provider": "stability",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "stability/sd3-medium": {
        "litellm_provider": "stability",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "stability/sd3.5-large": {
        "litellm_provider": "stability",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "stability/sd3.5-large-turbo": {
        "litellm_provider": "stability",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "stability/sd3.5-medium": {
        "litellm_provider": "stability",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "stability/stable-image-ultra": {
        "litellm_provider": "stability",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "stability/inpaint": {
        "litellm_provider": "stability",
        "mode": "image_edit",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "stability/outpaint": {
        "litellm_provider": "stability",
        "mode": "image_edit",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "stability/erase": {
        "litellm_provider": "stability",
        "mode": "image_edit",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "stability/search-and-replace": {
        "litellm_provider": "stability",
        "mode": "image_edit",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "stability/search-and-recolor": {
        "litellm_provider": "stability",
        "mode": "image_edit",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "stability/remove-background": {
        "litellm_provider": "stability",
        "mode": "image_edit",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "stability/replace-background-and-relight": {
        "litellm_provider": "stability",
        "mode": "image_edit",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "stability/sketch": {
        "litellm_provider": "stability",
        "mode": "image_edit",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "stability/structure": {
        "litellm_provider": "stability",
        "mode": "image_edit",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "stability/style": {
        "litellm_provider": "stability",
        "mode": "image_edit",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "stability/style-transfer": {
        "litellm_provider": "stability",
        "mode": "image_edit",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "stability/fast": {
        "litellm_provider": "stability",
        "mode": "image_edit",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "stability/conservative": {
        "litellm_provider": "stability",
        "mode": "image_edit",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "stability/creative": {
        "litellm_provider": "stability",
        "mode": "image_edit",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "stability/stable-image-core": {
        "litellm_provider": "stability",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "stability.sd3-5-large-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 77,
        "max_input_tokens": 77,
        "max_output_tokens": null
    },
    "stability.sd3-large-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 77,
        "max_input_tokens": 77,
        "max_output_tokens": null
    },
    "stability.stable-image-core-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 77,
        "max_input_tokens": 77,
        "max_output_tokens": null
    },
    "stability.stable-conservative-upscale-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "image_edit",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 77,
        "max_output_tokens": null
    },
    "stability.stable-creative-upscale-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "image_edit",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 77,
        "max_output_tokens": null
    },
    "stability.stable-fast-upscale-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "image_edit",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 77,
        "max_output_tokens": null
    },
    "stability.stable-outpaint-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "image_edit",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 77,
        "max_output_tokens": null
    },
    "stability.stable-image-control-sketch-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "image_edit",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 77,
        "max_output_tokens": null
    },
    "stability.stable-image-control-structure-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "image_edit",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 77,
        "max_output_tokens": null
    },
    "stability.stable-image-erase-object-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "image_edit",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 77,
        "max_output_tokens": null
    },
    "stability.stable-image-inpaint-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "image_edit",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 77,
        "max_output_tokens": null
    },
    "stability.stable-image-remove-background-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "image_edit",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 77,
        "max_output_tokens": null
    },
    "stability.stable-image-search-recolor-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "image_edit",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 77,
        "max_output_tokens": null
    },
    "stability.stable-image-search-replace-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "image_edit",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 77,
        "max_output_tokens": null
    },
    "stability.stable-image-style-guide-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "image_edit",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 77,
        "max_output_tokens": null
    },
    "stability.stable-style-transfer-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "image_edit",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 77,
        "max_output_tokens": null
    },
    "stability.stable-image-core-v1:1": {
        "litellm_provider": "bedrock",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 77,
        "max_input_tokens": 77,
        "max_output_tokens": null
    },
    "stability.stable-image-ultra-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 77,
        "max_input_tokens": 77,
        "max_output_tokens": null
    },
    "stability.stable-image-ultra-v1:1": {
        "litellm_provider": "bedrock",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 77,
        "max_input_tokens": 77,
        "max_output_tokens": null
    },
    "standard/1024-x-1024/dall-e-3": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "standard/1024-x-1792/dall-e-3": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "standard/1792-x-1024/dall-e-3": {
        "litellm_provider": "openai",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "linkup/search": {
        "litellm_provider": "linkup",
        "mode": "search",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "linkup/search-deep": {
        "litellm_provider": "linkup",
        "mode": "search",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "tavily/search": {
        "litellm_provider": "tavily",
        "mode": "search",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "tavily/search-advanced": {
        "litellm_provider": "tavily",
        "mode": "search",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "text-bison": {
        "litellm_provider": "vertex_ai-text-models",
        "mode": "completion",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 8192,
        "max_output_tokens": 2048
    },
    "text-bison32k": {
        "litellm_provider": "vertex_ai-text-models",
        "mode": "completion",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 1.25e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 8192,
        "max_output_tokens": 1024
    },
    "text-bison32k@002": {
        "litellm_provider": "vertex_ai-text-models",
        "mode": "completion",
        "input_cost_per_token": 1.25e-07,
        "output_cost_per_token": 1.25e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 8192,
        "max_output_tokens": 1024
    },
    "text-bison@001": {
        "litellm_provider": "vertex_ai-text-models",
        "mode": "completion",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 8192,
        "max_output_tokens": 1024
    },
    "text-bison@002": {
        "litellm_provider": "vertex_ai-text-models",
        "mode": "completion",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 8192,
        "max_output_tokens": 1024
    },
    "text-completion-codestral/codestral-2405": {
        "litellm_provider": "text-completion-codestral",
        "mode": "completion",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191
    },
    "text-completion-codestral/codestral-latest": {
        "litellm_provider": "text-completion-codestral",
        "mode": "completion",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191
    },
    "text-embedding-004": {
        "litellm_provider": "vertex_ai-embedding-models",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 2048,
        "max_output_tokens": null
    },
    "text-embedding-005": {
        "litellm_provider": "vertex_ai-embedding-models",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 2048,
        "max_output_tokens": null
    },
    "text-embedding-3-large": {
        "litellm_provider": "openai",
        "mode": "embedding",
        "input_cost_per_token": 1.3e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 8191,
        "max_output_tokens": null
    },
    "text-embedding-3-small": {
        "litellm_provider": "openai",
        "mode": "embedding",
        "input_cost_per_token": 2e-08,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 8191,
        "max_output_tokens": null
    },
    "text-embedding-ada-002": {
        "litellm_provider": "openai",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 8191,
        "max_output_tokens": null
    },
    "text-embedding-ada-002-v2": {
        "litellm_provider": "openai",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 8191,
        "max_output_tokens": null
    },
    "text-embedding-large-exp-03-07": {
        "litellm_provider": "vertex_ai-embedding-models",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": null
    },
    "text-embedding-preview-0409": {
        "litellm_provider": "vertex_ai-embedding-models",
        "mode": "embedding",
        "input_cost_per_token": 6.25e-09,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 3072,
        "max_input_tokens": 3072,
        "max_output_tokens": null
    },
    "text-moderation-007": {
        "litellm_provider": "openai",
        "mode": "moderation",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 0,
        "max_input_tokens": 32768,
        "max_output_tokens": 0
    },
    "text-moderation-latest": {
        "litellm_provider": "openai",
        "mode": "moderation",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 0,
        "max_input_tokens": 32768,
        "max_output_tokens": 0
    },
    "text-moderation-stable": {
        "litellm_provider": "openai",
        "mode": "moderation",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 0,
        "max_input_tokens": 32768,
        "max_output_tokens": 0
    },
    "text-multilingual-embedding-002": {
        "litellm_provider": "vertex_ai-embedding-models",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 2048,
        "max_output_tokens": null
    },
    "text-multilingual-embedding-preview-0409": {
        "litellm_provider": "vertex_ai-embedding-models",
        "mode": "embedding",
        "input_cost_per_token": 6.25e-09,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 3072,
        "max_input_tokens": 3072,
        "max_output_tokens": null
    },
    "text-unicorn": {
        "litellm_provider": "vertex_ai-text-models",
        "mode": "completion",
        "input_cost_per_token": 1e-05,
        "output_cost_per_token": 2.8e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 8192,
        "max_output_tokens": 1024
    },
    "text-unicorn@001": {
        "litellm_provider": "vertex_ai-text-models",
        "mode": "completion",
        "input_cost_per_token": 1e-05,
        "output_cost_per_token": 2.8e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 8192,
        "max_output_tokens": 1024
    },
    "textembedding-gecko": {
        "litellm_provider": "vertex_ai-embedding-models",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 3072,
        "max_input_tokens": 3072,
        "max_output_tokens": null
    },
    "textembedding-gecko-multilingual": {
        "litellm_provider": "vertex_ai-embedding-models",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 3072,
        "max_input_tokens": 3072,
        "max_output_tokens": null
    },
    "textembedding-gecko-multilingual@001": {
        "litellm_provider": "vertex_ai-embedding-models",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 3072,
        "max_input_tokens": 3072,
        "max_output_tokens": null
    },
    "textembedding-gecko@001": {
        "litellm_provider": "vertex_ai-embedding-models",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 3072,
        "max_input_tokens": 3072,
        "max_output_tokens": null
    },
    "textembedding-gecko@003": {
        "litellm_provider": "vertex_ai-embedding-models",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 3072,
        "max_input_tokens": 3072,
        "max_output_tokens": null
    },
    "together-ai-21.1b-41b": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 8e-07,
        "output_cost_per_token": 8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "together-ai-4.1b-8b": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "together-ai-41.1b-80b": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "together-ai-8.1b-21b": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1000,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "together-ai-81.1b-110b": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 1.8e-06,
        "output_cost_per_token": 1.8e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "together-ai-embedding-151m-to-350m": {
        "litellm_provider": "together_ai",
        "mode": "embedding",
        "input_cost_per_token": 1.6e-08,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "together-ai-embedding-up-to-150m": {
        "litellm_provider": "together_ai",
        "mode": "embedding",
        "input_cost_per_token": 8e-09,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "together_ai/baai/bge-base-en-v1.5": {
        "litellm_provider": "together_ai",
        "mode": "embedding",
        "input_cost_per_token": 8e-09,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 512,
        "max_output_tokens": null
    },
    "together_ai/BAAI/bge-base-en-v1.5": {
        "litellm_provider": "together_ai",
        "mode": "embedding",
        "input_cost_per_token": 8e-09,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 512,
        "max_output_tokens": null
    },
    "together-ai-up-to-4b": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "together_ai/Qwen/Qwen2.5-72B-Instruct-Turbo": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "together_ai/Qwen/Qwen2.5-7B-Instruct-Turbo": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "together_ai/Qwen/Qwen3-235B-A22B-Instruct-2507-tput": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 6e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 262000,
        "max_output_tokens": null
    },
    "together_ai/Qwen/Qwen3-235B-A22B-Thinking-2507": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 6.5e-07,
        "output_cost_per_token": 3e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 256000,
        "max_output_tokens": null
    },
    "together_ai/Qwen/Qwen3-235B-A22B-fp8-tput": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 40000,
        "max_output_tokens": null
    },
    "together_ai/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 256000,
        "max_output_tokens": null
    },
    "together_ai/deepseek-ai/DeepSeek-R1": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 7e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 20480,
        "max_input_tokens": 128000,
        "max_output_tokens": 20480
    },
    "together_ai/deepseek-ai/DeepSeek-R1-0528-tput": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 5.5e-07,
        "output_cost_per_token": 2.19e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 128000,
        "max_output_tokens": null
    },
    "together_ai/deepseek-ai/DeepSeek-V3": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 1.25e-06,
        "output_cost_per_token": 1.25e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 65536,
        "max_output_tokens": 8192
    },
    "together_ai/deepseek-ai/DeepSeek-V3.1": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 1.7e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "together_ai/meta-llama/Llama-3.2-3B-Instruct-Turbo": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 8.8e-07,
        "output_cost_per_token": 8.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo-Free": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "together_ai/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 2.7e-07,
        "output_cost_per_token": 8.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "together_ai/meta-llama/Llama-4-Scout-17B-16E-Instruct": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 1.8e-07,
        "output_cost_per_token": 5.9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "together_ai/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 3.5e-06,
        "output_cost_per_token": 3.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "together_ai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 8.8e-07,
        "output_cost_per_token": 8.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 1.8e-07,
        "output_cost_per_token": 1.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "together_ai/mistralai/Mistral-7B-Instruct-v0.1": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "together_ai/mistralai/Mistral-Small-24B-Instruct-2501": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "together_ai/mistralai/Mixtral-8x7B-Instruct-v0.1": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "together_ai/moonshotai/Kimi-K2-Instruct": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 3e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "together_ai/openai/gpt-oss-120b": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 128000,
        "max_output_tokens": null
    },
    "together_ai/openai/gpt-oss-20b": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 128000,
        "max_output_tokens": null
    },
    "together_ai/togethercomputer/CodeLlama-34b-Instruct": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "together_ai/zai-org/GLM-4.5-Air-FP8": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 1.1e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 128000,
        "max_output_tokens": null
    },
    "together_ai/zai-org/GLM-4.6": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 200000,
        "max_input_tokens": 200000,
        "max_output_tokens": 200000
    },
    "together_ai/zai-org/GLM-4.7": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 4.5e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 200000,
        "max_input_tokens": 200000,
        "max_output_tokens": 200000
    },
    "together_ai/moonshotai/Kimi-K2.5": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 2.8e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "together_ai/moonshotai/Kimi-K2-Instruct-0905": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 3e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 262144,
        "max_output_tokens": null
    },
    "together_ai/Qwen/Qwen3-Next-80B-A3B-Instruct": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 262144,
        "max_output_tokens": null
    },
    "together_ai/Qwen/Qwen3-Next-80B-A3B-Thinking": {
        "litellm_provider": "together_ai",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 262144,
        "max_output_tokens": null
    },
    "tts-1": {
        "litellm_provider": "openai",
        "mode": "audio_speech",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "tts-1-hd": {
        "litellm_provider": "openai",
        "mode": "audio_speech",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "aws_polly/standard": {
        "litellm_provider": "aws_polly",
        "mode": "audio_speech",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "aws_polly/neural": {
        "litellm_provider": "aws_polly",
        "mode": "audio_speech",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "aws_polly/long-form": {
        "litellm_provider": "aws_polly",
        "mode": "audio_speech",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "aws_polly/generative": {
        "litellm_provider": "aws_polly",
        "mode": "audio_speech",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "us.amazon.nova-lite-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 6e-08,
        "output_cost_per_token": 2.4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 10000,
        "max_input_tokens": 300000,
        "max_output_tokens": 10000
    },
    "us.amazon.nova-micro-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 3.5e-08,
        "output_cost_per_token": 1.4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 10000,
        "max_input_tokens": 128000,
        "max_output_tokens": 10000
    },
    "us.amazon.nova-premier-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1.25e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 10000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 10000
    },
    "us.amazon.nova-pro-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 8e-07,
        "output_cost_per_token": 3.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 10000,
        "max_input_tokens": 300000,
        "max_output_tokens": 10000
    },
    "us.anthropic.claude-3-5-haiku-20241022-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 8e-07,
        "output_cost_per_token": 4e-06,
        "cache_read_input_token_cost": 8e-08,
        "cache_creation_input_token_cost": 1e-06,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "us.anthropic.claude-haiku-4-5-20251001-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 1.1e-06,
        "output_cost_per_token": 5.5e-06,
        "cache_read_input_token_cost": 1.1e-07,
        "cache_creation_input_token_cost": 1.375e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "us.anthropic.claude-3-5-sonnet-20240620-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "us.anthropic.claude-3-5-sonnet-20241022-v2:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "us.anthropic.claude-3-7-sonnet-20250219-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "us.anthropic.claude-3-haiku-20240307-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 1.25e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "us.anthropic.claude-3-opus-20240229-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "us.anthropic.claude-3-sonnet-20240229-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "us.anthropic.claude-opus-4-1-20250805-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "cache_creation_input_token_cost": 1.875e-05,
        "max_tokens": 32000,
        "max_input_tokens": 200000,
        "max_output_tokens": 32000
    },
    "us.anthropic.claude-sonnet-4-5-20250929-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 3.3e-06,
        "output_cost_per_token": 1.65e-05,
        "cache_read_input_token_cost": 3.3e-07,
        "cache_creation_input_token_cost": 4.125e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "au.anthropic.claude-haiku-4-5-20251001-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 1.1e-06,
        "output_cost_per_token": 5.5e-06,
        "cache_read_input_token_cost": 1.1e-07,
        "cache_creation_input_token_cost": 1.375e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "us.anthropic.claude-opus-4-20250514-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "cache_creation_input_token_cost": 1.875e-05,
        "max_tokens": 32000,
        "max_input_tokens": 200000,
        "max_output_tokens": 32000
    },
    "us.anthropic.claude-opus-4-5-20251101-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 5.5e-06,
        "output_cost_per_token": 2.75e-05,
        "cache_read_input_token_cost": 5.5e-07,
        "cache_creation_input_token_cost": 6.875e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "global.anthropic.claude-opus-4-5-20251101-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 2.5e-05,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": 6.25e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "eu.anthropic.claude-opus-4-5-20251101-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 2.5e-05,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": 6.25e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "us.anthropic.claude-sonnet-4-20250514-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 64000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000
    },
    "us.deepseek.r1-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 1.35e-06,
        "output_cost_per_token": 5.4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "us.meta.llama3-1-405b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 5.32e-06,
        "output_cost_per_token": 1.6e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "us.meta.llama3-1-70b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 9.9e-07,
        "output_cost_per_token": 9.9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048
    },
    "us.meta.llama3-1-8b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 2.2e-07,
        "output_cost_per_token": 2.2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048
    },
    "us.meta.llama3-2-11b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 3.5e-07,
        "output_cost_per_token": 3.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "us.meta.llama3-2-1b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "us.meta.llama3-2-3b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 1.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "us.meta.llama3-2-90b-instruct-v1:0": {
        "litellm_provider": "bedrock",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "us.meta.llama3-3-70b-instruct-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 7.2e-07,
        "output_cost_per_token": 7.2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "us.meta.llama4-maverick-17b-instruct-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 2.4e-07,
        "output_cost_per_token": 9.7e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "us.meta.llama4-scout-17b-instruct-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 1.7e-07,
        "output_cost_per_token": 6.6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "us.mistral.pixtral-large-2502-v1:0": {
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 6e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "v0/v0-1.0-md": {
        "litellm_provider": "v0",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "v0/v0-1.5-lg": {
        "litellm_provider": "v0",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 512000,
        "max_input_tokens": 512000,
        "max_output_tokens": 512000
    },
    "v0/v0-1.5-md": {
        "litellm_provider": "v0",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "vercel_ai_gateway/alibaba/qwen-3-14b": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 8e-08,
        "output_cost_per_token": 2.4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 40960,
        "max_output_tokens": 16384
    },
    "vercel_ai_gateway/alibaba/qwen-3-235b": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 40960,
        "max_output_tokens": 16384
    },
    "vercel_ai_gateway/alibaba/qwen-3-30b": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 40960,
        "max_output_tokens": 16384
    },
    "vercel_ai_gateway/alibaba/qwen-3-32b": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 40960,
        "max_output_tokens": 16384
    },
    "vercel_ai_gateway/alibaba/qwen3-coder": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 1.6e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 66536,
        "max_input_tokens": 262144,
        "max_output_tokens": 66536
    },
    "vercel_ai_gateway/amazon/nova-lite": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 6e-08,
        "output_cost_per_token": 2.4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 300000,
        "max_output_tokens": 8192
    },
    "vercel_ai_gateway/amazon/nova-micro": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 3.5e-08,
        "output_cost_per_token": 1.4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "vercel_ai_gateway/amazon/nova-pro": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 8e-07,
        "output_cost_per_token": 3.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 300000,
        "max_output_tokens": 8192
    },
    "vercel_ai_gateway/amazon/titan-embed-text-v2": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 2e-08,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 0,
        "max_input_tokens": 0,
        "max_output_tokens": 0
    },
    "vercel_ai_gateway/anthropic/claude-3-haiku": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 1.25e-06,
        "cache_read_input_token_cost": 3e-08,
        "cache_creation_input_token_cost": 3e-07,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "vercel_ai_gateway/anthropic/claude-3-opus": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "cache_creation_input_token_cost": 1.875e-05,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "vercel_ai_gateway/anthropic/claude-3.5-haiku": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 8e-07,
        "output_cost_per_token": 4e-06,
        "cache_read_input_token_cost": 8e-08,
        "cache_creation_input_token_cost": 1e-06,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "vercel_ai_gateway/anthropic/claude-3.5-sonnet": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "vercel_ai_gateway/anthropic/claude-3.7-sonnet": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "vercel_ai_gateway/anthropic/claude-4-opus": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "cache_creation_input_token_cost": 1.875e-05,
        "max_tokens": 32000,
        "max_input_tokens": 200000,
        "max_output_tokens": 32000
    },
    "vercel_ai_gateway/anthropic/claude-4-sonnet": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "vercel_ai_gateway/anthropic/claude-3-5-sonnet": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "vercel_ai_gateway/anthropic/claude-3-5-sonnet-20241022": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "vercel_ai_gateway/anthropic/claude-3-7-sonnet": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "vercel_ai_gateway/anthropic/claude-haiku-4.5": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": 1e-07,
        "cache_creation_input_token_cost": 1.25e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "vercel_ai_gateway/anthropic/claude-opus-4": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "cache_creation_input_token_cost": 1.875e-05,
        "max_tokens": 32000,
        "max_input_tokens": 200000,
        "max_output_tokens": 32000
    },
    "vercel_ai_gateway/anthropic/claude-opus-4.1": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "cache_creation_input_token_cost": 1.875e-05,
        "max_tokens": 32000,
        "max_input_tokens": 200000,
        "max_output_tokens": 32000
    },
    "vercel_ai_gateway/anthropic/claude-opus-4.5": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 2.5e-05,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": 6.25e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "vercel_ai_gateway/anthropic/claude-opus-4.6": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 2.5e-05,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": 6.25e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "vercel_ai_gateway/anthropic/claude-sonnet-4": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "vercel_ai_gateway/anthropic/claude-sonnet-4.5": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 64000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000
    },
    "vercel_ai_gateway/cohere/command-a": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8000,
        "max_input_tokens": 256000,
        "max_output_tokens": 8000
    },
    "vercel_ai_gateway/cohere/command-r": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "vercel_ai_gateway/cohere/command-r-plus": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "vercel_ai_gateway/cohere/embed-v4.0": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 1.2e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 0,
        "max_input_tokens": 0,
        "max_output_tokens": 0
    },
    "vercel_ai_gateway/deepseek/deepseek-r1": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 5.5e-07,
        "output_cost_per_token": 2.19e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "vercel_ai_gateway/deepseek/deepseek-r1-distill-llama-70b": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 7.5e-07,
        "output_cost_per_token": 9.9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "vercel_ai_gateway/deepseek/deepseek-v3": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "vercel_ai_gateway/google/gemini-2.0-flash": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192
    },
    "vercel_ai_gateway/google/gemini-2.0-flash-lite": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 7.5e-08,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192
    },
    "vercel_ai_gateway/google/gemini-2.5-flash": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 1000000,
        "max_output_tokens": 65536
    },
    "vercel_ai_gateway/google/gemini-2.5-pro": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65536
    },
    "vercel_ai_gateway/google/gemini-embedding-001": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "embedding",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 0,
        "max_input_tokens": 0,
        "max_output_tokens": 0
    },
    "vercel_ai_gateway/google/gemma-2-9b": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "vercel_ai_gateway/google/text-embedding-005": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "embedding",
        "input_cost_per_token": 2.5e-08,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 0,
        "max_input_tokens": 0,
        "max_output_tokens": 0
    },
    "vercel_ai_gateway/google/text-multilingual-embedding-002": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "embedding",
        "input_cost_per_token": 2.5e-08,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 0,
        "max_input_tokens": 0,
        "max_output_tokens": 0
    },
    "vercel_ai_gateway/inception/mercury-coder-small": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 1e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 32000,
        "max_output_tokens": 16384
    },
    "vercel_ai_gateway/meta/llama-3-70b": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 5.9e-07,
        "output_cost_per_token": 7.9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "vercel_ai_gateway/meta/llama-3-8b": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 8e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "vercel_ai_gateway/meta/llama-3.1-70b": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 7.2e-07,
        "output_cost_per_token": 7.2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "vercel_ai_gateway/meta/llama-3.1-8b": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 8e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131000,
        "max_output_tokens": 131072
    },
    "vercel_ai_gateway/meta/llama-3.2-11b": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 1.6e-07,
        "output_cost_per_token": 1.6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "vercel_ai_gateway/meta/llama-3.2-1b": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "vercel_ai_gateway/meta/llama-3.2-3b": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 1.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "vercel_ai_gateway/meta/llama-3.2-90b": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 7.2e-07,
        "output_cost_per_token": 7.2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "vercel_ai_gateway/meta/llama-3.3-70b": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 7.2e-07,
        "output_cost_per_token": 7.2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "vercel_ai_gateway/meta/llama-4-maverick": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 131072,
        "max_output_tokens": 8192
    },
    "vercel_ai_gateway/meta/llama-4-scout": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 131072,
        "max_output_tokens": 8192
    },
    "vercel_ai_gateway/mistral/codestral": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4000,
        "max_input_tokens": 256000,
        "max_output_tokens": 4000
    },
    "vercel_ai_gateway/mistral/codestral-embed": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 0,
        "max_input_tokens": 0,
        "max_output_tokens": 0
    },
    "vercel_ai_gateway/mistral/devstral-small": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 7e-08,
        "output_cost_per_token": 2.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "vercel_ai_gateway/mistral/magistral-medium": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 64000,
        "max_input_tokens": 128000,
        "max_output_tokens": 64000
    },
    "vercel_ai_gateway/mistral/magistral-small": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 64000,
        "max_input_tokens": 128000,
        "max_output_tokens": 64000
    },
    "vercel_ai_gateway/mistral/ministral-3b": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 4e-08,
        "output_cost_per_token": 4e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4000,
        "max_input_tokens": 128000,
        "max_output_tokens": 4000
    },
    "vercel_ai_gateway/mistral/ministral-8b": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4000,
        "max_input_tokens": 128000,
        "max_output_tokens": 4000
    },
    "vercel_ai_gateway/mistral/mistral-embed": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 0,
        "max_input_tokens": 0,
        "max_output_tokens": 0
    },
    "vercel_ai_gateway/mistral/mistral-large": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 6e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4000,
        "max_input_tokens": 32000,
        "max_output_tokens": 4000
    },
    "vercel_ai_gateway/mistral/mistral-saba-24b": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 7.9e-07,
        "output_cost_per_token": 7.9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "vercel_ai_gateway/mistral/mistral-small": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4000,
        "max_input_tokens": 32000,
        "max_output_tokens": 4000
    },
    "vercel_ai_gateway/mistral/mixtral-8x22b-instruct": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 1.2e-06,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 65536,
        "max_output_tokens": 2048
    },
    "vercel_ai_gateway/mistral/pixtral-12b": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 1.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4000,
        "max_input_tokens": 128000,
        "max_output_tokens": 4000
    },
    "vercel_ai_gateway/mistral/pixtral-large": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 6e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4000,
        "max_input_tokens": 128000,
        "max_output_tokens": 4000
    },
    "vercel_ai_gateway/moonshotai/kimi-k2": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 5.5e-07,
        "output_cost_per_token": 2.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 131072,
        "max_output_tokens": 16384
    },
    "vercel_ai_gateway/morph/morph-v3-fast": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 8e-07,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 32768,
        "max_output_tokens": 16384
    },
    "vercel_ai_gateway/morph/morph-v3-large": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 1.9e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 32768,
        "max_output_tokens": 16384
    },
    "vercel_ai_gateway/openai/gpt-3.5-turbo": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 16385,
        "max_output_tokens": 4096
    },
    "vercel_ai_gateway/openai/gpt-3.5-turbo-instruct": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 1.5e-06,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 8192,
        "max_output_tokens": 4096
    },
    "vercel_ai_gateway/openai/gpt-4-turbo": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 1e-05,
        "output_cost_per_token": 3e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096
    },
    "vercel_ai_gateway/openai/gpt-4.1": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 8e-06,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": 0.0,
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768
    },
    "vercel_ai_gateway/openai/gpt-4.1-mini": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 1.6e-06,
        "cache_read_input_token_cost": 1e-07,
        "cache_creation_input_token_cost": 0.0,
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768
    },
    "vercel_ai_gateway/openai/gpt-4.1-nano": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": 2.5e-08,
        "cache_creation_input_token_cost": 0.0,
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768
    },
    "vercel_ai_gateway/openai/gpt-4o": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 2.5e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": 1.25e-06,
        "cache_creation_input_token_cost": 0.0,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "vercel_ai_gateway/openai/gpt-4o-mini": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": 7.5e-08,
        "cache_creation_input_token_cost": 0.0,
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384
    },
    "vercel_ai_gateway/openai/o1": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 6e-05,
        "cache_read_input_token_cost": 7.5e-06,
        "cache_creation_input_token_cost": 0.0,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "vercel_ai_gateway/openai/o3": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 8e-06,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": 0.0,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "vercel_ai_gateway/openai/o3-mini": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 1.1e-06,
        "output_cost_per_token": 4.4e-06,
        "cache_read_input_token_cost": 5.5e-07,
        "cache_creation_input_token_cost": 0.0,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "vercel_ai_gateway/openai/o4-mini": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 1.1e-06,
        "output_cost_per_token": 4.4e-06,
        "cache_read_input_token_cost": 2.75e-07,
        "cache_creation_input_token_cost": 0.0,
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000
    },
    "vercel_ai_gateway/openai/text-embedding-3-large": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "embedding",
        "input_cost_per_token": 1.3e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 0,
        "max_input_tokens": 0,
        "max_output_tokens": 0
    },
    "vercel_ai_gateway/openai/text-embedding-3-small": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "embedding",
        "input_cost_per_token": 2e-08,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 0,
        "max_input_tokens": 0,
        "max_output_tokens": 0
    },
    "vercel_ai_gateway/openai/text-embedding-ada-002": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 0,
        "max_input_tokens": 0,
        "max_output_tokens": 0
    },
    "vercel_ai_gateway/perplexity/sonar": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 1e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8000,
        "max_input_tokens": 127000,
        "max_output_tokens": 8000
    },
    "vercel_ai_gateway/perplexity/sonar-pro": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8000,
        "max_input_tokens": 200000,
        "max_output_tokens": 8000
    },
    "vercel_ai_gateway/perplexity/sonar-reasoning": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8000,
        "max_input_tokens": 127000,
        "max_output_tokens": 8000
    },
    "vercel_ai_gateway/perplexity/sonar-reasoning-pro": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 8e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8000,
        "max_input_tokens": 127000,
        "max_output_tokens": 8000
    },
    "vercel_ai_gateway/vercel/v0-1.0-md": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 128000,
        "max_output_tokens": 32000
    },
    "vercel_ai_gateway/vercel/v0-1.5-md": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 128000,
        "max_output_tokens": 32768
    },
    "vercel_ai_gateway/xai/grok-2": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4000,
        "max_input_tokens": 131072,
        "max_output_tokens": 4000
    },
    "vercel_ai_gateway/xai/grok-2-vision": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "vercel_ai_gateway/xai/grok-3": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "vercel_ai_gateway/xai/grok-3-fast": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 2.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "vercel_ai_gateway/xai/grok-3-mini": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "vercel_ai_gateway/xai/grok-3-mini-fast": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "vercel_ai_gateway/xai/grok-4": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "vercel_ai_gateway/zai/glm-4.5": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "vercel_ai_gateway/zai/glm-4.5-air": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 1.1e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 96000,
        "max_input_tokens": 128000,
        "max_output_tokens": 96000
    },
    "vercel_ai_gateway/zai/glm-4.6": {
        "litellm_provider": "vercel_ai_gateway",
        "mode": "chat",
        "input_cost_per_token": 4.5e-07,
        "output_cost_per_token": 1.8e-06,
        "cache_read_input_token_cost": 1.1e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 200000,
        "max_input_tokens": 200000,
        "max_output_tokens": 200000
    },
    "vertex_ai/chirp": {
        "litellm_provider": "vertex_ai",
        "mode": "audio_speech",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "vertex_ai/claude-3-5-haiku": {
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "vertex_ai/claude-3-5-haiku@20241022": {
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "vertex_ai/claude-haiku-4-5@20251001": {
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 5e-06,
        "cache_read_input_token_cost": 1e-07,
        "cache_creation_input_token_cost": 1.25e-06,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "vertex_ai/claude-3-5-sonnet": {
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "vertex_ai/claude-3-5-sonnet-v2": {
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "vertex_ai/claude-3-5-sonnet-v2@20241022": {
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "vertex_ai/claude-3-5-sonnet@20240620": {
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "vertex_ai/claude-3-7-sonnet@20250219": {
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192
    },
    "vertex_ai/claude-3-haiku": {
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 1.25e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "vertex_ai/claude-3-haiku@20240307": {
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 1.25e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "vertex_ai/claude-3-opus": {
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "vertex_ai/claude-3-opus@20240229": {
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "vertex_ai/claude-3-sonnet": {
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "vertex_ai/claude-3-sonnet@20240229": {
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096
    },
    "vertex_ai/claude-opus-4": {
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "cache_creation_input_token_cost": 1.875e-05,
        "max_tokens": 32000,
        "max_input_tokens": 200000,
        "max_output_tokens": 32000
    },
    "vertex_ai/claude-opus-4-1": {
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "cache_creation_input_token_cost": 1.875e-05,
        "max_tokens": 32000,
        "max_input_tokens": 200000,
        "max_output_tokens": 32000
    },
    "vertex_ai/claude-opus-4-1@20250805": {
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "cache_creation_input_token_cost": 1.875e-05,
        "max_tokens": 32000,
        "max_input_tokens": 200000,
        "max_output_tokens": 32000
    },
    "vertex_ai/claude-opus-4-5": {
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 2.5e-05,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": 6.25e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "vertex_ai/claude-opus-4-5@20251101": {
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 2.5e-05,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": 6.25e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "vertex_ai/claude-opus-4-6": {
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 2.5e-05,
        "cache_read_input_token_cost": 5e-07,
        "cache_creation_input_token_cost": 6.25e-06,
        "max_tokens": 128000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 128000
    },
    "vertex_ai/claude-sonnet-4-5": {
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "vertex_ai/claude-sonnet-4-5@20250929": {
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 64000,
        "max_input_tokens": 200000,
        "max_output_tokens": 64000
    },
    "vertex_ai/claude-opus-4@20250514": {
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "input_cost_per_token": 1.5e-05,
        "output_cost_per_token": 7.5e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "cache_creation_input_token_cost": 1.875e-05,
        "max_tokens": 32000,
        "max_input_tokens": 200000,
        "max_output_tokens": 32000
    },
    "vertex_ai/claude-sonnet-4": {
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 64000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000
    },
    "vertex_ai/claude-sonnet-4@20250514": {
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 3e-07,
        "cache_creation_input_token_cost": 3.75e-06,
        "max_tokens": 64000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000
    },
    "vertex_ai/mistralai/codestral-2@001": {
        "litellm_provider": "vertex_ai-mistral_models",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "vertex_ai/codestral-2": {
        "litellm_provider": "vertex_ai-mistral_models",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "vertex_ai/codestral-2@001": {
        "litellm_provider": "vertex_ai-mistral_models",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "vertex_ai/mistralai/codestral-2": {
        "litellm_provider": "vertex_ai-mistral_models",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "vertex_ai/codestral-2501": {
        "litellm_provider": "vertex_ai-mistral_models",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "vertex_ai/codestral@2405": {
        "litellm_provider": "vertex_ai-mistral_models",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "vertex_ai/codestral@latest": {
        "litellm_provider": "vertex_ai-mistral_models",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "vertex_ai/deepseek-ai/deepseek-v3.1-maas": {
        "litellm_provider": "vertex_ai-deepseek_models",
        "mode": "chat",
        "input_cost_per_token": 1.35e-06,
        "output_cost_per_token": 5.4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 163840,
        "max_output_tokens": 32768
    },
    "vertex_ai/deepseek-ai/deepseek-v3.2-maas": {
        "litellm_provider": "vertex_ai-deepseek_models",
        "mode": "chat",
        "input_cost_per_token": 5.6e-07,
        "output_cost_per_token": 1.68e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 163840,
        "max_output_tokens": 32768
    },
    "vertex_ai/deepseek-ai/deepseek-r1-0528-maas": {
        "litellm_provider": "vertex_ai-deepseek_models",
        "mode": "chat",
        "input_cost_per_token": 1.35e-06,
        "output_cost_per_token": 5.4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 65336,
        "max_output_tokens": 8192
    },
    "vertex_ai/gemini-2.5-flash-image": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "image_generation",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": 3e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "vertex_ai/gemini-3-pro-image-preview": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "image_generation",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 1.2e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 65536,
        "max_output_tokens": 32768
    },
    "vertex_ai/deep-research-pro-preview-12-2025": {
        "litellm_provider": "vertex_ai-language-models",
        "mode": "image_generation",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 1.2e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 65536,
        "max_output_tokens": 32768
    },
    "vertex_ai/imagegeneration@006": {
        "litellm_provider": "vertex_ai-image-models",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "vertex_ai/imagen-3.0-fast-generate-001": {
        "litellm_provider": "vertex_ai-image-models",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "vertex_ai/imagen-3.0-generate-001": {
        "litellm_provider": "vertex_ai-image-models",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "vertex_ai/imagen-3.0-generate-002": {
        "litellm_provider": "vertex_ai-image-models",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "vertex_ai/imagen-3.0-capability-001": {
        "litellm_provider": "vertex_ai-image-models",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "vertex_ai/imagen-4.0-fast-generate-001": {
        "litellm_provider": "vertex_ai-image-models",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "vertex_ai/imagen-4.0-generate-001": {
        "litellm_provider": "vertex_ai-image-models",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "vertex_ai/imagen-4.0-ultra-generate-001": {
        "litellm_provider": "vertex_ai-image-models",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "vertex_ai/jamba-1.5": {
        "litellm_provider": "vertex_ai-ai21_models",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "vertex_ai/jamba-1.5-large": {
        "litellm_provider": "vertex_ai-ai21_models",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 8e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "vertex_ai/jamba-1.5-large@001": {
        "litellm_provider": "vertex_ai-ai21_models",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 8e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "vertex_ai/jamba-1.5-mini": {
        "litellm_provider": "vertex_ai-ai21_models",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "vertex_ai/jamba-1.5-mini@001": {
        "litellm_provider": "vertex_ai-ai21_models",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "vertex_ai/meta/llama-3.1-405b-instruct-maas": {
        "litellm_provider": "vertex_ai-llama_models",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 1.6e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048
    },
    "vertex_ai/meta/llama-3.1-70b-instruct-maas": {
        "litellm_provider": "vertex_ai-llama_models",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048
    },
    "vertex_ai/meta/llama-3.1-8b-instruct-maas": {
        "litellm_provider": "vertex_ai-llama_models",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048
    },
    "vertex_ai/meta/llama-3.2-90b-vision-instruct-maas": {
        "litellm_provider": "vertex_ai-llama_models",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048
    },
    "vertex_ai/meta/llama-4-maverick-17b-128e-instruct-maas": {
        "litellm_provider": "vertex_ai-llama_models",
        "mode": "chat",
        "input_cost_per_token": 3.5e-07,
        "output_cost_per_token": 1.15e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1000000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 1000000
    },
    "vertex_ai/meta/llama-4-maverick-17b-16e-instruct-maas": {
        "litellm_provider": "vertex_ai-llama_models",
        "mode": "chat",
        "input_cost_per_token": 3.5e-07,
        "output_cost_per_token": 1.15e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1000000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 1000000
    },
    "vertex_ai/meta/llama-4-scout-17b-128e-instruct-maas": {
        "litellm_provider": "vertex_ai-llama_models",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 7e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 10000000,
        "max_input_tokens": 10000000,
        "max_output_tokens": 10000000
    },
    "vertex_ai/meta/llama-4-scout-17b-16e-instruct-maas": {
        "litellm_provider": "vertex_ai-llama_models",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 7e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 10000000,
        "max_input_tokens": 10000000,
        "max_output_tokens": 10000000
    },
    "vertex_ai/meta/llama3-405b-instruct-maas": {
        "litellm_provider": "vertex_ai-llama_models",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "max_output_tokens": 32000
    },
    "vertex_ai/meta/llama3-70b-instruct-maas": {
        "litellm_provider": "vertex_ai-llama_models",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "max_output_tokens": 32000
    },
    "vertex_ai/meta/llama3-8b-instruct-maas": {
        "litellm_provider": "vertex_ai-llama_models",
        "mode": "chat",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "max_output_tokens": 32000
    },
    "vertex_ai/minimaxai/minimax-m2-maas": {
        "litellm_provider": "vertex_ai-minimax_models",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 196608,
        "max_input_tokens": 196608,
        "max_output_tokens": 196608
    },
    "vertex_ai/moonshotai/kimi-k2-thinking-maas": {
        "litellm_provider": "vertex_ai-moonshot_models",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "vertex_ai/zai-org/glm-4.7-maas": {
        "litellm_provider": "vertex_ai-zai_models",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 200000,
        "max_output_tokens": 128000
    },
    "vertex_ai/mistral-medium-3": {
        "litellm_provider": "vertex_ai-mistral_models",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 128000,
        "max_output_tokens": 8191
    },
    "vertex_ai/mistral-medium-3@001": {
        "litellm_provider": "vertex_ai-mistral_models",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 128000,
        "max_output_tokens": 8191
    },
    "vertex_ai/mistralai/mistral-medium-3": {
        "litellm_provider": "vertex_ai-mistral_models",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 128000,
        "max_output_tokens": 8191
    },
    "vertex_ai/mistralai/mistral-medium-3@001": {
        "litellm_provider": "vertex_ai-mistral_models",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 128000,
        "max_output_tokens": 8191
    },
    "vertex_ai/mistral-large-2411": {
        "litellm_provider": "vertex_ai-mistral_models",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 6e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 128000,
        "max_output_tokens": 8191
    },
    "vertex_ai/mistral-large@2407": {
        "litellm_provider": "vertex_ai-mistral_models",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 6e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 128000,
        "max_output_tokens": 8191
    },
    "vertex_ai/mistral-large@2411-001": {
        "litellm_provider": "vertex_ai-mistral_models",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 6e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 128000,
        "max_output_tokens": 8191
    },
    "vertex_ai/mistral-large@latest": {
        "litellm_provider": "vertex_ai-mistral_models",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 6e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 128000,
        "max_output_tokens": 8191
    },
    "vertex_ai/mistral-nemo@2407": {
        "litellm_provider": "vertex_ai-mistral_models",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 3e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "vertex_ai/mistral-nemo@latest": {
        "litellm_provider": "vertex_ai-mistral_models",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 1.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "vertex_ai/mistral-small-2503": {
        "litellm_provider": "vertex_ai-mistral_models",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 3e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "vertex_ai/mistral-small-2503@001": {
        "litellm_provider": "vertex_ai-mistral_models",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 3e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8191,
        "max_input_tokens": 32000,
        "max_output_tokens": 8191
    },
    "vertex_ai/mistral-ocr-2505": {
        "litellm_provider": "vertex_ai",
        "mode": "ocr",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "vertex_ai/deepseek-ai/deepseek-ocr-maas": {
        "litellm_provider": "vertex_ai",
        "mode": "ocr",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "vertex_ai/openai/gpt-oss-120b-maas": {
        "litellm_provider": "vertex_ai-openai_models",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 131072,
        "max_output_tokens": 32768
    },
    "vertex_ai/openai/gpt-oss-20b-maas": {
        "litellm_provider": "vertex_ai-openai_models",
        "mode": "chat",
        "input_cost_per_token": 7.5e-08,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 131072,
        "max_output_tokens": 32768
    },
    "vertex_ai/qwen/qwen3-235b-a22b-instruct-2507-maas": {
        "litellm_provider": "vertex_ai-qwen_models",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 1e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 262144,
        "max_output_tokens": 16384
    },
    "vertex_ai/qwen/qwen3-coder-480b-a35b-instruct-maas": {
        "litellm_provider": "vertex_ai-qwen_models",
        "mode": "chat",
        "input_cost_per_token": 1e-06,
        "output_cost_per_token": 4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 262144,
        "max_output_tokens": 32768
    },
    "vertex_ai/qwen/qwen3-next-80b-a3b-instruct-maas": {
        "litellm_provider": "vertex_ai-qwen_models",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "vertex_ai/qwen/qwen3-next-80b-a3b-thinking-maas": {
        "litellm_provider": "vertex_ai-qwen_models",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "vertex_ai/veo-2.0-generate-001": {
        "litellm_provider": "vertex_ai-video-models",
        "mode": "video_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 1024,
        "max_output_tokens": null
    },
    "vertex_ai/veo-3.0-fast-generate-preview": {
        "litellm_provider": "vertex_ai-video-models",
        "mode": "video_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 1024,
        "max_output_tokens": null
    },
    "vertex_ai/veo-3.0-generate-preview": {
        "litellm_provider": "vertex_ai-video-models",
        "mode": "video_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 1024,
        "max_output_tokens": null
    },
    "vertex_ai/veo-3.0-fast-generate-001": {
        "litellm_provider": "vertex_ai-video-models",
        "mode": "video_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 1024,
        "max_output_tokens": null
    },
    "vertex_ai/veo-3.0-generate-001": {
        "litellm_provider": "vertex_ai-video-models",
        "mode": "video_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 1024,
        "max_output_tokens": null
    },
    "vertex_ai/veo-3.1-generate-preview": {
        "litellm_provider": "vertex_ai-video-models",
        "mode": "video_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 1024,
        "max_output_tokens": null
    },
    "vertex_ai/veo-3.1-fast-generate-preview": {
        "litellm_provider": "vertex_ai-video-models",
        "mode": "video_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 1024,
        "max_output_tokens": null
    },
    "vertex_ai/veo-3.1-generate-001": {
        "litellm_provider": "vertex_ai-video-models",
        "mode": "video_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 1024,
        "max_output_tokens": null
    },
    "vertex_ai/veo-3.1-fast-generate-001": {
        "litellm_provider": "vertex_ai-video-models",
        "mode": "video_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 1024,
        "max_output_tokens": null
    },
    "voyage/rerank-2": {
        "litellm_provider": "voyage",
        "mode": "rerank",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16000,
        "max_input_tokens": 16000,
        "max_output_tokens": 16000
    },
    "voyage/rerank-2-lite": {
        "litellm_provider": "voyage",
        "mode": "rerank",
        "input_cost_per_token": 2e-08,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8000,
        "max_input_tokens": 8000,
        "max_output_tokens": 8000
    },
    "voyage/rerank-2.5": {
        "litellm_provider": "voyage",
        "mode": "rerank",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "max_output_tokens": 32000
    },
    "voyage/rerank-2.5-lite": {
        "litellm_provider": "voyage",
        "mode": "rerank",
        "input_cost_per_token": 2e-08,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "max_output_tokens": 32000
    },
    "voyage/voyage-2": {
        "litellm_provider": "voyage",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4000,
        "max_input_tokens": 4000,
        "max_output_tokens": null
    },
    "voyage/voyage-3": {
        "litellm_provider": "voyage",
        "mode": "embedding",
        "input_cost_per_token": 6e-08,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "max_output_tokens": null
    },
    "voyage/voyage-3-large": {
        "litellm_provider": "voyage",
        "mode": "embedding",
        "input_cost_per_token": 1.8e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "max_output_tokens": null
    },
    "voyage/voyage-3-lite": {
        "litellm_provider": "voyage",
        "mode": "embedding",
        "input_cost_per_token": 2e-08,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "max_output_tokens": null
    },
    "voyage/voyage-3.5": {
        "litellm_provider": "voyage",
        "mode": "embedding",
        "input_cost_per_token": 6e-08,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "max_output_tokens": null
    },
    "voyage/voyage-3.5-lite": {
        "litellm_provider": "voyage",
        "mode": "embedding",
        "input_cost_per_token": 2e-08,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "max_output_tokens": null
    },
    "voyage/voyage-code-2": {
        "litellm_provider": "voyage",
        "mode": "embedding",
        "input_cost_per_token": 1.2e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16000,
        "max_input_tokens": 16000,
        "max_output_tokens": null
    },
    "voyage/voyage-code-3": {
        "litellm_provider": "voyage",
        "mode": "embedding",
        "input_cost_per_token": 1.8e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "max_output_tokens": null
    },
    "voyage/voyage-context-3": {
        "litellm_provider": "voyage",
        "mode": "embedding",
        "input_cost_per_token": 1.8e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 120000,
        "max_input_tokens": 120000,
        "max_output_tokens": null
    },
    "voyage/voyage-finance-2": {
        "litellm_provider": "voyage",
        "mode": "embedding",
        "input_cost_per_token": 1.2e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "max_output_tokens": null
    },
    "voyage/voyage-large-2": {
        "litellm_provider": "voyage",
        "mode": "embedding",
        "input_cost_per_token": 1.2e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16000,
        "max_input_tokens": 16000,
        "max_output_tokens": null
    },
    "voyage/voyage-law-2": {
        "litellm_provider": "voyage",
        "mode": "embedding",
        "input_cost_per_token": 1.2e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16000,
        "max_input_tokens": 16000,
        "max_output_tokens": null
    },
    "voyage/voyage-lite-01": {
        "litellm_provider": "voyage",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": null
    },
    "voyage/voyage-lite-02-instruct": {
        "litellm_provider": "voyage",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4000,
        "max_input_tokens": 4000,
        "max_output_tokens": null
    },
    "voyage/voyage-multimodal-3": {
        "litellm_provider": "voyage",
        "mode": "embedding",
        "input_cost_per_token": 1.2e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "max_output_tokens": null
    },
    "wandb/openai/gpt-oss-120b": {
        "litellm_provider": "wandb",
        "mode": "chat",
        "input_cost_per_token": 0.015,
        "output_cost_per_token": 0.06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "wandb/openai/gpt-oss-20b": {
        "litellm_provider": "wandb",
        "mode": "chat",
        "input_cost_per_token": 0.005,
        "output_cost_per_token": 0.02,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "wandb/zai-org/GLM-4.5": {
        "litellm_provider": "wandb",
        "mode": "chat",
        "input_cost_per_token": 0.055,
        "output_cost_per_token": 0.2,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "wandb/Qwen/Qwen3-235B-A22B-Instruct-2507": {
        "litellm_provider": "wandb",
        "mode": "chat",
        "input_cost_per_token": 0.01,
        "output_cost_per_token": 0.01,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "wandb/Qwen/Qwen3-Coder-480B-A35B-Instruct": {
        "litellm_provider": "wandb",
        "mode": "chat",
        "input_cost_per_token": 0.1,
        "output_cost_per_token": 0.15,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "wandb/Qwen/Qwen3-235B-A22B-Thinking-2507": {
        "litellm_provider": "wandb",
        "mode": "chat",
        "input_cost_per_token": 0.01,
        "output_cost_per_token": 0.01,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "wandb/moonshotai/Kimi-K2-Instruct": {
        "litellm_provider": "wandb",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "wandb/meta-llama/Llama-3.1-8B-Instruct": {
        "litellm_provider": "wandb",
        "mode": "chat",
        "input_cost_per_token": 0.022,
        "output_cost_per_token": 0.022,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "wandb/deepseek-ai/DeepSeek-V3.1": {
        "litellm_provider": "wandb",
        "mode": "chat",
        "input_cost_per_token": 0.055,
        "output_cost_per_token": 0.165,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "wandb/deepseek-ai/DeepSeek-R1-0528": {
        "litellm_provider": "wandb",
        "mode": "chat",
        "input_cost_per_token": 0.135,
        "output_cost_per_token": 0.54,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 161000,
        "max_input_tokens": 161000,
        "max_output_tokens": 161000
    },
    "wandb/deepseek-ai/DeepSeek-V3-0324": {
        "litellm_provider": "wandb",
        "mode": "chat",
        "input_cost_per_token": 0.114,
        "output_cost_per_token": 0.275,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 161000,
        "max_input_tokens": 161000,
        "max_output_tokens": 161000
    },
    "wandb/meta-llama/Llama-3.3-70B-Instruct": {
        "litellm_provider": "wandb",
        "mode": "chat",
        "input_cost_per_token": 0.071,
        "output_cost_per_token": 0.071,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "wandb/meta-llama/Llama-4-Scout-17B-16E-Instruct": {
        "litellm_provider": "wandb",
        "mode": "chat",
        "input_cost_per_token": 0.017,
        "output_cost_per_token": 0.066,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 64000,
        "max_input_tokens": 64000,
        "max_output_tokens": 64000
    },
    "wandb/microsoft/Phi-4-mini-instruct": {
        "litellm_provider": "wandb",
        "mode": "chat",
        "input_cost_per_token": 0.008,
        "output_cost_per_token": 0.035,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "watsonx/ibm/granite-3-8b-instruct": {
        "litellm_provider": "watsonx",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 1024,
        "max_input_tokens": 8192,
        "max_output_tokens": 1024
    },
    "watsonx/mistralai/mistral-large": {
        "litellm_provider": "watsonx",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 131072,
        "max_output_tokens": 16384
    },
    "watsonx/bigscience/mt0-xxl-13b": {
        "litellm_provider": "watsonx",
        "mode": "chat",
        "input_cost_per_token": 0.0005,
        "output_cost_per_token": 0.002,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "watsonx/core42/jais-13b-chat": {
        "litellm_provider": "watsonx",
        "mode": "chat",
        "input_cost_per_token": 0.0005,
        "output_cost_per_token": 0.002,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "watsonx/google/flan-t5-xl-3b": {
        "litellm_provider": "watsonx",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "watsonx/ibm/granite-13b-chat-v2": {
        "litellm_provider": "watsonx",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "watsonx/ibm/granite-13b-instruct-v2": {
        "litellm_provider": "watsonx",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "watsonx/ibm/granite-3-3-8b-instruct": {
        "litellm_provider": "watsonx",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "watsonx/ibm/granite-4-h-small": {
        "litellm_provider": "watsonx",
        "mode": "chat",
        "input_cost_per_token": 6e-08,
        "output_cost_per_token": 2.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 20480,
        "max_input_tokens": 20480,
        "max_output_tokens": 20480
    },
    "watsonx/ibm/granite-guardian-3-2-2b": {
        "litellm_provider": "watsonx",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "watsonx/ibm/granite-guardian-3-3-8b": {
        "litellm_provider": "watsonx",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "watsonx/ibm/granite-ttm-1024-96-r2": {
        "litellm_provider": "watsonx",
        "mode": "chat",
        "input_cost_per_token": 3.8e-07,
        "output_cost_per_token": 3.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 512,
        "max_input_tokens": 512,
        "max_output_tokens": 512
    },
    "watsonx/ibm/granite-ttm-1536-96-r2": {
        "litellm_provider": "watsonx",
        "mode": "chat",
        "input_cost_per_token": 3.8e-07,
        "output_cost_per_token": 3.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 512,
        "max_input_tokens": 512,
        "max_output_tokens": 512
    },
    "watsonx/ibm/granite-ttm-512-96-r2": {
        "litellm_provider": "watsonx",
        "mode": "chat",
        "input_cost_per_token": 3.8e-07,
        "output_cost_per_token": 3.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 512,
        "max_input_tokens": 512,
        "max_output_tokens": 512
    },
    "watsonx/ibm/granite-vision-3-2-2b": {
        "litellm_provider": "watsonx",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "watsonx/meta-llama/llama-3-2-11b-vision-instruct": {
        "litellm_provider": "watsonx",
        "mode": "chat",
        "input_cost_per_token": 3.5e-07,
        "output_cost_per_token": 3.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "watsonx/meta-llama/llama-3-2-1b-instruct": {
        "litellm_provider": "watsonx",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "watsonx/meta-llama/llama-3-2-3b-instruct": {
        "litellm_provider": "watsonx",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 1.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "watsonx/meta-llama/llama-3-2-90b-vision-instruct": {
        "litellm_provider": "watsonx",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "watsonx/meta-llama/llama-3-3-70b-instruct": {
        "litellm_provider": "watsonx",
        "mode": "chat",
        "input_cost_per_token": 7.1e-07,
        "output_cost_per_token": 7.1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "watsonx/meta-llama/llama-4-maverick-17b": {
        "litellm_provider": "watsonx",
        "mode": "chat",
        "input_cost_per_token": 3.5e-07,
        "output_cost_per_token": 1.4e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "watsonx/meta-llama/llama-guard-3-11b-vision": {
        "litellm_provider": "watsonx",
        "mode": "chat",
        "input_cost_per_token": 3.5e-07,
        "output_cost_per_token": 3.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "watsonx/mistralai/mistral-medium-2505": {
        "litellm_provider": "watsonx",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "watsonx/mistralai/mistral-small-2503": {
        "litellm_provider": "watsonx",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "max_output_tokens": 32000
    },
    "watsonx/mistralai/mistral-small-3-1-24b-instruct-2503": {
        "litellm_provider": "watsonx",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "max_output_tokens": 32000
    },
    "watsonx/mistralai/pixtral-12b-2409": {
        "litellm_provider": "watsonx",
        "mode": "chat",
        "input_cost_per_token": 3.5e-07,
        "output_cost_per_token": 3.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "watsonx/openai/gpt-oss-120b": {
        "litellm_provider": "watsonx",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "watsonx/sdaia/allam-1-13b-instruct": {
        "litellm_provider": "watsonx",
        "mode": "chat",
        "input_cost_per_token": 1.8e-06,
        "output_cost_per_token": 1.8e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "watsonx/whisper-large-v3-turbo": {
        "litellm_provider": "watsonx",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "whisper-1": {
        "litellm_provider": "openai",
        "mode": "audio_transcription",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "xai/grok-2": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "xai/grok-2-1212": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "xai/grok-2-latest": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "xai/grok-2-vision": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "xai/grok-2-vision-1212": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "xai/grok-2-vision-latest": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 2e-06,
        "output_cost_per_token": 1e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "xai/grok-3": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 7.5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "xai/grok-3-beta": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 7.5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "xai/grok-3-fast-beta": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 2.5e-05,
        "cache_read_input_token_cost": 1.25e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "xai/grok-3-fast-latest": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 2.5e-05,
        "cache_read_input_token_cost": 1.25e-06,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "xai/grok-3-latest": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": 7.5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "xai/grok-3-mini": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": 7.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "xai/grok-3-mini-beta": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": 7.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "xai/grok-3-mini-fast": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 4e-06,
        "cache_read_input_token_cost": 1.5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "xai/grok-3-mini-fast-beta": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 4e-06,
        "cache_read_input_token_cost": 1.5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "xai/grok-3-mini-fast-latest": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 4e-06,
        "cache_read_input_token_cost": 1.5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "xai/grok-3-mini-latest": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": 7.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "xai/grok-4": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "xai/grok-4-fast-reasoning": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": 5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2000000.0,
        "max_input_tokens": 2000000.0,
        "max_output_tokens": 2000000.0
    },
    "xai/grok-4-fast-non-reasoning": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": 5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2000000.0,
        "max_input_tokens": 2000000.0,
        "max_output_tokens": 2000000.0
    },
    "xai/grok-4-0709": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "xai/grok-4-latest": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 3e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "xai/grok-4-1-fast": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": 5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2000000.0,
        "max_input_tokens": 2000000.0,
        "max_output_tokens": 2000000.0
    },
    "xai/grok-4-1-fast-reasoning": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": 5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2000000.0,
        "max_input_tokens": 2000000.0,
        "max_output_tokens": 2000000.0
    },
    "xai/grok-4-1-fast-reasoning-latest": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": 5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2000000.0,
        "max_input_tokens": 2000000.0,
        "max_output_tokens": 2000000.0
    },
    "xai/grok-4-1-fast-non-reasoning": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": 5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2000000.0,
        "max_input_tokens": 2000000.0,
        "max_output_tokens": 2000000.0
    },
    "xai/grok-4-1-fast-non-reasoning-latest": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": 5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2000000.0,
        "max_input_tokens": 2000000.0,
        "max_output_tokens": 2000000.0
    },
    "xai/grok-beta": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "xai/grok-code-fast": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": 2e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "xai/grok-code-fast-1": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": 2e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "xai/grok-code-fast-1-0825": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": 2e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "xai/grok-vision-beta": {
        "litellm_provider": "xai",
        "mode": "chat",
        "input_cost_per_token": 5e-06,
        "output_cost_per_token": 1.5e-05,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "zai/glm-4.7": {
        "litellm_provider": "zai",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.2e-06,
        "cache_read_input_token_cost": 1.1e-07,
        "cache_creation_input_token_cost": 0,
        "max_tokens": null,
        "max_input_tokens": 200000,
        "max_output_tokens": 128000
    },
    "zai/glm-4.6": {
        "litellm_provider": "zai",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.2e-06,
        "cache_read_input_token_cost": 1.1e-07,
        "cache_creation_input_token_cost": 0,
        "max_tokens": null,
        "max_input_tokens": 200000,
        "max_output_tokens": 128000
    },
    "zai/glm-4.5": {
        "litellm_provider": "zai",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 128000,
        "max_output_tokens": 32000
    },
    "zai/glm-4.5v": {
        "litellm_provider": "zai",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 1.8e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 128000,
        "max_output_tokens": 32000
    },
    "zai/glm-4.5-x": {
        "litellm_provider": "zai",
        "mode": "chat",
        "input_cost_per_token": 2.2e-06,
        "output_cost_per_token": 8.9e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 128000,
        "max_output_tokens": 32000
    },
    "zai/glm-4.5-air": {
        "litellm_provider": "zai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 1.1e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 128000,
        "max_output_tokens": 32000
    },
    "zai/glm-4.5-airx": {
        "litellm_provider": "zai",
        "mode": "chat",
        "input_cost_per_token": 1.1e-06,
        "output_cost_per_token": 4.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 128000,
        "max_output_tokens": 32000
    },
    "zai/glm-4-32b-0414-128k": {
        "litellm_provider": "zai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 128000,
        "max_output_tokens": 32000
    },
    "zai/glm-4.5-flash": {
        "litellm_provider": "zai",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": 128000,
        "max_output_tokens": 32000
    },
    "vertex_ai/search_api": {
        "litellm_provider": "vertex_ai",
        "mode": "vector_store",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openai/container": {
        "litellm_provider": "openai",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openai/sora-2": {
        "litellm_provider": "openai",
        "mode": "video_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "openai/sora-2-pro": {
        "litellm_provider": "openai",
        "mode": "video_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/sora-2": {
        "litellm_provider": "azure",
        "mode": "video_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/sora-2-pro": {
        "litellm_provider": "azure",
        "mode": "video_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "azure/sora-2-pro-high-res": {
        "litellm_provider": "azure",
        "mode": "video_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "runwayml/gen4_turbo": {
        "litellm_provider": "runwayml",
        "mode": "video_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "runwayml/gen4_aleph": {
        "litellm_provider": "runwayml",
        "mode": "video_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "runwayml/gen3a_turbo": {
        "litellm_provider": "runwayml",
        "mode": "video_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "runwayml/gen4_image": {
        "litellm_provider": "runwayml",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "runwayml/gen4_image_turbo": {
        "litellm_provider": "runwayml",
        "mode": "image_generation",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "runwayml/eleven_multilingual_v2": {
        "litellm_provider": "runwayml",
        "mode": "audio_speech",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": null,
        "max_input_tokens": null,
        "max_output_tokens": null
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-coder-480b-a35b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 4.5e-07,
        "output_cost_per_token": 1.8e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "fireworks_ai/accounts/fireworks/models/flux-kontext-pro": {
        "litellm_provider": "fireworks_ai",
        "mode": "image_generation",
        "input_cost_per_token": 4e-08,
        "output_cost_per_token": 4e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/SSD-1B": {
        "litellm_provider": "fireworks_ai",
        "mode": "image_generation",
        "input_cost_per_token": 1.3e-10,
        "output_cost_per_token": 1.3e-10,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/chronos-hermes-13b-v2": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-13b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-13b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-13b-python": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-34b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-34b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-34b-python": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-70b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-70b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-70b-python": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-7b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-7b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "fireworks_ai/accounts/fireworks/models/code-llama-7b-python": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "fireworks_ai/accounts/fireworks/models/code-qwen-1p5-7b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 65536,
        "max_output_tokens": 65536
    },
    "fireworks_ai/accounts/fireworks/models/codegemma-2b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "fireworks_ai/accounts/fireworks/models/codegemma-7b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "fireworks_ai/accounts/fireworks/models/cogito-671b-v2-p1": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1.2e-06,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840
    },
    "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-llama-3b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-llama-70b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-llama-8b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-qwen-14b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-qwen-32b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/flux-kontext-max": {
        "litellm_provider": "fireworks_ai",
        "mode": "image_generation",
        "input_cost_per_token": 8e-08,
        "output_cost_per_token": 8e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/dbrx-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1.2e-06,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-1b-base": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-33b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-7b-base": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-7b-base-v1p5": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-7b-instruct-v1p5": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-lite-base": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-lite-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-prover-v2": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1.2e-06,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-0528-distill-qwen3-8b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-llama-70b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-llama-8b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-qwen-14b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-qwen-1p5b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-qwen-32b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-qwen-7b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v2-lite-chat": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v2p5": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1.2e-06,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/devstral-small-2505": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/dobby-mini-unhinged-plus-llama-3-1-8b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/dobby-unhinged-llama-3-3-70b-new": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/dolphin-2-9-2-qwen2-72b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/dolphin-2p6-mixtral-8x7b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/ernie-4p5-21b-a3b-pt": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/ernie-4p5-300b-a47b-pt": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/fare-20b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/firefunction-v1": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/firellava-13b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/firesearch-ocr-v6": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "fireworks_ai/accounts/fireworks/models/fireworks-asr-large": {
        "litellm_provider": "fireworks_ai",
        "mode": "audio_transcription",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/fireworks-asr-v2": {
        "litellm_provider": "fireworks_ai",
        "mode": "audio_transcription",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/flux-1-dev": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/flux-1-dev-controlnet-union": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-09,
        "output_cost_per_token": 1e-09,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/flux-1-dev-fp8": {
        "litellm_provider": "fireworks_ai",
        "mode": "image_generation",
        "input_cost_per_token": 5e-10,
        "output_cost_per_token": 5e-10,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/flux-1-schnell": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/flux-1-schnell-fp8": {
        "litellm_provider": "fireworks_ai",
        "mode": "image_generation",
        "input_cost_per_token": 3.5e-10,
        "output_cost_per_token": 3.5e-10,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/gemma-2b-it": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "fireworks_ai/accounts/fireworks/models/gemma-3-27b-it": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/gemma-7b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "fireworks_ai/accounts/fireworks/models/gemma-7b-it": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "fireworks_ai/accounts/fireworks/models/gemma2-9b-it": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "fireworks_ai/accounts/fireworks/models/glm-4p5v": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1.2e-06,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/gpt-oss-safeguard-120b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1.2e-06,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/gpt-oss-safeguard-20b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/hermes-2-pro-mistral-7b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/internvl3-38b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "fireworks_ai/accounts/fireworks/models/internvl3-78b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "fireworks_ai/accounts/fireworks/models/internvl3-8b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "fireworks_ai/accounts/fireworks/models/japanese-stable-diffusion-xl": {
        "litellm_provider": "fireworks_ai",
        "mode": "image_generation",
        "input_cost_per_token": 1.3e-10,
        "output_cost_per_token": 1.3e-10,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/kat-coder": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "fireworks_ai/accounts/fireworks/models/kat-dev-32b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/kat-dev-72b-exp": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/llama-guard-2-8b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "fireworks_ai/accounts/fireworks/models/llama-guard-3-1b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/llama-guard-3-8b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/llama-v2-13b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/llama-v2-13b-chat": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/llama-v2-70b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/llama-v2-70b-chat": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 2048,
        "max_output_tokens": 2048
    },
    "fireworks_ai/accounts/fireworks/models/llama-v2-7b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/llama-v2-7b-chat": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3-70b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3-70b-instruct-hf": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3-8b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3-8b-instruct-hf": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p1-405b-instruct-long": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p1-70b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p1-70b-instruct-1b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p1-nemotron-70b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p2-1b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p2-3b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/llama-v3p3-70b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/llamaguard-7b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/llava-yi-34b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/minimax-m1-80k": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/minimax-m2": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/ministral-3-14b-instruct-2512": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "fireworks_ai/accounts/fireworks/models/ministral-3-3b-instruct-2512": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "fireworks_ai/accounts/fireworks/models/ministral-3-8b-instruct-2512": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "fireworks_ai/accounts/fireworks/models/mistral-7b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/mistral-7b-instruct-4k": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/mistral-7b-instruct-v0p2": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/mistral-7b-instruct-v3": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/mistral-7b-v0p2": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/mistral-large-3-fp8": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1.2e-06,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000
    },
    "fireworks_ai/accounts/fireworks/models/mistral-nemo-base-2407": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "fireworks_ai/accounts/fireworks/models/mistral-nemo-instruct-2407": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "fireworks_ai/accounts/fireworks/models/mistral-small-24b-instruct-2501": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/mixtral-8x22b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1.2e-06,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 65536,
        "max_output_tokens": 65536
    },
    "fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1.2e-06,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 65536,
        "max_output_tokens": 65536
    },
    "fireworks_ai/accounts/fireworks/models/mixtral-8x7b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/mixtral-8x7b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/mixtral-8x7b-instruct-hf": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/mythomax-l2-13b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/nemotron-nano-v2-12b-vl": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/nous-capybara-7b-v1p9": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/nous-hermes-2-mixtral-8x7b-dpo": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/nous-hermes-2-yi-34b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/nous-hermes-llama2-13b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/nous-hermes-llama2-70b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/nous-hermes-llama2-7b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/nvidia-nemotron-nano-12b-v2": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/nvidia-nemotron-nano-9b-v2": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/openchat-3p5-0106-7b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "fireworks_ai/accounts/fireworks/models/openhermes-2-mistral-7b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/openhermes-2p5-mistral-7b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/openorca-7b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/phi-2-3b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 2048,
        "max_output_tokens": 2048
    },
    "fireworks_ai/accounts/fireworks/models/phi-3-mini-128k-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/phi-3-vision-128k-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32064,
        "max_input_tokens": 32064,
        "max_output_tokens": 32064
    },
    "fireworks_ai/accounts/fireworks/models/phind-code-llama-34b-python-v1": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "fireworks_ai/accounts/fireworks/models/phind-code-llama-34b-v1": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "fireworks_ai/accounts/fireworks/models/phind-code-llama-34b-v2": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "fireworks_ai/accounts/fireworks/models/playground-v2-1024px-aesthetic": {
        "litellm_provider": "fireworks_ai",
        "mode": "image_generation",
        "input_cost_per_token": 1.3e-10,
        "output_cost_per_token": 1.3e-10,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/playground-v2-5-1024px-aesthetic": {
        "litellm_provider": "fireworks_ai",
        "mode": "image_generation",
        "input_cost_per_token": 1.3e-10,
        "output_cost_per_token": 1.3e-10,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/pythia-12b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 2048,
        "max_output_tokens": 2048
    },
    "fireworks_ai/accounts/fireworks/models/qwen-qwq-32b-preview": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/qwen-v2p5-14b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/qwen-v2p5-7b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/qwen1p5-72b-chat": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/qwen2-7b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/qwen2-vl-2b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/qwen2-vl-72b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/qwen2-vl-7b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-0p5b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-14b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-1p5b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-32b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-32b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-72b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-72b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-7b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-0p5b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-0p5b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-14b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-14b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-1p5b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-1p5b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct-128k": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct-32k-rope": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct-64k": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 65536,
        "max_output_tokens": 65536
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-3b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-3b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-7b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-7b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-math-72b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-vl-32b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-vl-3b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-vl-72b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "fireworks_ai/accounts/fireworks/models/qwen2p5-vl-7b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-0p6b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": 40960
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-14b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": 40960
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-1p7b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-1p7b-fp8-draft": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-1p7b-fp8-draft-131072": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-1p7b-fp8-draft-40960": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": 40960
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-235b-a22b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2.2e-07,
        "output_cost_per_token": 8.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-235b-a22b-instruct-2507": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2.2e-07,
        "output_cost_per_token": 8.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-235b-a22b-thinking-2507": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2.2e-07,
        "output_cost_per_token": 8.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-30b-a3b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-30b-a3b-instruct-2507": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 5e-07,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-30b-a3b-thinking-2507": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-32b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-4b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": 40960
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-4b-instruct-2507": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-8b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": 40960
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-coder-30b-a3b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-coder-480b-instruct-bf16": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-embedding-0p6b": {
        "litellm_provider": "fireworks_ai",
        "mode": "embedding",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-embedding-4b": {
        "litellm_provider": "fireworks_ai",
        "mode": "embedding",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": 40960
    },
    "fireworks_ai/accounts/fireworks/models/": {
        "litellm_provider": "fireworks_ai",
        "mode": "embedding",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": 40960
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-next-80b-a3b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-next-80b-a3b-thinking": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-reranker-0p6b": {
        "litellm_provider": "fireworks_ai",
        "mode": "rerank",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": 40960
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-reranker-4b": {
        "litellm_provider": "fireworks_ai",
        "mode": "rerank",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": 40960
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-reranker-8b": {
        "litellm_provider": "fireworks_ai",
        "mode": "rerank",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": 40960
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-vl-235b-a22b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2.2e-07,
        "output_cost_per_token": 8.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-vl-235b-a22b-thinking": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2.2e-07,
        "output_cost_per_token": 8.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-vl-30b-a3b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-vl-30b-a3b-thinking": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-vl-32b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/qwen3-vl-8b-instruct": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/qwq-32b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "fireworks_ai/accounts/fireworks/models/rolm-ocr": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000
    },
    "fireworks_ai/accounts/fireworks/models/snorkel-mistral-7b-pairrm-dpo": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/stable-diffusion-xl-1024-v1-0": {
        "litellm_provider": "fireworks_ai",
        "mode": "image_generation",
        "input_cost_per_token": 1.3e-10,
        "output_cost_per_token": 1.3e-10,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/stablecode-3b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/starcoder-16b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "fireworks_ai/accounts/fireworks/models/starcoder-7b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "fireworks_ai/accounts/fireworks/models/starcoder2-15b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "fireworks_ai/accounts/fireworks/models/starcoder2-3b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "fireworks_ai/accounts/fireworks/models/starcoder2-7b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "fireworks_ai/accounts/fireworks/models/toppy-m-7b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "fireworks_ai/accounts/fireworks/models/whisper-v3": {
        "litellm_provider": "fireworks_ai",
        "mode": "audio_transcription",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/whisper-v3-turbo": {
        "litellm_provider": "fireworks_ai",
        "mode": "audio_transcription",
        "input_cost_per_token": 0.0,
        "output_cost_per_token": 0.0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/yi-34b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/yi-34b-200k-capybara": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 200000,
        "max_input_tokens": 200000,
        "max_output_tokens": 200000
    },
    "fireworks_ai/accounts/fireworks/models/yi-34b-chat": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 9e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/yi-6b": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 4096,
        "max_output_tokens": 4096
    },
    "fireworks_ai/accounts/fireworks/models/zephyr-7b-beta": {
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "novita/deepseek/deepseek-v3.2": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 2.69e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": 1.345e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 163840,
        "max_output_tokens": 65536
    },
    "novita/minimax/minimax-m2.1": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": 3e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 204800,
        "max_output_tokens": 131072
    },
    "novita/zai-org/glm-4.7": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.2e-06,
        "cache_read_input_token_cost": 1.1e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 204800,
        "max_output_tokens": 131072
    },
    "novita/xiaomimimo/mimo-v2-flash": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": 2e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 262144,
        "max_output_tokens": 32000
    },
    "novita/zai-org/autoglm-phone-9b-multilingual": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 3.5e-08,
        "output_cost_per_token": 1.38e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 65536,
        "max_output_tokens": 65536
    },
    "novita/moonshotai/kimi-k2-thinking": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "novita/minimax/minimax-m2": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": 3e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 204800,
        "max_output_tokens": 131072
    },
    "novita/paddlepaddle/paddleocr-vl": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 2e-08,
        "output_cost_per_token": 2e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "novita/deepseek/deepseek-v3.2-exp": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 2.7e-07,
        "output_cost_per_token": 4.1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 163840,
        "max_output_tokens": 65536
    },
    "novita/qwen/qwen3-vl-235b-a22b-thinking": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 9.8e-07,
        "output_cost_per_token": 3.95e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 131072,
        "max_output_tokens": 32768
    },
    "novita/zai-org/glm-4.6v": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 9e-07,
        "cache_read_input_token_cost": 5.5e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 131072,
        "max_output_tokens": 32768
    },
    "novita/zai-org/glm-4.6": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 5.5e-07,
        "output_cost_per_token": 2.2e-06,
        "cache_read_input_token_cost": 1.1e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 204800,
        "max_output_tokens": 131072
    },
    "novita/kwaipilot/kat-coder-pro": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 1.2e-06,
        "cache_read_input_token_cost": 6e-08,
        "cache_creation_input_token_cost": null,
        "max_tokens": 128000,
        "max_input_tokens": 256000,
        "max_output_tokens": 128000
    },
    "novita/qwen/qwen3-next-80b-a3b-instruct": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 131072,
        "max_output_tokens": 32768
    },
    "novita/qwen/qwen3-next-80b-a3b-thinking": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 131072,
        "max_output_tokens": 32768
    },
    "novita/deepseek/deepseek-ocr": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 3e-08,
        "output_cost_per_token": 3e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "novita/deepseek/deepseek-v3.1-terminus": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 2.7e-07,
        "output_cost_per_token": 1e-06,
        "cache_read_input_token_cost": 1.35e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 131072,
        "max_output_tokens": 32768
    },
    "novita/qwen/qwen3-vl-235b-a22b-instruct": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 1.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 131072,
        "max_output_tokens": 32768
    },
    "novita/qwen/qwen3-max": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 2.11e-06,
        "output_cost_per_token": 8.45e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 262144,
        "max_output_tokens": 65536
    },
    "novita/skywork/r1v4-lite": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 262144,
        "max_output_tokens": 65536
    },
    "novita/deepseek/deepseek-v3.1": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 2.7e-07,
        "output_cost_per_token": 1e-06,
        "cache_read_input_token_cost": 1.35e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 131072,
        "max_output_tokens": 32768
    },
    "novita/moonshotai/kimi-k2-0905": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 262144,
        "max_input_tokens": 262144,
        "max_output_tokens": 262144
    },
    "novita/qwen/qwen3-coder-480b-a35b-instruct": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 1.3e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 262144,
        "max_output_tokens": 65536
    },
    "novita/qwen/qwen3-coder-30b-a3b-instruct": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 7e-08,
        "output_cost_per_token": 2.7e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 160000,
        "max_output_tokens": 32768
    },
    "novita/openai/gpt-oss-120b": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 2.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 131072,
        "max_output_tokens": 32768
    },
    "novita/moonshotai/kimi-k2-instruct": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 5.7e-07,
        "output_cost_per_token": 2.3e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "novita/deepseek/deepseek-v3-0324": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 2.7e-07,
        "output_cost_per_token": 1.12e-06,
        "cache_read_input_token_cost": 1.35e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 163840,
        "max_input_tokens": 163840,
        "max_output_tokens": 163840
    },
    "novita/zai-org/glm-4.5": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 2.2e-06,
        "cache_read_input_token_cost": 1.1e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 98304,
        "max_input_tokens": 131072,
        "max_output_tokens": 98304
    },
    "novita/qwen/qwen3-235b-a22b-thinking-2507": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 3e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 131072,
        "max_output_tokens": 32768
    },
    "novita/meta-llama/llama-3.1-8b-instruct": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 2e-08,
        "output_cost_per_token": 5e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 16384,
        "max_output_tokens": 16384
    },
    "novita/google/gemma-3-12b-it": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 1e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 131072,
        "max_output_tokens": 8192
    },
    "novita/zai-org/glm-4.5v": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 6e-07,
        "output_cost_per_token": 1.8e-06,
        "cache_read_input_token_cost": 1.1e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 65536,
        "max_output_tokens": 16384
    },
    "novita/openai/gpt-oss-20b": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 4e-08,
        "output_cost_per_token": 1.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 131072,
        "max_output_tokens": 32768
    },
    "novita/qwen/qwen3-235b-a22b-instruct-2507": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 9e-08,
        "output_cost_per_token": 5.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 131072,
        "max_output_tokens": 16384
    },
    "novita/deepseek/deepseek-r1-distill-qwen-14b": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 1.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 32768,
        "max_output_tokens": 16384
    },
    "novita/meta-llama/llama-3.3-70b-instruct": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 1.35e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 120000,
        "max_input_tokens": 131072,
        "max_output_tokens": 120000
    },
    "novita/qwen/qwen-2.5-72b-instruct": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 3.8e-07,
        "output_cost_per_token": 4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 32000,
        "max_output_tokens": 8192
    },
    "novita/mistralai/mistral-nemo": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 4e-08,
        "output_cost_per_token": 1.7e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16000,
        "max_input_tokens": 60288,
        "max_output_tokens": 16000
    },
    "novita/minimaxai/minimax-m1-80k": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 5.5e-07,
        "output_cost_per_token": 2.2e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 40000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 40000
    },
    "novita/deepseek/deepseek-r1-0528": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 7e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": 3.5e-07,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 163840,
        "max_output_tokens": 32768
    },
    "novita/deepseek/deepseek-r1-distill-qwen-32b": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 3e-07,
        "output_cost_per_token": 3e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 64000,
        "max_output_tokens": 32000
    },
    "novita/meta-llama/llama-3-8b-instruct": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 4e-08,
        "output_cost_per_token": 4e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "novita/microsoft/wizardlm-2-8x22b": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 6.2e-07,
        "output_cost_per_token": 6.2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8000,
        "max_input_tokens": 65535,
        "max_output_tokens": 8000
    },
    "novita/deepseek/deepseek-r1-0528-qwen3-8b": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 6e-08,
        "output_cost_per_token": 9e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 128000,
        "max_output_tokens": 32000
    },
    "novita/deepseek/deepseek-r1-distill-llama-70b": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 8e-07,
        "output_cost_per_token": 8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "novita/meta-llama/llama-3-70b-instruct": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 5.1e-07,
        "output_cost_per_token": 7.4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8000,
        "max_input_tokens": 8192,
        "max_output_tokens": 8000
    },
    "novita/qwen/qwen3-235b-a22b-fp8": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 20000,
        "max_input_tokens": 40960,
        "max_output_tokens": 20000
    },
    "novita/meta-llama/llama-4-maverick-17b-128e-instruct-fp8": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 2.7e-07,
        "output_cost_per_token": 8.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192
    },
    "novita/meta-llama/llama-4-scout-17b-16e-instruct": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 1.8e-07,
        "output_cost_per_token": 5.9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "novita/nousresearch/hermes-2-pro-llama-3-8b": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 1.4e-07,
        "output_cost_per_token": 1.4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "novita/qwen/qwen2.5-vl-72b-instruct": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 8e-07,
        "output_cost_per_token": 8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "novita/sao10k/l3-70b-euryale-v2.1": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 1.48e-06,
        "output_cost_per_token": 1.48e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "novita/baidu/ernie-4.5-21B-a3b-thinking": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 7e-08,
        "output_cost_per_token": 2.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 131072,
        "max_output_tokens": 65536
    },
    "novita/sao10k/l3-8b-lunaris": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 5e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "novita/baichuan/baichuan-m2-32b": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 7e-08,
        "output_cost_per_token": 7e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072
    },
    "novita/baidu/ernie-4.5-vl-424b-a47b": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 4.2e-07,
        "output_cost_per_token": 1.25e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16000,
        "max_input_tokens": 123000,
        "max_output_tokens": 16000
    },
    "novita/baidu/ernie-4.5-300b-a47b-paddle": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 2.8e-07,
        "output_cost_per_token": 1.1e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 12000,
        "max_input_tokens": 123000,
        "max_output_tokens": 12000
    },
    "novita/deepseek/deepseek-prover-v2-671b": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 7e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 160000,
        "max_input_tokens": 160000,
        "max_output_tokens": 160000
    },
    "novita/qwen/qwen3-32b-fp8": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 4.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 20000,
        "max_input_tokens": 40960,
        "max_output_tokens": 20000
    },
    "novita/qwen/qwen3-30b-a3b-fp8": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 9e-08,
        "output_cost_per_token": 4.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 20000,
        "max_input_tokens": 40960,
        "max_output_tokens": 20000
    },
    "novita/google/gemma-3-27b-it": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 1.19e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 98304,
        "max_output_tokens": 16384
    },
    "novita/deepseek/deepseek-v3-turbo": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 4e-07,
        "output_cost_per_token": 1.3e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16000,
        "max_input_tokens": 64000,
        "max_output_tokens": 16000
    },
    "novita/deepseek/deepseek-r1-turbo": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 7e-07,
        "output_cost_per_token": 2.5e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16000,
        "max_input_tokens": 64000,
        "max_output_tokens": 16000
    },
    "novita/Sao10K/L3-8B-Stheno-v3.2": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 5e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 8192,
        "max_output_tokens": 32000
    },
    "novita/gryphe/mythomax-l2-13b": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 9e-08,
        "output_cost_per_token": 9e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 3200,
        "max_input_tokens": 4096,
        "max_output_tokens": 3200
    },
    "novita/baidu/ernie-4.5-vl-28b-a3b-thinking": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 3.9e-07,
        "output_cost_per_token": 3.9e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 65536,
        "max_input_tokens": 131072,
        "max_output_tokens": 65536
    },
    "novita/qwen/qwen3-vl-8b-instruct": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 8e-08,
        "output_cost_per_token": 5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 131072,
        "max_output_tokens": 32768
    },
    "novita/zai-org/glm-4.5-air": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 1.3e-07,
        "output_cost_per_token": 8.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 98304,
        "max_input_tokens": 131072,
        "max_output_tokens": 98304
    },
    "novita/qwen/qwen3-vl-30b-a3b-instruct": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 7e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 131072,
        "max_output_tokens": 32768
    },
    "novita/qwen/qwen3-vl-30b-a3b-thinking": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 2e-07,
        "output_cost_per_token": 1e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 131072,
        "max_output_tokens": 32768
    },
    "novita/qwen/qwen3-omni-30b-a3b-thinking": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 9.7e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 65536,
        "max_output_tokens": 16384
    },
    "novita/qwen/qwen3-omni-30b-a3b-instruct": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 9.7e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 65536,
        "max_output_tokens": 16384
    },
    "novita/qwen/qwen-mt-plus": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 2.5e-07,
        "output_cost_per_token": 7.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 16384,
        "max_output_tokens": 8192
    },
    "novita/baidu/ernie-4.5-vl-28b-a3b": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 1.4e-07,
        "output_cost_per_token": 5.6e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8000,
        "max_input_tokens": 30000,
        "max_output_tokens": 8000
    },
    "novita/baidu/ernie-4.5-21B-a3b": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 7e-08,
        "output_cost_per_token": 2.8e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8000,
        "max_input_tokens": 120000,
        "max_output_tokens": 8000
    },
    "novita/qwen/qwen3-8b-fp8": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 3.5e-08,
        "output_cost_per_token": 1.38e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 20000,
        "max_input_tokens": 128000,
        "max_output_tokens": 20000
    },
    "novita/qwen/qwen3-4b-fp8": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 3e-08,
        "output_cost_per_token": 3e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 20000,
        "max_input_tokens": 128000,
        "max_output_tokens": 20000
    },
    "novita/qwen/qwen2.5-7b-instruct": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 7e-08,
        "output_cost_per_token": 7e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 32000,
        "max_output_tokens": 32000
    },
    "novita/meta-llama/llama-3.2-3b-instruct": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 3e-08,
        "output_cost_per_token": 5e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32000,
        "max_input_tokens": 32768,
        "max_output_tokens": 32000
    },
    "novita/sao10k/l31-70b-euryale-v2.2": {
        "litellm_provider": "novita",
        "mode": "chat",
        "input_cost_per_token": 1.48e-06,
        "output_cost_per_token": 1.48e-06,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": 8192
    },
    "novita/qwen/qwen3-embedding-0.6b": {
        "litellm_provider": "novita",
        "mode": "embedding",
        "input_cost_per_token": 7e-08,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 32768,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768
    },
    "novita/qwen/qwen3-embedding-8b": {
        "litellm_provider": "novita",
        "mode": "embedding",
        "input_cost_per_token": 7e-08,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 32768,
        "max_output_tokens": 4096
    },
    "novita/baai/bge-m3": {
        "litellm_provider": "novita",
        "mode": "embedding",
        "input_cost_per_token": 1e-08,
        "output_cost_per_token": 1e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 96000,
        "max_input_tokens": 8192,
        "max_output_tokens": 96000
    },
    "novita/qwen/qwen3-reranker-8b": {
        "litellm_provider": "novita",
        "mode": "rerank",
        "input_cost_per_token": 5e-08,
        "output_cost_per_token": 5e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 32768,
        "max_output_tokens": 4096
    },
    "novita/baai/bge-reranker-v2-m3": {
        "litellm_provider": "novita",
        "mode": "rerank",
        "input_cost_per_token": 1e-08,
        "output_cost_per_token": 1e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8000,
        "max_input_tokens": 8000,
        "max_output_tokens": 8000
    },
    "llamagate/llama-3.1-8b": {
        "litellm_provider": "llamagate",
        "mode": "chat",
        "input_cost_per_token": 3e-08,
        "output_cost_per_token": 5e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 131072,
        "max_output_tokens": 8192
    },
    "llamagate/llama-3.2-3b": {
        "litellm_provider": "llamagate",
        "mode": "chat",
        "input_cost_per_token": 4e-08,
        "output_cost_per_token": 8e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 131072,
        "max_output_tokens": 8192
    },
    "llamagate/mistral-7b-v0.3": {
        "litellm_provider": "llamagate",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 1.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 32768,
        "max_output_tokens": 8192
    },
    "llamagate/qwen3-8b": {
        "litellm_provider": "llamagate",
        "mode": "chat",
        "input_cost_per_token": 4e-08,
        "output_cost_per_token": 1.4e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 32768,
        "max_output_tokens": 8192
    },
    "llamagate/dolphin3-8b": {
        "litellm_provider": "llamagate",
        "mode": "chat",
        "input_cost_per_token": 8e-08,
        "output_cost_per_token": 1.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "llamagate/deepseek-r1-8b": {
        "litellm_provider": "llamagate",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 65536,
        "max_output_tokens": 16384
    },
    "llamagate/deepseek-r1-7b-qwen": {
        "litellm_provider": "llamagate",
        "mode": "chat",
        "input_cost_per_token": 8e-08,
        "output_cost_per_token": 1.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 16384,
        "max_input_tokens": 131072,
        "max_output_tokens": 16384
    },
    "llamagate/openthinker-7b": {
        "litellm_provider": "llamagate",
        "mode": "chat",
        "input_cost_per_token": 8e-08,
        "output_cost_per_token": 1.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 32768,
        "max_output_tokens": 8192
    },
    "llamagate/qwen2.5-coder-7b": {
        "litellm_provider": "llamagate",
        "mode": "chat",
        "input_cost_per_token": 6e-08,
        "output_cost_per_token": 1.2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 32768,
        "max_output_tokens": 8192
    },
    "llamagate/deepseek-coder-6.7b": {
        "litellm_provider": "llamagate",
        "mode": "chat",
        "input_cost_per_token": 6e-08,
        "output_cost_per_token": 1.2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 16384,
        "max_output_tokens": 4096
    },
    "llamagate/codellama-7b": {
        "litellm_provider": "llamagate",
        "mode": "chat",
        "input_cost_per_token": 6e-08,
        "output_cost_per_token": 1.2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 4096,
        "max_input_tokens": 16384,
        "max_output_tokens": 4096
    },
    "llamagate/qwen3-vl-8b": {
        "litellm_provider": "llamagate",
        "mode": "chat",
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 5.5e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 32768,
        "max_output_tokens": 8192
    },
    "llamagate/llava-7b": {
        "litellm_provider": "llamagate",
        "mode": "chat",
        "input_cost_per_token": 1e-07,
        "output_cost_per_token": 2e-07,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 2048,
        "max_input_tokens": 4096,
        "max_output_tokens": 2048
    },
    "llamagate/gemma3-4b": {
        "litellm_provider": "llamagate",
        "mode": "chat",
        "input_cost_per_token": 3e-08,
        "output_cost_per_token": 8e-08,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192
    },
    "llamagate/nomic-embed-text": {
        "litellm_provider": "llamagate",
        "mode": "embedding",
        "input_cost_per_token": 2e-08,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 8192,
        "max_input_tokens": 8192,
        "max_output_tokens": null
    },
    "llamagate/qwen3-embedding-8b": {
        "litellm_provider": "llamagate",
        "mode": "embedding",
        "input_cost_per_token": 2e-08,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": null,
        "cache_creation_input_token_cost": null,
        "max_tokens": 40960,
        "max_input_tokens": 40960,
        "max_output_tokens": null
    },
    "sarvam/sarvam-m": {
        "litellm_provider": "sarvam",
        "mode": "chat",
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "cache_read_input_token_cost": 0,
        "cache_creation_input_token_cost": 0,
        "max_tokens": 32000,
        "max_input_tokens": 8192,
        "max_output_tokens": 32000
    }
}